{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"GlassOps\u2122","text":"<p>Governance-first Salesforce DevOps.</p> <p>GlassOps governs outcomes, not implementations.</p> <p>GlassOps is an open governance protocol for Salesforce CI/CD. It enforces architectural and quality standards before deployments execute. No tool or vendor lock-in.</p>"},{"location":"#what-problem-does-glassops-solve","title":"What Problem Does GlassOps Solve?","text":"<p>Most Salesforce DevOps tools force a tradeoff:</p> <ul> <li>Fast but opaque (black-box platforms)</li> <li>Transparent but chaotic (raw CLI scripts)</li> </ul> <p>GlassOps removes the tradeoff.</p> <p>It separates:</p> <ul> <li>Governance (Policy, Standards, Audit)   from</li> <li>Execution (CLI tools, workflows, automation)</li> </ul> <p>You choose how you deploy. GlassOps decides whether you should.</p>"},{"location":"#the-mental-model","title":"The Mental Model","text":"<pre><code>Intent \u2192 Policy \u2192 Simulation \u2192 Contract \u2192 Enforcement \u2192 Execution\n</code></pre> <ul> <li>Intent: A deployment is requested</li> <li>Policy: Quality &amp; architectural standards are resolved</li> <li>Simulation: A dry run validates the change</li> <li>Contract: Results are normalized into a governance record</li> <li>Enforcement: Policy decides pass/fail</li> <li>Execution: Deployment only proceeds if governance passes</li> </ul> <p>GlassOps never parses raw CLI output. It only reads a Deployment Contract.</p>"},{"location":"#what-glassops-is-and-is-not","title":"What GlassOps Is (and Is Not)","text":""},{"location":"#glassops-is","title":"GlassOps is:","text":"<ul> <li>A governance control plane</li> <li>A portable policy layer (OPA)</li> <li>A protocol that execution tools must follow</li> <li>A Container-First architecture (Executed via GitHub Actions or K8s)</li> <li>An audit and compliance amplifier</li> </ul>"},{"location":"#glassops-is-not","title":"GlassOps is not:","text":"<ul> <li>A CI/CD pipeline engine</li> <li>A replacement for sfdx-hardis, Gearset, or Copado</li> <li>A proprietary black box</li> <li>A commercial SaaS product</li> </ul>"},{"location":"#execution-engines-adapters","title":"Execution Engines (Adapters)","text":"<p>GlassOps works with multiple execution tools via adapters:</p> <ul> <li>GlassOps Native. Raw <code>sf</code> CLI. Maximum transparency.</li> <li>GlassOps Hardis. Wraps <code>sfdx-hardis</code>. Maximum velocity.</li> <li>Bring Your Own. Implement the adapter interface.</li> </ul> <p>Switch engines without rewriting governance.</p>"},{"location":"#adoption-levels","title":"Adoption Levels","text":"<ul> <li>Level 1: Safe execution (adapters only)</li> <li>Level 2: Governance protocol (policy + contracts)</li> <li>Level 3: Optional Salesforce UI (Reference Console)</li> </ul> <p>You can stop at any level and still get value.</p>"},{"location":"#project-status","title":"Project Status","text":"<ul> <li>In active development</li> <li>Seeking testers and collaborators</li> </ul>"},{"location":"#implementation-status","title":"Implementation Status","text":"Component Status Description GlassOps Runtime In Development Unified governance primitive (<code>glassops/runtime:latest</code>). Native Adapter In Development Standard Salesforce CLI execution (bundled in Runtime v1). Policy Engine In Development OPA-based policy resolution API. <p>This project is an architectural reference implementation, not a commercial product.</p>"},{"location":"#learn-more","title":"Learn More","text":"<ul> <li>One-page overview: <code>overview.md</code></li> <li>Vision &amp; philosophy: <code>vision.md</code></li> <li>Full architecture spec: <code>architecture.md</code></li> </ul>"},{"location":"#who-this-is-for","title":"Who This Is For","text":"<p>GlassOps is designed for teams that:</p> <ul> <li>Already use (or want to use) GitHub Actions</li> <li>Care about auditability and compliance</li> <li>Prefer transparent systems over black boxes</li> <li>Think in systems and contracts</li> </ul> <p>If that's not you, that's okay. GlassOps is opinionated by design.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># .github/workflows/deploy.yml\njobs:\n    deploy:\n        runs-on: ubuntu-latest\n        steps:\n            - uses: actions/checkout@v4\n\n            - name: GlassOps Runtime\n              uses: glassops-platform/glassops/packages/runtime@v1\n              with:\n                  client_id: ${{ secrets.SF_CLIENT_ID }}\n                  jwt_key: ${{ secrets.SF_JWT_KEY }}\n                  username: ${{ vars.SF_USERNAME }}\n</code></pre> <p>See doc-map.md for available guides.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>GlassOps is intentionally modular. You don't need to adopt the whole platform to contribute.</p> <ul> <li>Build an adapter for your favorite tool</li> <li>Improve policy resolution logic</li> <li>Add audit visualizations</li> <li>Report bugs or suggest features</li> <li>See <code>CONTRIBUTING.md</code> for details.</li> </ul>"},{"location":"#license","title":"License","text":"<ul> <li>Code: Apache 2.0. See LICENSE</li> <li>Documentation: Creative Commons Attribution 4.0 International. See LICENSE-DOCS</li> </ul>"},{"location":"#contact","title":"Contact","text":"<ul> <li>Discussions: GitHub Discussions</li> <li>Issues: GitHub Issues</li> <li>Author: Ryan Bumstead (@rdbumstead)</li> <li>Maintainer: Ryan Bumstead (@rdbumstead)</li> </ul>"},{"location":"CONTRIBUTING/","title":"Contributing to GlassOps\u2122","text":"<p>We love your input! We want to make contributing to GlassOps as easy and transparent as possible, whether it's reporting a bug, proposing a new feature, or submitting a fix.</p>"},{"location":"CONTRIBUTING/#legal-notice-personal-capacity","title":"Legal Notice: Personal Capacity","text":"<p>To ensure the long-term independence and professional integrity of the GlassOps\u2122 platform, all contributions must be made in a personal capacity.</p> <p>By submitting a Pull Request, you represent and warrant that:</p> <ol> <li>Individual Action: You are making this contribution in your personal capacity and not as an employee, agent, or representative of any other entity.</li> <li>Resource Independence: You are not using any equipment, trade secrets, confidential information, or proprietary resources belonging to an employer or third party to develop this contribution.</li> <li>Right to License: You have the full legal right to grant the licenses set forth in the Apache License, Version 2.0.</li> </ol>"},{"location":"CONTRIBUTING/#community-governance","title":"Community Governance","text":""},{"location":"CONTRIBUTING/#the-glassops-protocol","title":"The GlassOps Protocol","text":"<p>GlassOps is a governance-first protocol. We prioritize architectural health and \"One Trigger Per Object\" discipline over raw deployment speed.</p>"},{"location":"CONTRIBUTING/#adoption-metrics","title":"Adoption Metrics","text":"<p>Before proposing a major change, consider if it aligns with our target maturity levels:</p> Maturity Level Component Who it's for Day 0 Native Adapter Teams wanting safe, transparent execution. Day 30 Scanner Adapter Teams ready to enforce architectural hygiene. Day 90 Hardis Adapter Teams ready for high-velocity automation."},{"location":"CONTRIBUTING/#how-to-contribute","title":"How to Contribute","text":""},{"location":"CONTRIBUTING/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repo and create your branch from <code>main</code>.</li> <li>Clean Room Standard: Ensure your contribution is independent of any proprietary or work-related logic.</li> <li>Test: Verify your changes against the Deployment Contract v1.0 schema.</li> <li>Lint: Ensure the CI build passes and follow the project's coding standards.</li> <li>Issue: Submit your Pull Request!</li> </ol>"},{"location":"CONTRIBUTING/#report-bugs","title":"Report Bugs","text":"<p>We use GitHub issues to track public bugs. Report a bug by opening a new issue.</p> <p>Great Bug Reports tend to have:</p> <ul> <li>A quick summary and background.</li> <li>Specific steps to reproduce (including sample code).</li> <li>Expected vs. actual outcomes.</li> <li>Notes on troubleshooting steps you\u2019ve already attempted.</li> </ul>"},{"location":"CONTRIBUTING/#license-trademark","title":"License &amp; Trademark","text":"<p>By contributing, you agree that your contributions will be licensed under the Apache License, Version 2.0.</p> <p>GlassOps\u2122 is a trademark of Ryan Bumstead. This project does not grant permission to use the trade names, trademarks, or service marks of the Licensor except as required for reasonable and customary use in describing the origin of the Work.</p>"},{"location":"LICENSE/","title":"Code License","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of     this License, each Contributor hereby grants to You a perpetual,     worldwide, non-exclusive, no-charge, royalty-free, irrevocable     copyright license to reproduce, prepare Derivative Works of,     publicly display, publicly perform, sublicense, and distribute the     Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of     this License, each Contributor hereby grants to You a perpetual,     worldwide, non-exclusive, no-charge, royalty-free, irrevocable     (except as stated in this section) patent license to make, have made,     use, offer to sell, sell, import, and otherwise transfer the Work,     where such license applies only to those patent claims licensable     by such Contributor that are necessarily infringed by their     Contribution(s) alone or by combination of their Contribution(s)     with the Work to which such Contribution(s) was submitted. If You     institute patent litigation against any entity (including a     cross-claim or counterclaim in a lawsuit) alleging that the Work     or a Contribution incorporated within the Work constitutes direct     or contributory patent infringement, then any patent licenses     granted to You under this License for that Work shall terminate     as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the     Work or Derivative Works thereof in any medium, with or without     modifications, and in Source or Object form, provided that You     meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,     any Contribution intentionally submitted for inclusion in the Work     by You to the Licensor shall be under the terms and conditions of     this License, without any additional terms or conditions.     Notwithstanding the above, nothing herein shall supersede or modify     the terms of any separate license agreement you may have executed     with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade     names, trademarks, service marks, or product names of the Licensor,     except as required for reasonable and customary use in describing the     origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or     agreed to in writing, Licensor provides the Work (and each     Contributor provides its Contributions) on an \"AS IS\" BASIS,     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or     implied, including, without limitation, any warranties or conditions     of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A     PARTICULAR PURPOSE. You are solely responsible for determining the     appropriateness of using or redistributing the Work and assume any     risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,     whether in tort (including negligence), contract, or otherwise,     unless required by applicable law (such as deliberate and grossly     negligent acts) or agreed to in writing, shall any Contributor be     liable to You for damages, including any direct, indirect, special,     incidental, or consequential damages of any character arising as a     result of this License or out of the use or inability to use the     Work (including but not limited to damages for loss of goodwill,     work stoppage, computer failure or malfunction, or any and all     other commercial damages or losses), even if such Contributor     has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing     the Work or Derivative Works thereof, You may choose to offer,     and charge a fee for, acceptance of support, warranty, indemnity,     or other liability obligations and/or rights consistent with this     License. However, in accepting such obligations, You may act only     on Your own behalf and on Your sole responsibility, not on behalf     of any other Contributor, and only if You agree to indemnify,     defend, and hold each Contributor harmless for any liability     incurred by, or claims asserted against, such Contributor by reason     of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright 2026 Ryan Bumstead</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"docs/LICENSE/","title":"Docs License","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"docs/adr-index/","title":"GlassOps Architecture Decision Records (ADR) Index","text":"<p>This document provides a centralized index of all architectural decisions across the GlassOps project.</p>"},{"location":"docs/adr-index/#what-are-adrs","title":"What are ADRs?","text":"<p>Architecture Decision Records (ADRs) capture important architectural decisions along with their context and consequences.</p> <p>Why ADRs Matter:</p> <ul> <li>\ud83d\udcdd Document Decisions - Capture the \"why\" behind technical choices</li> <li>\ud83d\udd0d Historical Context - Understand past decisions when making new ones</li> <li>\ud83e\udd1d Team Alignment - Ensure everyone understands the architecture</li> <li>\u2696\ufe0f Trade-offs - Explicitly document alternatives and consequences</li> </ul>"},{"location":"docs/adr-index/#adr-locations-by-project","title":"ADR Locations by Project","text":""},{"location":"docs/adr-index/#1-glassops-core-docsadr","title":"1. GlassOps Core (<code>docs/adr/</code>)","text":"<p>Platform-level decisions affecting the entire GlassOps ecosystem</p> ADR Title Status Date 001 System API Primitive Accepted 2026-01-19 002 GitHub Execution Authority Accepted 2026-01-19 003 Additive Governance Accepted 2026-01-19 004 Schema Contract Config Accepted 2026-01-19 005 Control Plane Architecture Accepted 2026-01-19 006 Documentation as Governed Artifact Proposed 2026-01-24 007 Protocol Supremacy Enforcement Accepted 2026-01-24 008 Federated Documentation Structure Accepted 2026-01-24 009 The 8/10 vs 10/10 Bridge Strategy Accepted 2026-01-24 010 Identity Contract Accepted 2026-01-24 011 Monorepo Strategy Accepted 2026-01-24"},{"location":"docs/adr-index/#2-glassops-runtime-glassops-runtimedocsadr","title":"2. GlassOps Runtime (<code>glassops-runtime/docs/adr/</code>)","text":"<p>Runtime execution decisions for GitHub Actions adapter</p> ADR Title Status Date 001 6-Phase Execution Model Accepted 2026-01-24 002 Caching Strategy in Docker Runtime Accepted 2026-02-01"},{"location":"docs/adr-index/#3-glassops-control-plane-glassops-control-planedocsadr","title":"3. GlassOps Control Plane (<code>glassops-control-plane/docs/adr/</code>)","text":"<p>Control plane and operator architecture decisions</p> ADR Title Status Date 001 Kubernetes Operator Pattern Accepted 2026-01-24"},{"location":"docs/adr-index/#4-glassspec-protocol-glassspecdocsadr","title":"4. GlassSpec Protocol (<code>glassspec/docs/adr/</code>)","text":"<p>Protocol specification and standard decisions</p> ADR Title Status Date 001 Layered Contract Model Accepted 2026-01-24"},{"location":"docs/adr-index/#5-glassops-native-adapter-packagesadaptersnativedocsadr","title":"5. GlassOps Native Adapter (<code>packages/adapters/native/docs/adr/</code>)","text":"<p>Native Salesforce adapter decisions</p> ADR Title Status Date - No ADRs yet - - <p>Proposed ADRs:</p> <ul> <li>sf CLI vs @salesforce/core Integration</li> <li>JWT Key Management Strategy</li> <li>SARIF Mapping from Deployment Results</li> <li>Coverage Calculation Methodology</li> </ul>"},{"location":"docs/adr-index/#6-glassops-sfdx-hardis-adapter-packagesadaptershardisdocsadr","title":"6. GlassOps SFDX-Hardis Adapter (<code>packages/adapters/hardis/docs/adr/</code>)","text":"<p>SFDX-Hardis quality gate adapter decisions</p> ADR Title Status Date - No ADRs yet - - <p>Proposed ADRs:</p> <ul> <li>Hardis Quality Gates to SARIF Mapping</li> <li>Branch Protection Enforcement Strategy</li> <li>Integration with Native Adapter Results</li> </ul>"},{"location":"docs/adr-index/#7-glassops-scanner-adapter-packagesadaptersscannerdocsadr","title":"7. GlassOps Scanner Adapter (<code>packages/adapters/scanner/docs/adr/</code>)","text":"<p>Static analysis and code scanner adapter decisions</p> ADR Title Status Date - No ADRs yet - - <p>Proposed ADRs:</p> <ul> <li>MegaLinter vs Individual Linters</li> <li>SARIF Aggregation from Multiple Scanners</li> <li>Scanner Priority and Weighting</li> <li>Baseline/Suppression Strategy</li> </ul>"},{"location":"docs/adr-index/#8-glassops-adr-enforcement-adapter-packagestoolsadr-enforcerdocsadr","title":"8. GlassOps ADR Enforcement Adapter (<code>packages/tools/adr-enforcer/docs/adr/</code>)","text":"<p>ADR governance and compliance adapter decisions (Meta-Adapter)</p> ADR Title Status Date - No ADRs yet - - <p>Proposed ADRs:</p> <ul> <li>ADR Detection Strategy</li> <li>Decision Drift Detection</li> <li>Enforcement Mode (Block vs Warn)</li> <li>ADR Coverage Metrics</li> <li>Meta-Governance (Self-Enforcement)</li> </ul> <p>Special Note: This is a meta-adapter that governs the governance process itself. It enforces ADR compliance and detects when architectural decisions are missing or violated.</p>"},{"location":"docs/adr-index/#adr-lifecycle","title":"ADR Lifecycle","text":"<pre><code>Proposed \u2192 Accepted \u2192 Deprecated \u2192 Superseded\n</code></pre> <ul> <li>Proposed - Under review, seeking feedback</li> <li>Accepted - Approved and actively implemented</li> <li>Deprecated - No longer recommended, but not yet replaced</li> <li>Superseded - Replaced by a newer ADR</li> </ul>"},{"location":"docs/adr-index/#creating-a-new-adr","title":"Creating a New ADR","text":""},{"location":"docs/adr-index/#1-choose-the-right-location","title":"1. Choose the Right Location","text":"<ul> <li>Platform-wide \u2192 <code>glassops/docs/adr/</code></li> <li>Runtime-specific \u2192 <code>glassops-runtime/docs/adr/</code></li> <li>Control plane \u2192 <code>glassops-control-plane/docs/adr/</code></li> <li>Protocol changes \u2192 <code>glassspec/docs/adr/</code></li> </ul>"},{"location":"docs/adr-index/#2-use-the-template","title":"2. Use the Template","text":"<pre><code># ADR [NUMBER]: [Title]\n\n**Status:** [Proposed|Accepted|Deprecated|Superseded]\n**Date:** YYYY-MM-DD\n**Context:** [What triggered this decision]\n\n## Context\n\n[Describe the forces at play: technical, political, social, project]\n\n## Decision\n\n[State the decision clearly]\n\n## Rationale\n\n[Explain why this decision was made]\n\n## Consequences\n\n### Positive\n\n- [Benefits]\n\n### Negative\n\n- [Costs, risks]\n\n### Neutral\n\n- [Side effects]\n\n## Alternatives Considered\n\n[What other options were evaluated and why they were rejected]\n\n## Related ADRs\n\n- [Links to related decisions]\n\n---\n\n**Author:** [Name]\n**Status:** [Current status]\n</code></pre>"},{"location":"docs/adr-index/#3-number-sequentially","title":"3. Number Sequentially","text":"<ul> <li>Each project maintains its own sequence</li> <li>Use leading zeros (001, 002, etc.)</li> <li>Never reuse numbers</li> </ul>"},{"location":"docs/adr-index/#4-update-this-index","title":"4. Update This Index","text":"<p>After creating an ADR, add it to the appropriate section above.</p>"},{"location":"docs/adr-index/#key-decisions-by-theme","title":"Key Decisions by Theme","text":""},{"location":"docs/adr-index/#governance-protocol","title":"Governance &amp; Protocol","text":"<ul> <li>ADR-002: GitHub Execution Authority</li> <li>ADR-003: Additive Governance</li> <li>ADR-007: Protocol Supremacy Enforcement</li> </ul>"},{"location":"docs/adr-index/#architecture-structure","title":"Architecture &amp; Structure","text":"<ul> <li>ADR-008: Federated Documentation Structure</li> <li>ADR-011: Monorepo Strategy</li> <li>ADR-009: The 8/10 vs 10/10 Bridge Strategy</li> </ul>"},{"location":"docs/adr-index/#contracts-standards","title":"Contracts &amp; Standards","text":"<ul> <li>ADR-004: Schema Contract Config</li> <li>ADR-006: Documentation as Governed Artifact</li> <li>ADR-010: Identity Contract</li> </ul>"},{"location":"docs/adr-index/#adr-best-practices","title":"ADR Best Practices","text":""},{"location":"docs/adr-index/#do","title":"Do","text":"<p>\u2705 Write ADRs when making significant decisions - Architectural impact, costly to change, affects multiple teams</p> <p>\u2705 Keep them concise - 1-2 pages maximum</p> <p>\u2705 Document alternatives - Show you considered trade-offs</p> <p>\u2705 Update status - Mark as Deprecated/Superseded when appropriate</p> <p>\u2705 Link related ADRs - Show evolution of thinking</p>"},{"location":"docs/adr-index/#dont","title":"Don't","text":"<p>\u274c Don't document implementation details - ADRs are decisions, not code</p> <p>\u274c Don't rewrite history - Keep old ADRs as historical record</p> <p>\u274c Don't delete ADRs - Mark as Superseded instead</p> <p>\u274c Don't wait too long - Write ADR when decision is fresh</p>"},{"location":"docs/adr-index/#questions","title":"Questions?","text":"<ul> <li>Platform ADRs: See docs/adr/</li> <li>Contributing: See CONTRIBUTING.md</li> <li>Discussion: GitHub Discussions</li> </ul> <p>Last Updated: 2026-01-24 Maintainer: Ryan Bumstead (@rdbumstead)</p>"},{"location":"docs/doc-map/","title":"Documentation Map","text":"<p>GlassOps Federated Documentation Index</p>"},{"location":"docs/doc-map/#discovery-central","title":"\ud83e\udded Discovery (Central)","text":"<p>These documents live here (<code>docs/</code>) and guide you through the system.</p> Document Purpose Vision The \"Why\" and \"Strategy\". Architecture The \"System Design\" and patterns. Platform Reference The \"API Specs\" and interfaces."},{"location":"docs/doc-map/#implementation-federated","title":"\ud83d\udee0\ufe0f Implementation (Federated)","text":"Component Documentation Authority Protocol <code>packages/glassspec/README.md</code> <code>/adr</code> Runtime <code>packages/runtime/README.md</code> <code>/adr</code> Control Plane <code>packages/control-plane/README.md</code> <code>/adr</code> Native Adapter <code>packages/adapters/native/README.md</code> <code>/adr</code>"},{"location":"docs/doc-map/#quick-links","title":"\ud83d\udd17 Quick Links","text":"<ul> <li>GitHub Repo</li> <li>Discussions</li> </ul>"},{"location":"docs/scripts-build-docs/","title":"Documentation Build Process: <code>build-docs.py</code>","text":"<p>This document details the functionality of the <code>build-docs.py</code> script, which automates the generation of documentation for the Glassops project. The script prepares source files, configures the MkDocs documentation generator, and builds the final static site.</p>"},{"location":"docs/scripts-build-docs/#overview","title":"Overview","text":"<p>The script\u2019s primary function is to take source documentation files, configure them for MkDocs, and generate a static website hosted in the <code>glassops_site</code> directory. It handles file copying, configuration adjustments, link fixing, and the execution of the MkDocs build process.  The script is designed to be robust, handling potential file system issues and providing informative output.</p>"},{"location":"docs/scripts-build-docs/#core-functionality","title":"Core Functionality","text":"<ol> <li> <p>Directory Setup:</p> <ul> <li>Defines key directories: <code>root_dir</code> (project root), <code>config_dir</code>, <code>staging_dir</code>, and <code>output_dir</code>.</li> <li>Cleans existing <code>staging_dir</code> and <code>output_dir</code> to ensure a fresh build.  Includes error handling for read-only files on Windows.</li> <li>Creates the <code>staging_dir</code> and a <code>content</code> subdirectory within it.</li> </ul> </li> <li> <p>File Staging:</p> <ul> <li>Copies specified documentation source files and directories (defined in <code>copy_list</code>) from the <code>root_dir</code> to the <code>content</code> directory within <code>staging_dir</code>.</li> <li>Uses an allow-list approach for copying, ensuring only explicitly defined files are included.</li> <li>Ignores <code>.git</code>, <code>node_modules</code>, and <code>.DS_Store</code> directories during the copy process.</li> <li>Logs warnings if source items are not found.</li> <li>Copies the <code>mkdocs.yml</code> configuration file from <code>config_dir</code> to the root of <code>staging_dir</code>.</li> </ul> </li> <li> <p>Configuration Modification:</p> <ul> <li>Modifies the <code>mkdocs.yml</code> file within the <code>staging_dir</code> to:<ul> <li>Set <code>docs_dir</code> to <code>content</code>.</li> <li>Set <code>site_dir</code> to <code>../glassops_site</code> (relative path to the output directory).</li> </ul> </li> </ul> </li> <li> <p>Post-Processing &amp; Link Correction:</p> <ul> <li>ADR Index Generation: If an <code>index.md</code> or <code>README.md</code> does not exist in the <code>docs/adr</code> directory, it automatically generates a <code>README.md</code> file containing an index of all Architectural Decision Records (ADRs).</li> <li>README/README.md Collision Resolution: If both <code>README.md</code> and <code>index.md</code> exist in the same directory, <code>README.md</code> is renamed to <code>overview.md</code> to avoid conflicts.</li> <li>Link Fixing: Iterates through all Markdown (<code>.md</code>) files in the <code>content</code> directory and performs the following:<ul> <li>GitHub Alert Conversion: Converts GitHub-style alerts (e.g., <code>&gt; [!NOTE]</code>) to MkDocs-compatible admonitions (e.g., <code>!!! note</code>).  Supports <code>note</code>, <code>tip</code>, <code>important</code>, <code>warning</code>, and <code>caution</code> alert types.</li> <li>Directory Link Correction:  Corrects links to ADRs to point to <code>README.md</code> within each ADR directory.</li> <li>Legacy Link Fixes: Replaces outdated links to <code>index.md</code> with <code>README.md</code>.</li> </ul> </li> </ul> </li> <li> <p>MkDocs Build Execution:</p> <ul> <li>Executes the <code>mkdocs build</code> command within the <code>staging_dir</code> to generate the static site.</li> <li>Captures and prints the standard output and standard error from the <code>mkdocs build</code> process for debugging purposes.</li> <li>Exits with a non-zero exit code if the build fails.</li> </ul> </li> </ol>"},{"location":"docs/scripts-build-docs/#dependencies","title":"Dependencies","text":"<ul> <li>Python 3.6 or higher</li> <li>MkDocs</li> <li><code>pathlib</code> (standard library)</li> <li><code>shutil</code> (standard library)</li> <li><code>subprocess</code> (standard library)</li> <li><code>re</code> (standard library)</li> </ul>"},{"location":"docs/scripts-build-docs/#error-handling","title":"Error Handling","text":"<p>The script includes error handling for:</p> <ul> <li>Read-only files on Windows during directory cleanup.</li> <li>Missing source files during the staging process.</li> <li>Errors during Markdown file processing.</li> <li>Failures during the <code>mkdocs build</code> process.</li> </ul>"},{"location":"docs/scripts-build-docs/#output","title":"Output","text":"<p>The generated documentation website is located in the <code>glassops_site</code> directory. The script provides informative output to the console during each stage of the process, including warnings and error messages.</p>"},{"location":"docs/vision/","title":"GlassOps Vision: Universal Governance Protocol","text":"<p>\"GlassOps governs outcomes, not implementations.\"</p> <p>Version: 2.0 Status: Strategic Authority</p>"},{"location":"docs/vision/#1-the-core-question","title":"1. The Core Question","text":"<p>Most DevOps systems ask only one question:</p> <p>\"Did the deployment succeed?\"</p> <p>GlassOps asks the harder question:</p> <p>\"Should this code exist in production?\"</p> <p>Execution success does not imply architectural health.</p>"},{"location":"docs/vision/#2-the-problem-governance-fragmentation","title":"2. The Problem: Governance Fragmentation","text":"<p>Organizations use dozens of tools (SonarQube, Terraform, Salesforce), but they don't talk to each other.</p> <ul> <li>No Correlation: A code change causes an alert, but you can't prove it.</li> <li>Vendor Lock-in: Switching tools means rewriting compliance rules.</li> <li>Black Boxes: Deployment logic is hidden in proprietary platforms.</li> </ul>"},{"location":"docs/vision/#3-the-solution-governance-as-a-protocol","title":"3. The Solution: Governance as a Protocol","text":"<p>GlassOps is not a product; it is a Universal Governance Protocol.</p> <p>It decouples Policy (The Brain) from Execution (The Muscle).</p> <ul> <li>Policy is defined once (Github, Config, CMDT).</li> <li>Execution is delegated to pluggable Adapters.</li> <li>Audit is normalized into a standard Deployment Contract.</li> </ul>"},{"location":"docs/vision/#the-layered-contract-model","title":"The Layered Contract Model","text":"<p>We use the right standard for each signal:</p> Layer Standard Purpose 1. Governance SARIF Policy violations (Static Analysis) 2. Telemetry OpenTelemetry Runtime metrics (Time series) 3. Transport CloudEvents Lifecycle state (Event bus)"},{"location":"docs/vision/#4-the-origin-story","title":"4. The Origin Story","text":"<p>Note</p> <p>Born from the pain of \"Successful Deployments\" that destroyed architecture.</p> <p>We hired brilliant consultants. They deployed successfully every week. Two years later, we had 5 triggers per object and SOQL in loops. We realized that we couldn't automate safely because we couldn't enforce invariants.</p> <p>GlassOps exists to enforce Architectural Invariants (e.g., \"One Trigger Per Object\") before execution is permitted.</p>"},{"location":"docs/vision/#5-strategy-the-810-vision","title":"5. Strategy: The 8/10 Vision","text":"<p>We are mostly focused on the 8/10 Vision (Months 0-18):</p> <ul> <li>Scope: Salesforce-first.</li> <li>Authority: GitHub Actions.</li> <li>Goal: Prove the protocol works in production.</li> </ul> <p>We effectively ignore the \"10/10 Vision\" (K8s Controller, Multi-Cloud) until the 8/10 goal is met. This constraint is deliberate.</p> <p>Next Steps:</p> <ul> <li>See Architecture for how it works.</li> </ul>"},{"location":"docs/adr/","title":"Platform ADRs","text":"<p>Index of Architectural Decision Records for the GlassOps Platform:</p> <ul> <li>001-system-api-primitive</li> <li>002-github-execution-authority</li> <li>003-additive-governance</li> <li>004-schema-contract-config</li> <li>005-control-plane-architecture</li> <li>006-documentation-as-governed-artifact</li> <li>007-protocol-supremacy-enforcement</li> <li>008-federated-documentation-structure</li> <li>009-8-10-vs-10-10-bridge-strategy</li> <li>010-identity-contract</li> <li>011-monorepo-strategy</li> </ul>"},{"location":"docs/adr/001-system-api-primitive/","title":"ADR-001: glassops-runtime as System API Primitive","text":"<p>Date: 2026-01-19 Status: Accepted Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/001-system-api-primitive/#context","title":"Context","text":"<p>Salesforce Actions on the GitHub Marketplace vary wildly in scope, often mixing CLI installation, authentication, and deployment logic. This creates coupling and maintenance burdens.</p>"},{"location":"docs/adr/001-system-api-primitive/#decision","title":"Decision","text":"<p>We define <code>glassops-runtime</code> as a 'System API Primitive' - a foundational layer with a strictly limited scope:</p> <ol> <li>Install CLI</li> <li>Authenticate (JWT/SfdxUrl)</li> <li>Validate Environment (Invariants)</li> </ol> <p>It provides stable outputs (org_id, instance_url) but enforces zero policy.</p>"},{"location":"docs/adr/001-system-api-primitive/#consequences","title":"Consequences","text":"<p>Positive:</p> <ul> <li>Reusable workflows (Level 2) can build ANY policy on top of this stable foundation.</li> </ul> <p>Negative:</p> <ul> <li>Requires a second layer (workflows) to do anything useful (like deploy).</li> </ul>"},{"location":"docs/adr/001-system-api-primitive/#mitigation","title":"Mitigation","text":"<ul> <li>Provide robust reusable workflow templates.</li> </ul>"},{"location":"docs/adr/001-system-api-primitive/#future-evolution-v4-roadmap","title":"Future Evolution (v4 Roadmap)","text":"<p>Concept: The \"SAPI Consolidator\" Pattern</p> <p>As the platform matures, <code>glassops-runtime@v4</code> will evolve from a monolithic JavaScript action into a Composite Action that orchestrates smaller, atomic primitives.</p> <p>Proposed Structure:</p> <ul> <li>Wrapper: <code>glassops-platform/glassops-runtime@v1</code> (Maintains the stable API Contract)</li> <li>Atomic Primitive A: <code>glassops-platform/action-install-cli</code> (Binary management)</li> <li>Atomic Primitive B: <code>glassops-platform/action-auth-jwt</code> (Identity management)</li> <li>Atomic Primitive C: <code>glassops-platform/action-resolve-context</code> (Org introspection)</li> </ul> <p>Benefit: This allows us to patch authentication logic (e.g., if Salesforce changes <code>auth:jwt:grant</code>) without risking regressions in CLI installation logic, while consumers (Adapters) see no breaking changes.</p>"},{"location":"docs/adr/001-system-api-primitive/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/002-github-execution-authority/","title":"ADR-002: GitHub as Execution Authority","text":"<p>Date: 2026-01-19 Status: Accepted Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/002-github-execution-authority/#context","title":"Context","text":"<p>Traditional Salesforce DevOps tools (Gearset, Copado) use Salesforce as the execution authority. This creates a single point of failure.</p>"},{"location":"docs/adr/002-github-execution-authority/#decision","title":"Decision","text":"<p>GitHub will be the final execution authority. Salesforce provides governance but cannot block GitHub from executing workflows.</p>"},{"location":"docs/adr/002-github-execution-authority/#consequences","title":"Consequences","text":"<p>Positive:</p> <ul> <li>Deployments continue during Salesforce outages</li> <li>Break-glass operations don't require Salesforce access</li> <li>Higher uptime (GitHub Actions 99.95% vs Salesforce 99.9%)</li> </ul> <p>Negative:</p> <ul> <li>GitHub outage = deployment outage</li> <li>Requires DevOps engineers to have GitHub UI access</li> </ul>"},{"location":"docs/adr/002-github-execution-authority/#mitigation","title":"Mitigation","text":"<ul> <li>Maintain local Salesforce CLI access</li> <li>Document break-glass runbooks</li> <li>Cross-train team on GitHub Actions UI</li> </ul>"},{"location":"docs/adr/002-github-execution-authority/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/003-additive-governance/","title":"ADR-003: Additive Governance Model","text":"<p>Date: 2026-01-19 Status: Accepted Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/003-additive-governance/#context","title":"Context","text":"<p>We need to govern deployments (check coverage, freeze windows) without creating 'lowest common denominator' policies that block high-performing teams.</p>"},{"location":"docs/adr/003-additive-governance/#decision","title":"Decision","text":"<p>We adopt an Additive Governance model. GitHub Environment config is the Floor. devops-config.json is the Team Standard. Salesforce CMDT is the Org-Specific Ceiling/Addition.</p>"},{"location":"docs/adr/003-additive-governance/#consequences","title":"Consequences","text":"<p>Positive:</p> <ul> <li>Governance can only RAISE quality standards, never lower them below the platform floor.</li> </ul> <p>Negative:</p> <ul> <li>Runtime resolution complexity.</li> </ul>"},{"location":"docs/adr/003-additive-governance/#mitigation","title":"Mitigation","text":"<ul> <li>Clear documentation on precedence logic.</li> </ul>"},{"location":"docs/adr/003-additive-governance/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/004-schema-contract-config/","title":"ADR-004: Schema Contract over YAML Parsing","text":"<p>Date: 2026-01-19 Status: Accepted Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/004-schema-contract-config/#context","title":"Context","text":"<p>Parsing workflow_dispatch YAML files in Apex (Level 3) to build dynamic UI forms is brittle (regex, indentation issues) and prone to breakage.</p>"},{"location":"docs/adr/004-schema-contract-config/#decision","title":"Decision","text":"<p>We enforce a Schema Contract pattern. Inputs must be explicitly defined in Salesforce Custom Metadata (Workflow_Template__mdt). Apex does NOT parse YAML.</p>"},{"location":"docs/adr/004-schema-contract-config/#consequences","title":"Consequences","text":"<p>Positive:</p> <ul> <li>Robustness. Eliminates YAML parsing bugs.</li> <li>Typed inputs in Salesforce.</li> </ul> <p>Negative:</p> <ul> <li>Double maintenance (YAML + CMDT records).</li> </ul>"},{"location":"docs/adr/004-schema-contract-config/#mitigation","title":"Mitigation","text":"<ul> <li>Automation tools to sync YAML inputs to CMDT (future roadmap).</li> </ul>"},{"location":"docs/adr/004-schema-contract-config/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/005-control-plane-architecture/","title":"ADR-005: Control Plane Architecture &amp; Reference Console","text":"<p>Date: 2026-01-19 Status: Accepted Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/005-control-plane-architecture/#overview","title":"Overview","text":"<p>This ADR defines the decoupling of the GlassOps UI from the core protocol, establishing the \"Reference Console\" pattern.</p>"},{"location":"docs/adr/005-control-plane-architecture/#components","title":"Components","text":"<ol> <li>Protocol (Level 2): The governance logic (policy, contracts).</li> <li>Reference Console (Level 3): The optional visualization layer.</li> </ol>"},{"location":"docs/adr/005-control-plane-architecture/#data-flow","title":"Data Flow","text":"<p>Data flows from the Protocol execution (Github Actions) to the Console (Salesforce) via Platform Events, but not vice-versa for execution control.</p>"},{"location":"docs/adr/005-control-plane-architecture/#context","title":"Context","text":"<p>The initial \"Three-Level\" architecture implied that \"Level 3: GlassOps Reference Console\" (the Salesforce UI) was the ultimate destination of the adoption journey. This created friction:</p> <ol> <li>Implication of Necessity: Teams felt they had to install the package to get value.</li> <li>Naming Confusion: \"Manager\" implied it orchestrated deployments (it doesn't; GitHub Actions does).</li> <li>Role Mismatch: DevOps engineers don't want a Salesforce UI; Admins do.</li> </ol>"},{"location":"docs/adr/005-control-plane-architecture/#decision","title":"Decision","text":"<ol> <li>Decoupling: The UI is explicitly defined as an optional \"Level 3\" component, purely for visualization.</li> <li>Renaming: \"GlassOps Manager\" is renamed to \"GlassOps Reference Console\".</li> <li>Role: The Salesforce UI is an optional reference implementation of a control plane consumer, not a required component.</li> </ol>"},{"location":"docs/adr/005-control-plane-architecture/#consequences","title":"Consequences","text":"<p>Positive:</p> <ul> <li>Psychological Safety: Teams can adopt the Protocol (Level 2) without fearing vendor lock-in to the UI.</li> <li>Ecosystem Friendly: Invites 3rd-party vendors (e.g., sfdx-hardis, Copado) to plug into the event stream rather than competing for the glass.</li> <li>Clear Boundaries: Reinforces that GlassOps owns State and Policy, but delegates Execution and UX.</li> </ul> <p>Negative:</p> <ul> <li>Documentation is slightly more abstract (\"Protocol\" vs \"Product\").</li> </ul>"},{"location":"docs/adr/005-control-plane-architecture/#mitigation","title":"Mitigation","text":"<ul> <li>Use \"Three-Level Adoption Model\" to keep the simple \"Walk, Run, Fly\" narrative for beginners, while using \"Control Plane\" for architects.</li> </ul>"},{"location":"docs/adr/005-control-plane-architecture/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/","title":"ADR 006: Documentation as a Governed Artifact","text":"<p>Status: Proposed Date: 2026-01-24 Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#context","title":"Context","text":"<p>GlassOps currently governs:</p> <ul> <li>Code Quality (SARIF findings from static analysis)</li> <li>Deployment Safety (test coverage, validation results)</li> <li>Architecture Decisions (ADR compliance)</li> <li>Runtime Risk (OpenTelemetry correlation)</li> </ul> <p>Missing: Documentation itself is not treated as a first-class governed signal.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#the-reframed-question","title":"The Reframed Question","text":"<p>We're not asking: \"Should GlassOps generate documentation?\"</p> <p>We're asking: \"Should documentation be a governed, enforceable, first-class signal in GlassOps?\"</p> <p>Once you see it that way, GlassOps Knowledge + MkDocs aren't tooling choices \u2014 they're reference implementations of a capability.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#decision","title":"Decision","text":"<p>GlassOps will treat documentation as a governed artifact, subject to the same protocol enforcement as code quality, deployments, and architecture.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#core-principle","title":"Core Principle","text":"<p>Most platforms consume documentation. GlassOps governs it.</p> <p>Documentation becomes the 9th substrate (joining Code, Cloud, Network, Analytics, IaC, Databases, Monitoring, Deployments).</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#architecture-docs-as-a-first-class-signal","title":"Architecture: Docs as a First-Class Signal","text":"<pre><code>Code / IaC / Config\n        \u2502\n        \u25bc\nGlassOps Knowledge (AST + Auto Docs)\n        \u2502\n        \u25bc\nStructured Doc Artifacts\n        \u2502\n        \u25bc\nGlassOps Documentation Adapter\n        \u2502\n        \u25bc\nProtocol Engine\n        \u2502\n        \u251c\u2500 Enforce coverage\n        \u251c\u2500 Detect drift\n        \u251c\u2500 Gate deployments\n        \u2514\u2500 Correlate with runtime risk\n        \u2502\n        \u25bc\nMkDocs (Curated Projection)\n</code></pre> <p>Key Insight: MkDocs is not \"the docs site\". It's the compiled output of governed documentation.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#concrete-product-features","title":"Concrete Product Features","text":""},{"location":"docs/adr/006-documentation-as-governed-artifact/#1-documentation-coverage-enforcement","title":"1. Documentation Coverage Enforcement","text":"<p>GlassOps enforces rules like:</p> <p>Every deployable unit must have:</p> <ul> <li>Architecture overview</li> <li>Ownership</li> <li>Risk classification</li> </ul> <p>Public APIs require:</p> <ul> <li>Versioned contract docs</li> <li>Breaking-change notices</li> </ul> <p>Regulated repos require:</p> <ul> <li>ADRs</li> <li>Data handling docs</li> </ul> <p>Flow:</p> <ul> <li>RepoAgent \u2192 detects</li> <li>GlassOps \u2192 enforces</li> <li>MkDocs \u2192 proves compliance</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#2-documentation-drift-detection","title":"2. Documentation Drift Detection","text":"<p>Problem: This is extremely under-served in tooling.</p> <p>Examples GlassOps can detect:</p> <ul> <li>\u274c Code changed, docs didn't</li> <li>\u274c Architecture diagram references deleted modules</li> <li>\u274c README says \"sync\", code is async</li> <li>\u274c Maturity level claims don't match repo reality</li> </ul> <p>Output:</p> <p>\"This system claims Level 3 governance but behaves like Level 1.\"</p> <p>That's gold.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#3-governance-aware-documentation-views","title":"3. Governance-Aware Documentation Views","text":"<p>MkDocs becomes dynamic by governance state:</p> <ul> <li>Show warnings for non-compliant sections</li> <li>Highlight \"out of protocol\" components</li> <li>Link runtime incidents \u2192 docs sections</li> <li>Surface risk levels inline</li> </ul> <p>Nobody else does this.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#4-audit-compliance-without-the-theater","title":"4. Audit &amp; Compliance Without the Theater","text":"<p>Instead of:</p> <ul> <li>Word docs</li> <li>Confluence sprawl</li> <li>Manual audits</li> </ul> <p>You get:</p> <ul> <li>Versioned docs</li> <li>Deterministic builds</li> <li>Policy-backed guarantees</li> </ul> <p>GlassOps can say:</p> <p>\"This documentation set passed governance checks at commit X.\"</p> <p>That's audit-grade.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#5-documentation-as-an-execution-gate","title":"5. Documentation as an Execution Gate","text":"<p>This is where it gets spicy \ud83d\udd25</p> <p>Examples:</p> <ul> <li>\u274c No docs \u2192 no deploy</li> <li>\u26a0\ufe0f Docs incomplete \u2192 deploy to lower environment only</li> <li>\u26a0\ufe0f Docs stale \u2192 require override</li> <li>\u2705 Docs updated \u2192 unlock fast path</li> </ul> <p>Documentation literally controls velocity.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#why-repoagent-mkdocs-specifically","title":"Why RepoAgent + MkDocs Specifically","text":""},{"location":"docs/adr/006-documentation-as-governed-artifact/#repoagent","title":"RepoAgent","text":"<ul> <li>Objective signal generator</li> <li>AST-aware</li> <li>Language-agnostic trajectory</li> <li>Automatable</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#mkdocs","title":"MkDocs","text":"<ul> <li>Deterministic</li> <li>Static</li> <li>Versionable</li> <li>CI-native</li> <li>No runtime dependencies</li> </ul> <p>Together they form: The reference pipeline for governable documentation.</p> <p>You're not locking users in \u2014 you're showing them what \"good\" looks like.</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#positioning","title":"Positioning","text":""},{"location":"docs/adr/006-documentation-as-governed-artifact/#dont-say","title":"\u274c Don't Say:","text":"<p>\"GlassOps uses RepoAgent and MkDocs\"</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#do-say","title":"\u2705 Do Say:","text":"<p>\"GlassOps governs documentation pipelines. RepoAgent and MkDocs are supported reference implementations.\"</p> <p>This keeps you:</p> <ul> <li>Vendor-neutral</li> <li>Extensible</li> <li>Architecturally credible</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#implementation-strategy","title":"Implementation Strategy","text":""},{"location":"docs/adr/006-documentation-as-governed-artifact/#phase-1-define-the-documentation-adapter-interface","title":"Phase 1: Define the Documentation Adapter Interface","text":"<p>Create <code>DOCUMENTATION_ADAPTER.md</code> in <code>glassspec/</code>:</p> <pre><code>apiVersion: glassops.io/v1alpha1\nkind: DocumentationAdapter\nspec:\n    input:\n        - type: markdown\n          location: docs/\n        - type: auto-generated\n          generator: repoagent\n          source: src/\n\n    validation:\n        - coverage: required\n          sections: [architecture, ownership, api]\n        - drift_detection: true\n          compare_with: code_ast\n        - adrs: required\n          when: architectural_changes\n\n    output:\n        format: sarif\n        findings:\n            - rule: DOC_COVERAGE\n            - rule: DOC_DRIFT\n            - rule: DOC_STALE\n</code></pre>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#phase-2-build-reference-implementation","title":"Phase 2: Build Reference Implementation","text":"<p>Repo: <code>glassops-documentation-adapter</code></p> <ul> <li>Integrates RepoAgent for auto-generation</li> <li>Validates against documentation policies</li> <li>Emits SARIF contract</li> <li>Optionally builds MkDocs site</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#phase-3-documentation-governance-policies","title":"Phase 3: Documentation Governance Policies","text":"<p>Add to Policy Store:</p> <pre><code>documentation:\n    coverage:\n        required_sections:\n            - architecture\n            - ownership\n            - risk_classification\n        public_apis: versioned_contracts\n\n    drift:\n        max_staleness_days: 30\n        require_update_on_code_change: true\n\n    gates:\n        no_docs: block_deployment\n        incomplete_docs: restrict_to_dev\n        stale_docs: require_override\n</code></pre>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#benefits","title":"Benefits","text":"<ol> <li>Governance Consistency - Docs treated like code</li> <li>Audit Trail - Provable compliance</li> <li>Velocity Control - Bad docs = blocked deploys</li> <li>Drift Detection - Code/docs sync enforced</li> <li>Competitive Differentiation - Nobody else governs docs at protocol level</li> </ol>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#risks-mitigations","title":"Risks &amp; Mitigations","text":""},{"location":"docs/adr/006-documentation-as-governed-artifact/#risk-1-documentation-feels-like-busywork","title":"Risk 1: Documentation Feels Like Busywork","text":"<p>Mitigation: Auto-generate baseline with RepoAgent, humans curate</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#risk-2-hard-coded-tool-assumptions","title":"Risk 2: Hard-Coded Tool Assumptions","text":"<p>Mitigation: Define adapter interface, support multiple generators</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#risk-3-overhead-without-value","title":"Risk 3: Overhead Without Value","text":"<p>Mitigation: Start with optional enforcement, prove value before mandating</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"docs/adr/006-documentation-as-governed-artifact/#alternative-1-docs-stay-outside-governance","title":"Alternative 1: Docs Stay Outside Governance","text":"<p>Rejected: Misses huge value opportunity, docs drift leads to incidents</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#alternative-2-hard-code-mkdocs","title":"Alternative 2: Hard-Code MkDocs","text":"<p>Rejected: Violates adapter philosophy, creates vendor lock-in</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#alternative-3-manual-doc-review-only","title":"Alternative 3: Manual Doc Review Only","text":"<p>Rejected: Doesn't scale, loses automation benefits</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#consequences","title":"Consequences","text":""},{"location":"docs/adr/006-documentation-as-governed-artifact/#positive","title":"Positive","text":"<ul> <li>\u2705 Documentation becomes enforceable</li> <li>\u2705 Audit compliance provable</li> <li>\u2705 Drift detection automated</li> <li>\u2705 9th substrate adds strategic value</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#negative","title":"Negative","text":"<ul> <li>\u26a0\ufe0f Requires Documentation Adapter development</li> <li>\u26a0\ufe0f Teams must adapt to doc-gated deployments</li> <li>\u26a0\ufe0f Tooling ecosystem expansion</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#neutral","title":"Neutral","text":"<ul> <li>\ud83d\udcdd RepoAgent and MkDocs become reference implementations</li> <li>\ud83d\udcdd Documentation governance optional but recommended</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#next-steps","title":"Next Steps","text":"<ol> <li>Create <code>glassspec/DOCUMENTATION_ADAPTER.md</code> - Define the interface</li> <li>Build POC - RepoAgent \u2192 SARIF \u2192 Policy Engine</li> <li>Add Documentation Policies - Coverage, drift, staleness rules</li> <li>Document in Vision - Add docs governance to vision/technical.md</li> <li>Reference Implementation - Build glassops-documentation-adapter</li> </ol>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-001: System API Primitive</li> <li>ADR-003: Additive Governance</li> <li>ADR-004: Schema Contract Config</li> </ul>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#references","title":"References","text":"<ul> <li>OASIS SARIF 2.1.0</li> <li>RepoAgent Documentation</li> <li>MkDocs</li> <li>GlassOps Protocol</li> </ul> <p>Author: Ryan Bumstead Reviewers: TBD Implementation: Proposed for v2.0</p>"},{"location":"docs/adr/006-documentation-as-governed-artifact/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/","title":"ADR 007: Protocol Supremacy Enforcement in Adapter Development","text":"<p>Status: Accepted Date: 2026-01-24 Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#context","title":"Context","text":"<p>The core value proposition of GlassOps is the Layered Contract Model, where governance decisions are made against standard, interoperable schemas (SARIF, CloudEvents).</p> <p>Analysis of the adapter ecosystem revealed a risk of schema fragmentation: allowing adapters to define custom output formats weakens the governance layer's ability to enforce universal policy. To ensure long-term interoperability and protocol integrity, the documentation must strictly enforce the use of canonical, versioned contracts over ad-hoc JSON structures.</p>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#the-strategic-gap","title":"The Strategic Gap","text":"<p>Custom Schema vs. Protocol Standard:</p> <p>Teaching developers to build adapters with custom schemas creates a \"Tower of Babel\" effect where the Policy Engine cannot reliably interpret findings across different tools. Aligning all adapters to SARIF 2.1.0 is necessary to unlock the platform's ability to normalize and govern diverse signals.</p>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#decision","title":"Decision","text":"<p>The Manual (glassops/docs/) MUST defer to the Protocol (glassspec/).</p> <p>All adapter development documentation will:</p> <ol> <li>Use SARIF 2.1.0 as defined in <code>glassspec/adapter-interface.md</code></li> <li>Link to the Protocol for authoritative schema definitions</li> <li>Reference Anti-Patterns from <code>glassspec/protocol.md</code> for scope boundaries</li> <li>Emit contracts to <code>.glassops/glassops-contract.sarif.json</code> (not custom filenames)</li> </ol>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#protocol-supremacy-hierarchy","title":"Protocol Supremacy Hierarchy","text":"<pre><code>glassspec/                       [LAW - Immutable, Versioned]\n  \u251c\u2500\u2500 protocol.md               [The Protocol definition]\n  \u2514\u2500\u2500 adapter-interface.md      [Canonical SARIF schema]\n        \u2502\n        \u25bc\nglassops/docs/                   [MANUAL - Defers to Law]\n  \u2514\u2500\u2500 guides/adapter-development.md  [Must comply with Protocol]\n</code></pre> <p>When in conflict: <code>glassspec/</code> is always correct.</p>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#rationale","title":"Rationale","text":""},{"location":"docs/adr/007-protocol-supremacy-enforcement/#why-this-matters","title":"Why This Matters","text":"<ol> <li>Protocol Integrity - The Layered Contract Model depends on SARIF conformance</li> <li>Interoperability - Tools expect standard SARIF, not custom schemas</li> <li>Governance Enforcement - Policy Engine parses SARIF results, not custom JSON</li> <li>Audit Trail - SARIF contracts are immutable governance records</li> </ol>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#why-custom-schemas-are-dangerous","title":"Why Custom Schemas Are Dangerous","text":"<ul> <li>Schema Proliferation - Every adapter invents its own format</li> <li>Parser Fragmentation - Governance layer can't normalize findings</li> <li>Protocol Violation - Breaks the Layered Contract Model</li> <li>Ecosystem Confusion - Developers don't know which schema to use</li> </ul>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#implementation","title":"Implementation","text":""},{"location":"docs/adr/007-protocol-supremacy-enforcement/#changes-made-to-adapter-developmentmd","title":"Changes Made to adapter-development.md","text":"<ol> <li> <p>Added Protocol Supremacy Warning:</p> <p>```markdown</p> </li> </ol> <p>Important</p> <p>Protocol Supremacy: All adapters MUST emit SARIF 2.1.0 as defined in adapter-interface.md. Do NOT invent custom schemas. ```</p> <ol> <li> <p>Replaced Custom Schema with SARIF 2.1.0:</p> <ul> <li>Removed custom JSON structure</li> <li>Added minimal compliant SARIF example</li> <li>Updated all code examples to emit SARIF</li> </ul> </li> <li> <p>Added Mapping Table:</p> <ul> <li>Tool Concept \u2192 SARIF Field mappings</li> <li>Deployment metadata \u2192 <code>invocation.properties.glassops</code></li> <li>Governance findings \u2192 <code>results[]</code> array</li> </ul> </li> <li> <p>Added \"What Goes in SARIF vs. What Doesn't\":</p> <ul> <li>\u2705 DO: Policy violations, test failures, coverage findings</li> <li>\u274c DON'T: CPU metrics (use OTel), logs (use OTel Logs), trace IDs (use CloudEvents)</li> <li>Links to Protocol Anti-Patterns section</li> </ul> </li> <li> <p>Updated Integration Logic:</p> <ul> <li>Check <code>invocation.executionSuccessful</code> (not custom <code>status</code> field)</li> <li>Filter <code>results</code> for errors (not custom <code>quality.coverage.met</code>)</li> <li>Extract from <code>invocation.properties.glassops.deploymentId</code></li> </ul> </li> </ol>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#consequences","title":"Consequences","text":""},{"location":"docs/adr/007-protocol-supremacy-enforcement/#positive","title":"Positive","text":"<ul> <li>\u2705 Developers build Protocol-compliant adapters</li> <li>\u2705 Documentation reinforces glassspec/ authority</li> <li>\u2705 Clear guidance on SARIF scope boundaries</li> <li>\u2705 Interoperability with SARIF tooling ecosystem</li> </ul>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#negative","title":"Negative","text":"<ul> <li>\u26a0\ufe0f More verbose examples (SARIF is larger than custom JSON)</li> <li>\u26a0\ufe0f Developers must learn SARIF structure</li> <li>\u26a0\ufe0f Existing adapters may be non-compliant (requires audit)</li> </ul>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#neutral","title":"Neutral","text":"<ul> <li>\ud83d\udcdd Manual must be updated when Protocol changes</li> <li>\ud83d\udcdd Reinforces separation between Law (glassspec/) and Guide (docs/)</li> </ul>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#validation","title":"Validation","text":""},{"location":"docs/adr/007-protocol-supremacy-enforcement/#how-to-verify-compliance","title":"How to Verify Compliance","text":"<pre><code># Validate SARIF schema\njq -e '.version == \"2.1.0\"' .glassops/glassops-contract.sarif.json\njq -e '.$schema | contains(\"sarif-2.1.0\")' .glassops/glassops-contract.sarif.json\n\n# Validate structure\njq -e '.runs[0].tool.driver.name' .glassops/glassops-contract.sarif.json\njq -e '.runs[0].invocations[0].executionSuccessful' .glassops/glassops-contract.sarif.json\n</code></pre>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#future-considerations","title":"Future Considerations","text":""},{"location":"docs/adr/007-protocol-supremacy-enforcement/#potential-next-steps","title":"Potential Next Steps","text":"<ol> <li>Audit Existing Adapters - Check glassops-native, glassops-hardis, glassops-scanner for SARIF compliance</li> <li>Schema Validation - Add automated SARIF schema validation to CI</li> <li>Contract Linter - Create tool to validate SARIF contracts against Protocol</li> <li>Migration Guide - If legacy adapters exist, provide migration path</li> </ol>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-001: System API Primitive</li> <li>ADR-004: Schema Contract Config</li> <li>ADR-006: Documentation as Governed Artifact</li> </ul>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#references","title":"References","text":"<ul> <li>OASIS SARIF 2.1.0 Specification</li> <li>GlassOps Protocol</li> <li>Adapter Interface</li> <li>Adapter Development Guide</li> </ul> <p>Author: Ryan Bumstead Implemented: 2026-01-24 Status: Active</p>"},{"location":"docs/adr/007-protocol-supremacy-enforcement/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/","title":"ADR 008: Federated Documentation Structure","text":"<p>Status: Accepted Date: 2026-01-24 Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/008-federated-documentation-structure/#context","title":"Context","text":"<p>As GlassOps evolves from a conceptual framework to a deployable platform, the documentation architecture must scale to support three distinct audiences: Architects (evaluating the protocol), Implementers (building adapters), and Operators (running the control plane).</p> <p>A flat structure creates friction for these users, mixing high-level philosophy with low-level implementation details. To support the \"Protocol Ecosystem\" vision, the documentation structure must mirror the separation of concerns found in the code itself\u2014creating clear, navigable paths for each stakeholder while maintaining a single source of truth for core principles.</p>"},{"location":"docs/adr/008-federated-documentation-structure/#decision","title":"Decision","text":"<p>Adopt a Federated Documentation Structure with clear separation of concerns:</p>"},{"location":"docs/adr/008-federated-documentation-structure/#7-tier-hierarchy","title":"7-Tier Hierarchy","text":"<pre><code>docs/\n\u251c\u2500\u2500 Tier 1: Entry Points (under 5 min)\n\u2502   \u251c\u2500\u2500 overview.md\n\u2502   \u2514\u2500\u2500 README.md (root)\n\u2502\n\u251c\u2500\u2500 Tier 2: Philosophy &amp; Story (15-20 min)\n\u2502   \u2514\u2500\u2500 philosophy.md  [NEW - Merged vision_v1_legacy + executive-summary]\n\u2502\n\u251c\u2500\u2500 Tier 3: Technical Architecture (30-60 min)\n\u2502   \u2514\u2500\u2500 architecture/\n\u2502       \u251c\u2500\u2500 protocol.md  [NEW - Links to glassspec/]\n\u2502       \u251c\u2500\u2500 current.md   [Future - extracted from vision.md]\n\u2502       \u2514\u2500\u2500 future.md    [Moved from future-architecture.md]\n\u2502\n\u251c\u2500\u2500 Tier 4: Business Vision (30-45 min)\n\u2502   \u2514\u2500\u2500 vision/\n\u2502       \u251c\u2500\u2500 technical.md  [Future - extracted from vision.md]\n\u2502       \u251c\u2500\u2500 business.md   [Future - extracted from vision.md]\n\u2502       \u2514\u2500\u2500 roadmap.md    [Future - extracted from vision.md]\n\u2502\n\u251c\u2500\u2500 Tier 5: Implementation Guides (30+ min)\n\u2502   \u2514\u2500\u2500 guides/\n\u2502       \u251c\u2500\u2500 getting-started.md\n\u2502       \u251c\u2500\u2500 adapter-development.md\n\u2502       \u251c\u2500\u2500 level-3-setup.md\n\u2502       \u2514\u2500\u2500 comparison.md\n\u2502\n\u251c\u2500\u2500 Tier 6: Reference Material\n\u2502   \u2514\u2500\u2500 reference/\n\u2502       \u251c\u2500\u2500 platform-reference.md\n\u2502       \u251c\u2500\u2500 troubleshooting.md\n\u2502       \u251c\u2500\u2500 notifications.md\n\u2502       \u2514\u2500\u2500 governance-without-lockin.md\n\u2502\n\u2514\u2500\u2500 Tier 7: Meta Documentation\n    \u251c\u2500\u2500 doc-map.md\n    \u251c\u2500\u2500 adr/  (Architecture Decision Records)\n    \u2514\u2500\u2500 specs/  (Technical specifications)\n</code></pre>"},{"location":"docs/adr/008-federated-documentation-structure/#rationale","title":"Rationale","text":""},{"location":"docs/adr/008-federated-documentation-structure/#why-federated-structure","title":"Why Federated Structure","text":"<ol> <li> <p>Clear Audience Targeting - Different tiers serve different readers</p> <ul> <li>Entry points for evaluators</li> <li>Philosophy for architects</li> <li>Guides for implementers</li> <li>Reference for operators</li> </ul> </li> <li> <p>Single Source of Truth - No duplicate content</p> <ul> <li>One philosophy document (not three)</li> <li>Clear delineation between guides and reference</li> <li>Protocol authority reinforced</li> </ul> </li> <li> <p>Scalability - Easy to add content without clutter</p> <ul> <li>New guides go in guides/</li> <li>New references go in reference/</li> <li>No flat directory confusion</li> </ul> </li> <li> <p>Protocol Clarity - glassspec/ remains authoritative</p> <ul> <li>architecture/protocol.md links to glassspec/</li> <li>Reinforces Law (Protocol) vs Manual (Docs) separation</li> </ul> </li> </ol>"},{"location":"docs/adr/008-federated-documentation-structure/#why-federated","title":"Why \"Federated\"","text":"<p>The term \"Federated\" reflects the separation of concerns:</p> <ul> <li>Protocol (Law): <code>packages/glassspec/</code> - Immutable, versioned, authoritative</li> <li>Manual (Guide): <code>docs/</code> - Tutorials, examples, implementation</li> <li>Implementations: <code>packages/runtime/</code>, <code>packages/control-plane/</code>, <code>packages/adapters/</code></li> </ul> <p>Each has its own documentation, but all defer to the Protocol.</p>"},{"location":"docs/adr/008-federated-documentation-structure/#implementation","title":"Implementation","text":""},{"location":"docs/adr/008-federated-documentation-structure/#phase-1-core-restructure-completed","title":"Phase 1: Core Restructure (Completed)","text":"<ol> <li>\u2705 Created directory structure (<code>architecture/</code>, <code>vision/</code>, <code>guides/</code>, <code>reference/</code>)</li> <li>\u2705 Created <code>philosophy.md</code> by merging:<ul> <li><code>vision_v1_legacy.md</code> (principles, 8/10 vision, adapter philosophy)</li> <li><code>executive-summary.md</code> (origin story, AI era positioning)</li> </ul> </li> <li>\u2705 Moved files to logical locations:<ul> <li>4 guides \u2192 <code>guides/</code></li> <li>4 references \u2192 <code>reference/</code></li> </ul> </li> <li>\u2705 Created <code>architecture/protocol.md</code> linking to <code>glassspec/</code></li> <li>\u2705 Moved <code>future-architecture.md</code> \u2192 <code>architecture/future.md</code></li> <li>\u2705 Deleted legacy files (<code>vision_v1_legacy.md</code>, <code>executive-summary.md</code>)</li> </ol>"},{"location":"docs/adr/008-federated-documentation-structure/#phase-2-large-file-splitting-future","title":"Phase 2: Large File Splitting (Future)","text":"<p>Large files still in root need splitting:</p> <ul> <li><code>vision.md</code> (1201 lines) \u2192 <code>vision/technical.md</code>, <code>vision/business.md</code>, <code>vision/roadmap.md</code></li> <li><code>architecture.md</code> (1003 lines) \u2192 <code>architecture/current.md</code></li> <li><code>doc-map.md</code> \u2192 Complete rewrite for new structure</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#consequences","title":"Consequences","text":""},{"location":"docs/adr/008-federated-documentation-structure/#positive","title":"Positive","text":"<ul> <li>\u2705 No duplicate content in reorganized files</li> <li>\u2705 Clear purpose for each document</li> <li>\u2705 Logical grouping by audience and type</li> <li>\u2705 Easy navigation with subdirectories</li> <li>\u2705 Protocol authority reinforced</li> <li>\u2705 Scalable for future growth</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#negative","title":"Negative","text":"<ul> <li>\u26a0\ufe0f Existing links may break (need doc-map.md update)</li> <li>\u26a0\ufe0f Learning curve for new structure</li> <li>\u26a0\ufe0f Large files still need splitting (Phase 2 work)</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#neutral","title":"Neutral","text":"<ul> <li>\ud83d\udcdd More directories but clearer organization</li> <li>\ud83d\udcdd Longer file paths but more intuitive</li> <li>\ud83d\udcdd Requires maintenance of directory structure</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#design-principles","title":"Design Principles","text":""},{"location":"docs/adr/008-federated-documentation-structure/#1-clear-ownership","title":"1. Clear Ownership","text":"Document Type Owner Purpose Protocol glassspec/ Law - What MUST be Philosophy docs/philosophy.md Why - Core principles Architecture docs/architecture/ How - Technical implementation Guides docs/guides/ Do - Step-by-step tutorials Reference docs/reference/ Lookup - API specs, troubleshooting"},{"location":"docs/adr/008-federated-documentation-structure/#2-no-duplication","title":"2. No Duplication","text":"<ul> <li>Each concept documented once</li> <li>Cross-links when referencing other docs</li> <li>Philosophy document is single source for principles</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#3-protocol-supremacy","title":"3. Protocol Supremacy","text":"<ul> <li><code>glassspec/</code> is always authoritative</li> <li><code>docs/</code> defers to Protocol</li> <li>architecture/protocol.md reinforces this hierarchy</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#4-audience-first","title":"4. Audience-First","text":"<ul> <li>Tier 1: Quick evaluation (3-5 min)</li> <li>Tier 2: Understand philosophy (15-20 min)</li> <li>Tier 3-4: Technical depth (30-60 min)</li> <li>Tier 5: Implement (30+ min)</li> <li>Tier 6: Operate (reference)</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"docs/adr/008-federated-documentation-structure/#alternative-1-keep-flat-structure","title":"Alternative 1: Keep Flat Structure","text":"<p>Rejected: 17 files in single directory is unmanageable and will only grow</p>"},{"location":"docs/adr/008-federated-documentation-structure/#alternative-2-split-by-topic-eg-governance-deployment-monitoring","title":"Alternative 2: Split by Topic (e.g., governance/, deployment/, monitoring/)","text":"<p>Rejected: Doesn't serve different audiences; creates artificial topic boundaries</p>"},{"location":"docs/adr/008-federated-documentation-structure/#alternative-3-single-mega-document","title":"Alternative 3: Single Mega-Document","text":"<p>Rejected: vision.md at 3000 lines proves this doesn't scale</p>"},{"location":"docs/adr/008-federated-documentation-structure/#alternative-4-wiki-style-with-heavy-cross-linking","title":"Alternative 4: Wiki-Style with Heavy Cross-Linking","text":"<p>Rejected: Requires maintenance of link graph; less discoverable than directory structure</p>"},{"location":"docs/adr/008-federated-documentation-structure/#validation-checklist","title":"Validation Checklist","text":"<ul> <li>[x] No duplicate content between moved files</li> <li>[x] Each file has clear, single purpose</li> <li>[x] Reading paths make sense for different audiences</li> <li>[x] Protocol files (glassspec/) are authoritative and referenced</li> <li>[x] Legacy files deleted</li> <li>[ ] All links updated (Phase 2 - doc-map.md rewrite)</li> <li>[ ] Large files split (Phase 2 - optional)</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#migration-path","title":"Migration Path","text":"<p>For teams with existing documentation:</p> <ol> <li>Audit - Identify overlap and legacy content</li> <li>Categorize - Sort docs into Entry/Philosophy/Architecture/Vision/Guides/Reference</li> <li>Consolidate - Merge duplicate content</li> <li>Move - Relocate to appropriate subdirectories</li> <li>Link - Update cross-references</li> <li>Delete - Remove legacy files</li> <li>Validate - Ensure no broken links</li> </ol>"},{"location":"docs/adr/008-federated-documentation-structure/#future-enhancements","title":"Future Enhancements","text":""},{"location":"docs/adr/008-federated-documentation-structure/#potential-additions","title":"Potential Additions","text":"<ul> <li>docs/tutorials/ - Separate from guides/ for hands-on workshops</li> <li>docs/examples/ - Sample implementations</li> <li>docs/api/ - Auto-generated API documentation</li> <li>docs/diagrams/ - Centralized architecture diagrams</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#automation-opportunities","title":"Automation Opportunities","text":"<ul> <li>Link checker - Validate all cross-references</li> <li>Doc linter - Enforce structure and formatting</li> <li>Auto-generated indexes - Build doc-map.md from metadata</li> <li>Versioning - Tag docs with Protocol version compatibility</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-006: Documentation as Governed Artifact</li> <li>ADR-007: Protocol Supremacy Enforcement</li> </ul>"},{"location":"docs/adr/008-federated-documentation-structure/#references","title":"References","text":"<ul> <li>Divio Documentation System - Inspiration for four-quadrant structure</li> <li>GlassOps Protocol</li> </ul> <p>Author: Ryan Bumstead Implemented: 2026-01-24 Status: Active (Phase 1 Complete)</p>"},{"location":"docs/adr/008-federated-documentation-structure/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/","title":"ADR 009: The 8/10 vs 10/10 Bridge Strategy","text":"<p>Status: Accepted Date: 2026-01-24 Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#context","title":"Context","text":"<p>GlassOps aims to be the \"Universal Control Plane\" (10/10 Vision), but immediate tailored value is required to drive adoption in the Salesforce ecosystem (8/10 Vision).</p> <p>Rather than viewing these as conflicting goals, we recognize them as a strategic progression. The architecture must be designed to deliver immediate, concrete value for Salesforce teams today while laying the immutable foundation (SARIF, OpenTelemetry, CloudEvents) required for the future universal platform. This \"Bridge Strategy\" ensures that every artifact built for the current narrow use case is forward-compatible with the broader long-term vision.</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#the-bifurcation","title":"The Bifurcation","text":"<p>8/10 Vision (Current - 18 months):</p> <ul> <li>Authority: GitHub Actions</li> <li>Model: Event-driven (commit \u2192 webhook)</li> <li>Focus: Salesforce DevOps governance</li> <li>Deployment: Free/low-cost (Vercel, Neon, GitHub Actions)</li> <li>Users: 15-20 production deployments</li> </ul> <p>10/10 Vision (Future - 36+ months):</p> <ul> <li>Authority: Kubernetes Operator</li> <li>Model: Level-triggered (controller reconciliation loop)</li> <li>Focus: Universal multi-substrate governance</li> <li>Deployment: Enterprise Kubernetes clusters</li> <li>Users: Multi-tenant SaaS platform</li> </ul>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#the-conflicts-identified","title":"The Conflicts Identified","text":"<ol> <li>Authority Conflict: GitHub vs Kubernetes as execution authority</li> <li>Identity Gap: No unified identity contract across substrates</li> <li>Scaling Path: No migration playbook from zero-dollar to enterprise</li> <li>Documentation vs Reality: Roadmap inconsistencies</li> </ol>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#decision","title":"Decision","text":"<p>Accept the bifurcation as an intentional architectural evolution, with the Layered Contract Model as the immutable bridge.</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#core-principle","title":"Core Principle","text":"<p>The Contract is the Constant</p> <p>Regardless of which execution authority (GitHub or Kubernetes) orchestrates the deployment, the Layered Contract (SARIF + OTel + CloudEvents) remains the immutable governance record.</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#rationale","title":"Rationale","text":""},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#why-two-timelines-are-necessary","title":"Why Two Timelines Are Necessary","text":"<ol> <li>Market Reality - Salesforce teams need GitHub Actions today, not K8s operators</li> <li>Learning Curve - Building a K8s operator without production usage is academic</li> <li>Revenue Path - 8/10 generates consulting revenue; 10/10 requires venture funding</li> <li>Technical Debt - Better to validate Protocol with real users before committing to K8s</li> </ol>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#why-the-contract-bridges-them","title":"Why the Contract Bridges Them","text":"<p>The Layered Contract provides temporal invariance:</p> <pre><code>GitHub Actions (8/10)         Kubernetes Operator (10/10)\n        \u2502                              \u2502\n        \u25bc                              \u25bc\n    [Adapter]                      [Adapter]\n        \u2502                              \u2502\n        \u25bc                              \u25bc\n Layered Contract  \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550  Layered Contract\n  (SARIF+OTel+CE)   [IDENTICAL]   (SARIF+OTel+CE)\n        \u2502                              \u2502\n        \u25bc                              \u25bc\n  Policy Engine                  Policy Engine\n</code></pre> <p>Key Insight: If both emit identical Layered Contracts, the governance layer doesn't care which orchestrator triggered it.</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#implementation-strategy","title":"Implementation Strategy","text":""},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#phase-1-810-current-months-1-18","title":"Phase 1: 8/10 (Current - Months 1-18)","text":"<p>Goal: Validate Protocol with real Salesforce users</p> <p>Architecture:</p> <pre><code>Execution Authority: GitHub Actions\nAdapters: glassops-native, glassops-hardis\nContract Store: GitHub Artifacts (S3 later)\nPolicy Engine: JavaScript (serverless)\nUI: Optional Salesforce Console\nDeployment: Zero-dollar stack (Neon, Vercel)\n</code></pre> <p>Outcomes:</p> <ul> <li>15-20 production deployments</li> <li>Validated SARIF schema</li> <li>Proven adapter interface</li> <li>Real-world policy patterns</li> <li>Consulting revenue</li> </ul>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#bridge-phase-hybrid-months-19-24","title":"Bridge Phase: Hybrid (Months 19-24)","text":"<p>Goal: Decouple Protocol from GitHub-specific assumptions</p> <p>Architecture:</p> <pre><code>Execution Authority: GitHub Actions OR Kubernetes\nAdapters: Same adapters work in both modes\nContract Store: S3/GCS (cloud-agnostic)\nPolicy Engine: Go microservice (can run anywhere)\nUI: API-first (UI is projection)\nDeployment: Optional K8s for policy engine\n</code></pre> <p>Key Migrations:</p> <ol> <li>Policy Engine: JavaScript \u2192 Go microservice</li> <li>Contract Store: GitHub Artifacts \u2192 S3/GCS</li> <li>Identity: Add Identity Contract abstraction</li> <li>Adapters: Make substrate-agnostic (via env vars)</li> </ol>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#phase-2-1010-months-25","title":"Phase 2: 10/10 (Months 25+)","text":"<p>Goal: Universal governance control plane</p> <p>Architecture:</p> <pre><code>Execution Authority: Kubernetes Operator\nAdapters: CRD-based adapter resources\nContract Store: TimescaleDB (queryable history)\nPolicy Engine: Operator controller\nUI: Next.js dashboard (multi-tenant)\nDeployment: Enterprise K8s (multi-cluster)\n</code></pre> <p>New Capabilities:</p> <ul> <li>Multi-substrate beyond Salesforce</li> <li>Level-triggered reconciliation</li> <li>Multi-tenant SaaS</li> <li>Advanced correlation engine</li> <li>Glass Language DSL</li> </ul>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#addressing-the-conflicts","title":"Addressing the Conflicts","text":""},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#1-authority-conflict-github-vs-kubernetes","title":"1. Authority Conflict (GitHub vs Kubernetes)","text":"<p>Resolution: The authority changes, but the contract doesn't.</p> <p>Implementation:</p> <pre><code># Phase 8/10: GitHub Actions\non: [push]\nsteps:\n    - name: Deploy via Adapter\n      run: glassops-native-adapter deploy\n    # Emits: .glassops/glassops-contract.sarif.json\n\n    - name: Enforce Policy\n      run: glassops policy enforce .glassops/glassops-contract.sarif.json\n</code></pre> <pre><code># Phase 10/10: Kubernetes Operator\napiVersion: governance.glassops.io/v1\nkind: Deployment\nspec:\n    adapter: glassops-native-adapter\n    target: salesforce-prod\n# Controller reconciles, emits SARIF to TimescaleDB\n</code></pre> <p>Bridge: Both emit identical SARIF. Policy engine doesn't know (or care) which triggered it.</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#2-identity-gap","title":"2. Identity Gap","text":"<p>Problem: \"GitHub User\" \u2260 \"Salesforce User\" \u2260 \"K8s Service Account\"</p> <p>Resolution: Create Identity Contract (ADR-010 to be written)</p> <p>Proposal:</p> <pre><code>{\n    \"identity\": {\n        \"subject\": \"alice@company.com\",\n        \"provider\": \"github|salesforce|kubernetes\",\n        \"provider_id\": \"github:alice|sf:005...|k8s:sa:...\",\n        \"roles\": [\"developer\", \"deployer\"],\n        \"authorization\": {\n            \"can_deploy\": true,\n            \"can_override\": false\n        }\n    }\n}\n</code></pre> <p>Bridge: SARIF <code>invocations[].properties.glassops.identity</code> field works in both modes.</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#3-scaling-path-zero-dollar-enterprise","title":"3. Scaling Path (Zero-Dollar \u2192 Enterprise)","text":"<p>Problem: No migration playbook from Neon/Vercel to K8s/TimescaleDB.</p> <p>Resolution: Document explicit migration path</p> <p>Path:</p> <pre><code>Zero-Dollar (8/10)\n  \u251c\u2500 GitHub Actions (free tier)\n  \u251c\u2500 Neon PostgreSQL (free tier)\n  \u251c\u2500 Vercel (hobbyist plan)\n  \u2514\u2500 S3 artifacts (AWS free tier)\n        \u2502\n        \u25bc [Migrate when: &gt;20 deploys/day OR &gt;5 orgs]\n        \u2502\nLow-Cost (8.5/10)\n  \u251c\u2500 GitHub Actions (Team plan $4/user)\n  \u251c\u2500 AWS RDS PostgreSQL ($50/mo)\n  \u251c\u2500 Vercel Pro ($20/mo)\n  \u2514\u2500 S3 artifacts ($10/mo)\n        \u2502\n        \u25bc [Migrate when: Need multi-tenant OR &gt;100 users]\n        \u2502\nEnterprise (10/10)\n  \u251c\u2500 Kubernetes cluster ($500-2000/mo)\n  \u251c\u2500 TimescaleDB (managed $300/mo)\n  \u251c\u2500 Multi-region S3 ($100/mo)\n  \u2514\u2500 Load balancer + monitoring ($200/mo)\n</code></pre> <p>Key Insight: Each phase is fully functional, not a \"prototype.\"</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#4-documentation-vs-reality","title":"4. Documentation vs Reality","text":"<p>Problem: Some docs describe 8/10 (GitHub), others describe 10/10 (K8s).</p> <p>Resolution: Use <code>[Phase 8/10]</code> and <code>[Phase 10/10]</code> prefixes</p> <p>Example:</p> <pre><code>## Deployment\n\n**[Phase 8/10]** Use GitHub Actions workflow:\n...\n\n**[Phase 10/10]** Use Kubernetes CRD:\n...\n\n**Bridge:** Both emit SARIF contracts to the Policy Engine.\n</code></pre>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#invariants-what-never-changes","title":"Invariants (What Never Changes)","text":"<ol> <li>SARIF 2.1.0 - Canonical governance format across all phases</li> <li>Layered Contract Model - SARIF + OTel + CloudEvents + Native</li> <li>Protocol Supremacy - glassspec/ is authoritative</li> <li>Adapter Interface - Same interface works in GitHub and K8s modes</li> <li>Stateless Adapters - Never store state, always emit contracts</li> </ol>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#consequences","title":"Consequences","text":""},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#positive","title":"Positive","text":"<ul> <li>\u2705 Validates before scaling - 8/10 proves market fit before K8s investment</li> <li>\u2705 Revenue path - Consulting revenue funds 10/10 development</li> <li>\u2705 User-driven evolution - Real production usage informs K8s design</li> <li>\u2705 Explicit migration - No hidden technical debt</li> <li>\u2705 Contract immutability - Governance records survive authority transition</li> </ul>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#negative","title":"Negative","text":"<ul> <li>\u26a0\ufe0f Two codebases - Policy engine exists in JS (8/10) and Go (10/10)</li> <li>\u26a0\ufe0f Documentation burden - Must maintain both timelines</li> <li>\u26a0\ufe0f User confusion - Some users on 8/10, some on 10/10</li> <li>\u26a0\ufe0f Feature parity lag - 10/10 features not available in 8/10</li> </ul>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#neutral","title":"Neutral","text":"<ul> <li>\ud83d\udcdd Contract is constant, execution varies</li> <li>\ud83d\udcdd 8/10 is not a \"prototype\" - it's a deliberate constraint</li> <li>\ud83d\udcdd 10/10 is not speculative - it's informed by 8/10 usage</li> </ul>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#alternative-1-build-only-810-github-forever","title":"Alternative 1: Build Only 8/10 (GitHub Forever)","text":"<p>Rejected: Limits addressable market to Salesforce-only teams</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#alternative-2-build-only-1010-k8s-from-day-1","title":"Alternative 2: Build Only 10/10 (K8s From Day 1)","text":"<p>Rejected: Too complex for initial users, burns runway on speculation</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#alternative-3-build-both-simultaneously","title":"Alternative 3: Build Both Simultaneously","text":"<p>Rejected: Splits focus, neither gets production validation</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#alternative-4-hide-the-bifurcation","title":"Alternative 4: Hide the Bifurcation","text":"<p>Rejected: Users deserve transparency about roadmap</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#migration-triggers","title":"Migration Triggers","text":"<p>When to move from 8/10 \u2192 10/10:</p> <ol> <li>Volume: &gt;100 deployments/day across all users</li> <li>Multi-tenancy: &gt;10 distinct organizations</li> <li>Multi-substrate: Need to govern beyond Salesforce (AWS, K8s, etc.)</li> <li>Funding: Secured seed round to invest in K8s infrastructure</li> <li>Team: Hired K8s/Go engineers (can't build 10/10 solo)</li> </ol> <p>Until then: 8/10 is the recommended path.</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-001: System API Primitive</li> <li>ADR-002: GitHub Execution Authority \u2190 8/10 decision</li> <li>ADR-005: Control Plane Architecture \u2190 10/10 vision</li> <li>ADR-007: Protocol Supremacy Enforcement</li> <li>ADR-008: Federated Documentation Structure</li> <li>ADR-010: Identity Contract (Future - addresses identity gap)</li> </ul>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#references","title":"References","text":"<ul> <li>Philosophy</li> <li>Architecture Future</li> </ul> <p>Author: Ryan Bumstead Implemented: 2026-01-24 Status: Active - Defines long-term strategy</p>"},{"location":"docs/adr/009-8-10-vs-10-10-bridge-strategy/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/010-identity-contract/","title":"ADR 010: Identity Contract","text":"<p>Status: Accepted Date: 2026-01-24 Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/010-identity-contract/#context","title":"Context","text":"<p>GlassOps operates across multiple execution substrates (GitHub Actions, Salesforce, Kubernetes), each with their own identity systems. Currently, there is no unified identity contract to represent \"who\" is performing governance actions.</p>"},{"location":"docs/adr/010-identity-contract/#the-identity-gap","title":"The Identity Gap","text":"<p>Current State:</p> <ul> <li>GitHub Actions: <code>GITHUB_ACTOR</code> environment variable</li> <li>Salesforce: JWT-OAuth with <code>username</code> claim</li> <li>Kubernetes: ServiceAccount with <code>subjects[].name</code></li> <li>Policy Overrides: Email address in override request</li> </ul> <p>Problem: These are incompatible identity representations. The governance layer cannot answer:</p> <ul> <li>\"Who triggered this deployment across all substrates?\"</li> <li>\"Does Alice have permission to override policy in Salesforce AND Kubernetes?\"</li> <li>\"Can we trace this audit trail back to a human?\"</li> </ul>"},{"location":"docs/adr/010-identity-contract/#real-world-scenario","title":"Real-World Scenario","text":"<pre><code>Deployment abc123:\n  - Triggered by: github:alice (GitHub Actions)\n  - Authenticated to: salesforce:alice@company.com (JWT)\n  - Approved by: alice@company.com (override request)\n  - Service Account: k8s:system:serviceaccount:glassops:deployer\n</code></pre> <p>Question: Are all four the same person? Current system cannot answer.</p>"},{"location":"docs/adr/010-identity-contract/#decision","title":"Decision","text":"<p>Create a Universal Identity Contract that works across all execution substrates.</p>"},{"location":"docs/adr/010-identity-contract/#core-principle","title":"Core Principle","text":"<p>\"Governance decisions are meaningless without knowing who made them.\"</p> <p>The Identity Contract is embedded in every SARIF contract via <code>invocations[].properties.glassops.identity</code>.</p>"},{"location":"docs/adr/010-identity-contract/#identity-contract-schema","title":"Identity Contract Schema","text":""},{"location":"docs/adr/010-identity-contract/#minimal-contract","title":"Minimal Contract","text":"<pre><code>{\n  \"identity\": {\n    \"subject\": \"alice@company.com\",\n    \"provider\": \"github|salesforce|kubernetes|manual\",\n    \"provider_id\": \"github:alice|sf:005000000...|k8s:sa:deployer|email:alice@...\",\n    \"verified\": true|false,\n    \"timestamp\": \"2026-01-24T10:00:00Z\"\n  }\n}\n</code></pre>"},{"location":"docs/adr/010-identity-contract/#full-contract-with-authorization","title":"Full Contract (with Authorization)","text":"<pre><code>{\n    \"identity\": {\n        \"subject\": \"alice@company.com\",\n        \"displayName\": \"Alice Developer\",\n        \"provider\": \"github\",\n        \"provider_id\": \"github:alice\",\n        \"verified\": true,\n        \"timestamp\": \"2026-01-24T10:00:00Z\",\n\n        \"roles\": [\"developer\", \"deployer\"],\n        \"teams\": [\"platform-team\", \"security-team\"],\n\n        \"authorization\": {\n            \"can_deploy\": true,\n            \"can_override\": false,\n            \"can_approve_overrides\": true,\n            \"max_coverage_reduction\": 0\n        },\n\n        \"context\": {\n            \"ip_address\": \"192.168.1.100\",\n            \"user_agent\": \"GitHub-Actions/2.0\",\n            \"session_id\": \"sess_abc123\",\n            \"mfa_verified\": true\n        }\n    }\n}\n</code></pre>"},{"location":"docs/adr/010-identity-contract/#implementation-strategy","title":"Implementation Strategy","text":""},{"location":"docs/adr/010-identity-contract/#phase-1-identity-detection-current","title":"Phase 1: Identity Detection (Current)","text":"<p>Goal: Extract identity from execution context</p> <p>GitHub Actions:</p> <pre><code>function detectIdentity() {\n    return {\n        subject: process.env.GITHUB_ACTOR_EMAIL || `${process.env.GITHUB_ACTOR}@users.noreply.github.com`,\n        provider: 'github',\n        provider_id: `github:${process.env.GITHUB_ACTOR}`,\n        verified: !!process.env.GITHUB_ACTOR_EMAIL,\n        timestamp: new Date().toISOString()\n    };\n}\n</code></pre> <p>Salesforce JWT:</p> <pre><code>function detectIdentity(jwtPayload) {\n    return {\n        subject: jwtPayload.sub, // username\n        provider: 'salesforce',\n        provider_id: `sf:${jwtPayload.user_id}`,\n        verified: true, // JWT signature validated\n        timestamp: new Date(jwtPayload.iat * 1000).toISOString()\n    };\n}\n</code></pre> <p>Kubernetes ServiceAccount:</p> <pre><code>func detectIdentity(ctx context.Context) *Identity {\n    sa := ctx.Value(\"serviceaccount\")\n    return &amp;Identity{\n        Subject:    sa.Annotations[\"glassops.io/human-user\"],\n        Provider:   \"kubernetes\",\n        ProviderID: fmt.Sprintf(\"k8s:sa:%s:%s\", sa.Namespace, sa.Name),\n        Verified:   true,\n        Timestamp:  time.Now(),\n    }\n}\n</code></pre>"},{"location":"docs/adr/010-identity-contract/#phase-2-identity-resolution-bridge","title":"Phase 2: Identity Resolution (Bridge)","text":"<p>Goal: Map provider-specific IDs to canonical subjects</p> <p>Identity Resolution Service:</p> <pre><code>apiVersion: identity.glassops.io/v1\nkind: IdentityMapping\nmetadata:\n    name: alice-identity\nspec:\n    canonical_subject: alice@company.com\n\n    mappings:\n        - provider: github\n          provider_id: github:alice\n          verified_at: '2026-01-20T00:00:00Z'\n\n        - provider: salesforce\n          provider_id: sf:005000000abcXYZ\n          verified_at: '2026-01-20T00:00:00Z'\n\n        - provider: kubernetes\n          provider_id: k8s:sa:glassops:alice-deployer\n          verified_at: '2026-01-20T00:00:00Z'\n</code></pre> <p>Resolution Logic:</p> <pre><code>async function resolveIdentity(detectedIdentity) {\n    // Look up canonical subject from provider_id\n    const mapping = await identityStore.findMapping(detectedIdentity.provider_id);\n\n    if (mapping) {\n        return {\n            ...detectedIdentity,\n            subject: mapping.canonical_subject,\n            verified: true\n        };\n    }\n\n    // Fallback: Use detected identity as-is\n    return detectedIdentity;\n}\n</code></pre>"},{"location":"docs/adr/010-identity-contract/#phase-3-identity-authorization-future","title":"Phase 3: Identity Authorization (Future)","text":"<p>Goal: Enforce permissions based on identity</p> <p>Authorization Policy:</p> <pre><code>apiVersion: policy.glassops.io/v1\nkind: AuthorizationPolicy\nmetadata:\n    name: deployment-permissions\nspec:\n    rules:\n        - subjects: ['alice@company.com']\n          roles: ['deployer']\n          permissions:\n              deploy: ['production', 'staging']\n              override: false\n\n        - subjects: ['bob@company.com']\n          roles: ['platform-lead']\n          permissions:\n              deploy: ['production', 'staging', 'dev']\n              override: true\n              approve_overrides: true\n</code></pre>"},{"location":"docs/adr/010-identity-contract/#sarif-integration","title":"SARIF Integration","text":""},{"location":"docs/adr/010-identity-contract/#where-identity-goes","title":"Where Identity Goes","text":"<p>Location: <code>invocations[].properties.glassops.identity</code></p> <p>Example SARIF Contract:</p> <pre><code>{\n    \"$schema\": \"https://schemastore.azurewebsites.net/schemas/json/sarif-2.1.0-rtm.5.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [\n        {\n            \"tool\": {\n                \"driver\": {\n                    \"name\": \"glassops-native-adapter\",\n                    \"version\": \"1.0.0\"\n                }\n            },\n            \"invocations\": [\n                {\n                    \"executionSuccessful\": true,\n                    \"endTimeUtc\": \"2026-01-24T10:00:00Z\",\n                    \"properties\": {\n                        \"glassops\": {\n                            \"deploymentId\": \"0Af...\",\n                            \"identity\": {\n                                \"subject\": \"alice@company.com\",\n                                \"provider\": \"github\",\n                                \"provider_id\": \"github:alice\",\n                                \"verified\": true,\n                                \"timestamp\": \"2026-01-24T09:55:00Z\",\n                                \"roles\": [\"developer\", \"deployer\"],\n                                \"authorization\": {\n                                    \"can_deploy\": true,\n                                    \"can_override\": false\n                                }\n                            }\n                        }\n                    }\n                }\n            ],\n            \"results\": []\n        }\n    ]\n}\n</code></pre>"},{"location":"docs/adr/010-identity-contract/#audit-trail-benefits","title":"Audit Trail Benefits","text":""},{"location":"docs/adr/010-identity-contract/#before-identity-contract","title":"Before Identity Contract","text":"<pre><code>Deployment abc123: Who did this?\n  \u2514\u2500 GITHUB_ACTOR=alice (Could be anyone named alice)\n</code></pre>"},{"location":"docs/adr/010-identity-contract/#after-identity-contract","title":"After Identity Contract","text":"<pre><code>Deployment abc123: alice@company.com (verified)\n  \u251c\u2500 Provider: GitHub (github:alice)\n  \u251c\u2500 Roles: [developer, deployer]\n  \u251c\u2500 Authorization: can_deploy=true, can_override=false\n  \u251c\u2500 MFA: verified\n  \u2514\u2500 IP: 192.168.1.100\n</code></pre> <p>Audit Questions Now Answerable:</p> <ul> <li>\u2705 \"Who deployed this?\" \u2192 alice@company.com</li> <li>\u2705 \"Were they authorized?\" \u2192 Yes, can_deploy=true</li> <li>\u2705 \"Was identity verified?\" \u2192 Yes, MFA verified</li> <li>\u2705 \"Can we correlate across substrates?\" \u2192 Yes, canonical subject</li> </ul>"},{"location":"docs/adr/010-identity-contract/#cross-substrate-correlation","title":"Cross-Substrate Correlation","text":""},{"location":"docs/adr/010-identity-contract/#example-override-request-flow","title":"Example: Override Request Flow","text":"<p>1. Deployment Attempt (GitHub Actions)</p> <pre><code>{\n    \"identity\": {\n        \"subject\": \"alice@company.com\",\n        \"provider\": \"github\",\n        \"provider_id\": \"github:alice\",\n        \"authorization\": {\n            \"can_deploy\": true,\n            \"can_override\": false // \u2190 Cannot override\n        }\n    }\n}\n</code></pre> <p>2. Override Request (CLI/API)</p> <pre><code>glassops override request \\\n  --repository acme/salesforce \\\n  --reason \"Production outage\" \\\n  --requester alice@company.com  # \u2190 Same canonical subject\n</code></pre> <p>3. Override Approval (Kubernetes Operator)</p> <pre><code>{\n    \"identity\": {\n        \"subject\": \"bob@company.com\",\n        \"provider\": \"kubernetes\",\n        \"provider_id\": \"k8s:sa:glassops:platform-lead\",\n        \"authorization\": {\n            \"can_approve_overrides\": true // \u2190 Can approve\n        }\n    }\n}\n</code></pre> <p>4. Deployment with Override (GitHub Actions)</p> <pre><code>{\n    \"identity\": {\n        \"subject\": \"alice@company.com\", // \u2190 Same requester\n        \"provider\": \"github\",\n        \"authorization\": {\n            \"can_deploy\": true,\n            \"override_approved_by\": \"bob@company.com\", // \u2190 Approver tracked\n            \"override_id\": \"override-1234\"\n        }\n    }\n}\n</code></pre> <p>Result: Complete audit trail across all substrates.</p>"},{"location":"docs/adr/010-identity-contract/#consequences","title":"Consequences","text":""},{"location":"docs/adr/010-identity-contract/#positive","title":"Positive","text":"<ul> <li>\u2705 Unified Identity - Single canonical subject across all substrates</li> <li>\u2705 Audit Trail - Can trace actions back to humans</li> <li>\u2705 Authorization - Enforce permissions consistently</li> <li>\u2705 Compliance - SOC 2 / audit-ready identity records</li> <li>\u2705 Cross-Substrate - Correlate actions across GitHub, Salesforce, K8s</li> </ul>"},{"location":"docs/adr/010-identity-contract/#negative","title":"Negative","text":"<ul> <li>\u26a0\ufe0f Identity Mapping Maintenance - Must keep mappings updated</li> <li>\u26a0\ufe0f Privacy Concerns - Storing email addresses in SARIF contracts</li> <li>\u26a0\ufe0f Resolution Overhead - Extra lookup for canonical subject</li> <li>\u26a0\ufe0f Migration - Existing contracts lack identity field</li> </ul>"},{"location":"docs/adr/010-identity-contract/#neutral","title":"Neutral","text":"<ul> <li>\ud83d\udcdd Identity is optional in SARIF (can be missing)</li> <li>\ud83d\udcdd Verified=false is valid (unverified identity still captured)</li> <li>\ud83d\udcdd Provider-specific fields allowed in <code>context</code></li> </ul>"},{"location":"docs/adr/010-identity-contract/#privacy-security-considerations","title":"Privacy &amp; Security Considerations","text":""},{"location":"docs/adr/010-identity-contract/#personal-data-in-sarif","title":"Personal Data in SARIF","text":"<p>Problem: Email addresses are PII (Personally Identifiable Information)</p> <p>Mitigations:</p> <ol> <li>Hashing: Store <code>subject_hash</code> instead of email</li> <li>Pseudonymization: Use stable pseudonym (e.g., <code>user_123</code>)</li> <li>Retention: Auto-delete identity after 90 days</li> <li>Access Control: Restrict SARIF contract access</li> </ol> <p>Recommendation: Start with email, add hashing in Phase 2.</p>"},{"location":"docs/adr/010-identity-contract/#alternatives-considered","title":"Alternatives Considered","text":""},{"location":"docs/adr/010-identity-contract/#alternative-1-no-identity-contract","title":"Alternative 1: No Identity Contract","text":"<p>Rejected: Audit trail is meaningless without knowing \"who\"</p>"},{"location":"docs/adr/010-identity-contract/#alternative-2-provider-specific-identity-only","title":"Alternative 2: Provider-Specific Identity Only","text":"<p>Rejected: Cannot correlate across substrates (GitHub vs Salesforce vs K8s)</p>"},{"location":"docs/adr/010-identity-contract/#alternative-3-external-identity-provider-oauth2","title":"Alternative 3: External Identity Provider (OAuth2)","text":"<p>Rejected: Too complex for 8/10 vision, consider for 10/10</p>"},{"location":"docs/adr/010-identity-contract/#alternative-4-sign-sarif-contracts-with-private-keys","title":"Alternative 4: Sign SARIF Contracts with Private Keys","text":"<p>Considered: Strong non-repudiation, but high complexity. Future enhancement.</p>"},{"location":"docs/adr/010-identity-contract/#migration-path","title":"Migration Path","text":""},{"location":"docs/adr/010-identity-contract/#existing-contracts-without-identity","title":"Existing Contracts Without Identity","text":"<p>Problem: Contracts emitted before ADR-010 lack identity field</p> <p>Solution: Backfill from audit logs</p> <pre><code>async function backfillIdentity(contract) {\n    if (contract.runs[0].invocations[0].properties?.glassops?.identity) {\n        return contract; // Already has identity\n    }\n\n    // Extract from audit context\n    const auditData = contract.runs[0].invocations[0].properties?.glassops;\n\n    const identity = {\n        subject: auditData?.triggeredBy || 'unknown',\n        provider: 'github', // Assumption for pre-ADR-010 contracts\n        provider_id: `github:${auditData?.triggeredBy}`,\n        verified: false, // Cannot verify retroactively\n        timestamp: contract.runs[0].invocations[0].endTimeUtc,\n        _backfilled: true\n    };\n\n    contract.runs[0].invocations[0].properties.glassops.identity = identity;\n    return contract;\n}\n</code></pre>"},{"location":"docs/adr/010-identity-contract/#related-adrs","title":"Related ADRs","text":"<ul> <li>ADR-007: Protocol Supremacy Enforcement</li> <li>ADR-009: The 8/10 vs 10/10 Bridge Strategy \u2190 Identified identity gap</li> <li>GlassSpec ADR-001: Layered Contract Model</li> </ul>"},{"location":"docs/adr/010-identity-contract/#references","title":"References","text":"<ul> <li>OASIS SARIF 2.1.0</li> <li>OAuth 2.0 RFC 6749</li> <li>NIST SP 800-63B: Digital Identity Guidelines</li> </ul> <p>Author: Ryan Bumstead Implemented: 2026-01-24 Status: Active - Identity field required in all new contracts</p>"},{"location":"docs/adr/010-identity-contract/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/adr/011-monorepo-strategy/","title":"ADR 011: Monorepo Strategy for Protocol Ecosystem","text":"<p>Status: Accepted Date: 2026-01-24 Deciders: Ryan Bumstead</p>"},{"location":"docs/adr/011-monorepo-strategy/#context","title":"Context","text":"<p>GlassOps is a \"Protocol Ecosystem\" consisting of:</p> <ol> <li>The Law (<code>glassspec</code>) - The Interface</li> <li>The Manual (<code>glassops/docs</code>) - The Documentation</li> <li>The Implementations (<code>runtime</code>, <code>control-plane</code>, <code>adapters</code>) - The Code</li> </ol> <p>The development team is currently one person.</p>"},{"location":"docs/adr/011-monorepo-strategy/#the-problem-with-polyrepos-separate-repos","title":"The Problem with Polyrepos (Separate Repos)","text":"<p>If we split these into 5+ repositories (<code>glass-protocol</code>, <code>glass-runtime</code>, <code>glass-adapter-native</code>, etc.):</p> <ol> <li>Context Switching Cost: Updating a standard requires 5 PRs across 5 repos.</li> <li>Versioning Hell: \"Runtime v1.2 depends on Protocol v1.1 but imports Adapter v1.0 which expects Protocol v1.0.\"</li> <li>Synchronization Lag: The docs will inevitably drift from the code because they live in different universes.</li> </ol> <p>For a solo developer, this friction is fatal.</p>"},{"location":"docs/adr/011-monorepo-strategy/#decision","title":"Decision","text":"<p>We will use a Single Governance Monorepo (<code>glassops-platform/glassops</code>) for all core components.</p>"},{"location":"docs/adr/011-monorepo-strategy/#the-structure","title":"The Structure","text":"<pre><code>glassops/\n\u251c\u2500\u2500 packages/\n\u2502   \u251c\u2500\u2500 glassspec/              # The constraints (Sarif schemas, Protocol.md)\n\u2502   \u251c\u2500\u2500 runtime/                # The machinery (@glassops/runtime)\n\u2502   \u251c\u2500\u2500 control-plane/          # The brains (@glassops/control-plane)\n\u2502   \u2514\u2500\u2500 adapters/               # The hands (@glassops/native-adapter, etc)\n\u251c\u2500\u2500 docs/                       # The Manual\n\u2514\u2500\u2500 config/                     # Shared configuration\n</code></pre>"},{"location":"docs/adr/011-monorepo-strategy/#the-publisher-pattern-for-distribution","title":"The \"Publisher Pattern\" for Distribution","text":"<p>While development happens in the Monorepo, consumption may require separate repos (e.g., GitHub Actions marketplace limitations).</p> <p>Strategy:</p> <ol> <li>Develop in <code>glassops</code>.</li> <li>Release via automated pipelines that copy folders to read-only public mirrors (e.g., <code>glassops-platform/glassops-runtime</code>).</li> <li>Never write code in the mirrors.</li> </ol>"},{"location":"docs/adr/011-monorepo-strategy/#rationale","title":"Rationale","text":"<ol> <li>Atomic Protocol Updates: A single commit can update the SARIF spec in <code>glassspec</code> AND the implementation in <code>glassops-runtime</code>. Drift is impossible.</li> <li>Solo Velocity: Zero context switching. grep across the entire universe. Refactor global names in one pass.</li> <li>Coherent Versioning: The ecosystem moves forward together.</li> </ol>"},{"location":"docs/adr/011-monorepo-strategy/#strategic-extensibility","title":"Strategic Extensibility","text":"<p>The monorepo structure allows for seamless expansion. we can add <code>glassops-cli</code>, <code>glassops-docs</code>, <code>glassops-policy-engine</code>, or even a second platform later without renaming anything. The structure is designed to accept new domains as top-level directories without disrupting the core.</p>"},{"location":"docs/adr/011-monorepo-strategy/#consequences","title":"Consequences","text":"<ul> <li>Positive: Maximum velocity for 1-3 developers. Guaranteed consistency.</li> <li>Negative: CI pipelines are complex (need to detect which folder changed).</li> <li>Mitigation: Use tools like <code>turborepo</code> or simple path-based GitHub Action triggers.</li> </ul> <p>Author: Ryan Bumstead (Population: 1)</p>"},{"location":"docs/adr/011-monorepo-strategy/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"docs/architecture/overview/","title":"GlassOps Architecture &amp; Design","text":"<p>The Blueprint for the Governance Control Plane.</p>"},{"location":"docs/architecture/overview/#1-high-level-architecture","title":"1. High-Level Architecture","text":"<p>GlassOps uses a Container-First Architecture where GitHub acts as the Control Plane and specialized Containers act as Execution Adapters.</p>"},{"location":"docs/architecture/overview/#the-control-loop","title":"The Control Loop","text":"<pre><code>graph LR\n    Intent[User Intent] --&gt; Policy[Policy Engine]\n    Policy --&gt;|Approved| Adapter[Execution Adapter]\n    Adapter --&gt;|Contract| Audit[Audit Trail]\n    Policy --&gt;|Rejected| Block[Block Deployment]</code></pre>"},{"location":"docs/architecture/overview/#component-breakdown","title":"Component Breakdown","text":"<ol> <li>Control Plane (GitHub): Owns state, secrets, and policy resolution.</li> <li>Runtime Primitive: Bootstraps the environment (CLI, Auth).</li> <li>Adapters: Stateless workers that execute commands and normalize output.</li> <li>Protocol: The message format (SARIF/OTel) exchanged between components.</li> </ol>"},{"location":"docs/architecture/overview/#2-governance-flow-the-pipeline","title":"2. Governance Flow (The Pipeline)","text":"<p>Deployment is not a single step; it is a 4-phase governance process.</p> <ol> <li> <p>Phase 1: Policy Resolution</p> <ul> <li>Merges <code>GitHub Vars</code> (Floor) + <code>devops-config.json</code> (Team) + <code>Salesforce CMDT</code> (Additive).</li> <li>Result: A single <code>Effective Policy</code>.</li> </ul> </li> <li> <p>Phase 2: Architectural Validity</p> <ul> <li>Static analysis checks (PMD/ESLint).</li> <li>Enforces Hard Invariants (e.g., No RunAllTests in Prod).</li> </ul> </li> <li> <p>Phase 3: Simulation (The Dry Run)</p> <ul> <li>Runs the specific adapter in <code>check-only</code> mode.</li> <li>Generates a Draft Contract (SARIF).</li> </ul> </li> <li> <p>Phase 4: Execution Gate</p> <ul> <li>The Governance Engine compares Draft Contract vs Effective Policy.</li> <li>If <code>Pass</code> -&gt; Execute Quick Deploy.</li> <li>If <code>Fail</code> -&gt; Block.</li> </ul> </li> </ol>"},{"location":"docs/architecture/overview/#3-security-model","title":"3. Security Model","text":""},{"location":"docs/architecture/overview/#confused-deputy-protection","title":"Confused Deputy Protection","text":"<p>Principle: Salesforce never holds deployment secrets. GitHub holds secrets and requests a token via JWT.</p> <ul> <li>Benefit: If Salesforce is compromised, they cannot deploy to other envs. If GitHub is compromised, scope is limited to the specific repo environment.</li> </ul>"},{"location":"docs/architecture/overview/#secrets-management","title":"Secrets Management","text":"<ul> <li>Location: GitHub Secrets (Environment Scoped).</li> <li>Rotation: 90-day automated rotation for JWT keys.</li> </ul>"},{"location":"docs/architecture/overview/#4-failure-modes-recovery","title":"4. Failure Modes &amp; Recovery","text":"<p>| Failure | Behavior | Recovery | | (System) | (Workflow) | (Manual) | |---|---|---| | GitHub Down | Deployment Impossible | Manual <code>sf deploy</code> from local machine (Break Glass) | | Salesforce Down | Workflow Fails Gracefully | Retry when service restored | | Policy Block | Workflow Fails (Intentional) | Fix code or Request <code>Manual Override</code> |</p>"},{"location":"docs/architecture/overview/#5-directory-structure","title":"5. Directory Structure","text":"<ul> <li><code>packages/control-plane</code>: The Policy decision logic.</li> <li><code>packages/runtime</code>: The environment boostrapper.</li> <li><code>packages/adapters/*</code>: The execution workers.</li> <li><code>packages/glassspec</code>: The protocol definitions.</li> </ul>"},{"location":"docs/reference/platform-reference/","title":"Platform Reference &amp; API","text":"<p>The Normative Specification for GlassOps Components.</p> <p>This document defines the inputs, outputs, and interfaces for the core system. For architecture, see overview.md.</p>"},{"location":"docs/reference/platform-reference/#1-runtime-primitive-glassops-platformruntime","title":"1. Runtime Primitive (<code>@glassops-platform/runtime</code>)","text":"<p>Location: <code>packages/runtime</code> Purpose: Bootstraps the secure environment.</p>"},{"location":"docs/reference/platform-reference/#inputs","title":"Inputs","text":"Input Required Description <code>jwt_key</code> Yes PEM Encrypted Private Key <code>client_id</code> Yes Connected App Consumer Key <code>username</code> Yes Target Username <code>instance_url</code> No Default: login.salesforce.com"},{"location":"docs/reference/platform-reference/#outputs","title":"Outputs","text":"Output Description <code>org_id</code> 18-char Organization ID <code>is_production</code> Boolean flag for safety gates <code>session_id</code> (Masked) Access Token"},{"location":"docs/reference/platform-reference/#2-deployment-contract-schema","title":"2. Deployment Contract Schema","text":"<p>Authority: <code>packages/glassspec/README.md</code></p> <p>Every adapter MUST emit a contract matching this schema (simplified):</p> <pre><code>{\n    \"schemaVersion\": \"1.0\",\n    \"meta\": { \"adapter\": \"native\", \"timestamp\": \"...\" },\n    \"status\": \"Succeeded\",\n    \"policy\": {\n        \"effective\": { \"minCoverage\": 75 },\n        \"met\": true\n    },\n    \"results\": [{ \"ruleId\": \"COVERAGE\", \"level\": \"error\", \"message\": \"72% &lt; 75%\" }]\n}\n</code></pre>"},{"location":"docs/reference/platform-reference/#3-policy-resolution-api","title":"3. Policy Resolution API","text":"<p>Location: <code>packages/control-plane</code></p>"},{"location":"docs/reference/platform-reference/#resolution-logic","title":"Resolution Logic","text":"<pre><code>EffectivePolicy = MAX(GitHub_Env_Var(Floor), Repo_Config_File(Team), Salesforce_CMDT(Organization));\n</code></pre> <p>Invariant: No source can lower the GitHub Floor.</p>"},{"location":"docs/reference/platform-reference/#4-adapter-interface","title":"4. Adapter Interface","text":"<p>To be a compliant adapter, a container must:</p> <ol> <li>Accept <code>--policy-in</code> (JSON path).</li> <li>Emit <code>--contract-out</code> (JSON path).</li> <li>Exit <code>0</code> for success, <code>1</code> for crash (System Error).</li> <li>Exit <code>0</code> for Policy Failure (Logic Error) but mark Contract status as <code>Failed</code>.</li> </ol>"},{"location":"examples/","title":"GlassOps Examples","text":"<p>This directory will contain example configurations and workflow templates for various GlassOps scenarios.</p>"},{"location":"examples/#current-examples","title":"Current Examples","text":"<ul> <li>Deployment Workflow: A standard GitHub Actions workflow for governed deployments.</li> <li>Configuration Template: A starter <code>devops-config.json</code> file for your repository.</li> </ul>"},{"location":"packages/adapters/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/adapters/docs/adapter-development/","title":"Adapter Development Guide (Draft)","text":"<p>Danger</p> <p>This specification is currently in DRAFT status. The Adapter Interface is subject to change before v1.0.0 finalization. Contributors are encouraged to experiment, but please pin dependencies and expect breaking changes.</p> <p>Building execution adapters for GlassOps</p> <p>This guide walks you through creating a new adapter that integrates your preferred deployment tool with the GlassOps governance protocol.</p>"},{"location":"packages/adapters/docs/adapter-development/#what-is-an-adapter","title":"What is an Adapter?","text":"<p>An adapter is a stateless worker that conforms to the GlassOps Protocol. It translates tool-specific output into the Universal SARIF Contract defined in Adapter Interface.</p> <ol> <li>Consumes deployment intent.</li> <li>Executes using your chosen tool.</li> <li>Emits a standard SARIF 2.1.0 contract.</li> </ol> <p>Think of it as a translator between your tool and the governance layer.</p> <p>Important</p> <p>Protocol Supremacy: All adapters MUST emit OASIS SARIF 2.1.0 format as defined in Adapter Interface. Do NOT invent custom schemas. See the Protocol's Anti-Patterns section for scope boundaries.</p>"},{"location":"packages/adapters/docs/adapter-development/#the-adapter-contract","title":"The Adapter Contract","text":"<p>Every adapter MUST implement this interface:</p>"},{"location":"packages/adapters/docs/adapter-development/#required-functions","title":"Required Functions","text":"<pre><code>/**\n * Validate deployment without execution (check-only/dry-run)\n * @returns {DeploymentContract} Draft contract with validation results\n */\nasync function simulate(options) {\n    // Run check-only deployment\n    // Calculate coverage\n    // Return draft contract\n}\n\n/**\n * Execute validated deployment using Quick Deploy\n * @param {string} validationId - ID from successful simulation\n * @returns {DeploymentContract} Final contract with deployment results\n */\nasync function execute(validationId, options) {\n    // Use quick deploy with validation ID\n    // Return final contract\n}\n\n/**\n * Normalize tool-specific errors to standard format\n * @param {Error} rawError - Tool-specific error object\n * @returns {NormalizedError} Standard error format\n */\nfunction normalizeError(rawError) {\n    // Convert tool errors to standard schema\n}\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#the-deployment-contract-schema","title":"The Deployment Contract Schema","text":"<p>Your adapter must emit a SARIF 2.1.0 contract as defined in the GlassOps Adapter Interface.</p>"},{"location":"packages/adapters/docs/adapter-development/#minimal-compliant-sarif-contract","title":"Minimal Compliant SARIF Contract","text":"<pre><code>{\n    \"$schema\": \"https://schemastore.azurewebsites.net/schemas/json/sarif-2.1.0-rtm.5.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [\n        {\n            \"tool\": {\n                \"driver\": {\n                    \"name\": \"glassops-mytool-adapter\",\n                    \"version\": \"1.0.0\",\n                    \"informationUri\": \"https://github.com/yourorg/glassops-mytool-adapter\"\n                }\n            },\n            \"invocations\": [\n                {\n                    \"executionSuccessful\": true,\n                    \"endTimeUtc\": \"2026-01-24T12:00:00Z\",\n                    \"properties\": {\n                        \"glassops\": {\n                            \"deploymentId\": \"0Af5e000000abcXYZ\",\n                            \"targetOrg\": \"production\",\n                            \"testLevel\": \"RunLocalTests\",\n                            \"componentsDeployed\": 42,\n                            \"testsRun\": 120\n                        }\n                    }\n                }\n            ],\n            \"results\": [\n                {\n                    \"ruleId\": \"COVERAGE_THRESHOLD\",\n                    \"level\": \"error\",\n                    \"message\": {\n                        \"text\": \"Code Coverage (72%) is below threshold (75%)\"\n                    },\n                    \"locations\": [\n                        {\n                            \"physicalLocation\": {\n                                \"artifactLocation\": {\n                                    \"uri\": \"force-app/main/default/classes/AccountService.cls\"\n                                }\n                            }\n                        }\n                    ]\n                }\n            ]\n        }\n    ]\n}\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#key-mapping-rules","title":"Key Mapping Rules","text":"<p>Adapters translate tool-specific concepts to SARIF fields:</p> Tool Concept SARIF Field Notes Violation ID <code>result.ruleId</code> Must be stable and queryable. Severity <code>result.level</code> Map to <code>error</code>, <code>warning</code>, <code>note</code>, or <code>none</code>. Error Message <code>result.message.text</code> Human-readable explanation. File Path <code>location.physicalLocation.uri</code> Relative path from repo root. Line Number <code>region.startLine</code> 1-based line number. Deployment Metadata <code>invocation.properties.glassops</code> Custom metadata in property bag."},{"location":"packages/adapters/docs/adapter-development/#what-goes-in-sarif-vs-what-doesnt","title":"What Goes in SARIF vs. What Doesn't","text":"<p>\u2705 DO normalize into SARIF:</p> <ul> <li>Policy violations (coverage failures, test failures)</li> <li>Code quality findings (static analysis results)</li> <li>Deployment decisions (approved, rejected, override)</li> <li>Governance outcomes</li> </ul> <p>\u274c DO NOT normalize into SARIF:</p> <ul> <li>CPU/Memory metrics \u2192 Use OpenTelemetry</li> <li>Live logs \u2192 Use OpenTelemetry Logs</li> <li>Trace IDs \u2192 Use CloudEvents Context</li> <li>Raw configuration state \u2192 Link to native store</li> </ul> <p>See the Protocol's Anti-Patterns section for complete guidance.</p>"},{"location":"packages/adapters/docs/adapter-development/#step-by-step-building-your-first-adapter","title":"Step-by-Step: Building Your First Adapter","text":""},{"location":"packages/adapters/docs/adapter-development/#step-1-set-up-the-project-structure","title":"Step 1: Set Up the Project Structure","text":"<pre><code>mkdir glassops-mytool-adapter\ncd glassops-mytool-adapter\n\n# Initialize package.json\nnpm init -y\n\n# Install dependencies\nnpm install @actions/core @actions/exec\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#step-2-create-the-adapter-script","title":"Step 2: Create the Adapter Script","text":"<pre><code>// src/adapter.js\nconst core = require('@actions/core');\nconst exec = require('@actions/exec');\nconst fs = require('fs').promises;\nconst path = require('path');\n\nclass MyToolAdapter {\n    constructor(options) {\n        this.options = options;\n    }\n\n    async simulate() {\n        core.info('Running check-only deployment...');\n\n        let output = '';\n        const options = {\n            listeners: {\n                stdout: (data) =&gt; {\n                    output += data.toString();\n                }\n            }\n        };\n\n        try {\n            // Execute your tool in check-only mode\n            await exec.exec(\n                'mytool',\n                [\n                    'deploy',\n                    '--check-only',\n                    '--source-dir',\n                    this.options.sourceDir,\n                    '--test-level',\n                    this.options.testLevel\n                ],\n                options\n            );\n\n            // Parse output and build contract\n            const results = this.parseOutput(output);\n            return this.buildContract('draft', results);\n        } catch (error) {\n            return this.buildContract('failed', null, error);\n        }\n    }\n\n    async execute(validationId) {\n        core.info(`Executing quick deploy with validation ID: ${validationId}`);\n\n        let output = '';\n        const options = {\n            listeners: {\n                stdout: (data) =&gt; {\n                    output += data.toString();\n                }\n            }\n        };\n\n        try {\n            await exec.exec('mytool', ['deploy', '--quick-deploy', '--validation-id', validationId], options);\n\n            const results = this.parseOutput(output);\n            return this.buildContract('final', results);\n        } catch (error) {\n            return this.buildContract('failed', null, error);\n        }\n    }\n\n    parseOutput(output) {\n        // Parse your tool's output format\n        // Extract: deployment ID, coverage, test results, etc.\n\n        // Example for JSON output:\n        const data = JSON.parse(output);\n\n        return {\n            deploymentId: data.id,\n            coverage: data.coverage,\n            tests: data.testResults,\n            componentsDeployed: data.components.length\n        };\n    }\n\n    buildContract(mode, results, error = null) {\n        // Build SARIF 2.1.0 compliant contract\n        const contract = {\n            $schema: 'https://schemastore.azurewebsites.net/schemas/json/sarif-2.1.0-rtm.5.json',\n            version: '2.1.0',\n            runs: [\n                {\n                    tool: {\n                        driver: {\n                            name: 'glassops-mytool-adapter',\n                            version: '1.0.0',\n                            informationUri: 'https://github.com/yourorg/glassops-mytool-adapter'\n                        }\n                    },\n                    invocations: [\n                        {\n                            executionSuccessful: !error,\n                            endTimeUtc: new Date().toISOString(),\n                            properties: {\n                                glassops: {\n                                    deploymentId: results?.deploymentId || 'unknown',\n                                    mode: mode === 'draft' ? 'validate' : 'deploy',\n                                    componentsDeployed: results?.componentsDeployed || 0,\n                                    testsRun: results?.tests?.total || 0,\n                                    triggeredBy: process.env.GITHUB_ACTOR,\n                                    repository: process.env.GITHUB_REPOSITORY,\n                                    ref: process.env.GITHUB_REF,\n                                    commit: process.env.GITHUB_SHA,\n                                    runUrl: `https://github.com/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID}`\n                                }\n                            }\n                        }\n                    ],\n                    results: []\n                }\n            ]\n        };\n\n        // Add coverage violation if below threshold\n        if (results &amp;&amp; results.coverage &lt; this.options.minCoverage) {\n            contract.runs[0].results.push({\n                ruleId: 'COVERAGE_THRESHOLD',\n                level: 'error',\n                message: {\n                    text: `Code Coverage (${results.coverage}%) is below threshold (${this.options.minCoverage}%)`\n                },\n                properties: {\n                    coverage: {\n                        actual: results.coverage,\n                        required: this.options.minCoverage\n                    }\n                }\n            });\n        }\n\n        // Add test failures\n        if (results?.tests?.failed &gt; 0) {\n            contract.runs[0].results.push({\n                ruleId: 'TEST_FAILURE',\n                level: 'error',\n                message: {\n                    text: `${results.tests.failed} test(s) failed out of ${results.tests.total}`\n                },\n                properties: {\n                    tests: results.tests\n                }\n            });\n        }\n\n        // Add general error if present\n        if (error) {\n            contract.runs[0].results.push({\n                ruleId: 'DEPLOYMENT_FAILURE',\n                level: 'error',\n                message: {\n                    text: error.message\n                },\n                properties: {\n                    errorCode: error.code || 'UNKNOWN',\n                    errorType: 'deployment_failure'\n                }\n            });\n        }\n\n        return contract;\n    }\n\n    normalizeError(error) {\n        return {\n            code: error.code || 'UNKNOWN',\n            message: error.message,\n            type: 'deployment_failure'\n        };\n    }\n\n    async writeContract(contract) {\n        const contractPath = '.glassops/glassops-contract.sarif.json';\n        await fs.mkdir('.glassops', { recursive: true });\n\n        // Write atomically (temp file + rename)\n        const tempPath = `${contractPath}.tmp`;\n        await fs.writeFile(tempPath, JSON.stringify(contract, null, 2));\n        await fs.rename(tempPath, contractPath);\n\n        core.info(`Contract written to ${contractPath}`);\n    }\n}\n\nmodule.exports = MyToolAdapter;\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#step-3-create-the-github-action-wrapper","title":"Step 3: Create the GitHub Action Wrapper","text":"<pre><code>// src/index.js\nconst core = require('@actions/core');\nconst MyToolAdapter = require('./adapter');\n\nasync function run() {\n    try {\n        const adapter = new MyToolAdapter({\n            sourceDir: core.getInput('source-dir', { required: true }),\n            testLevel: core.getInput('test-level') || 'RunLocalTests',\n            minCoverage: parseInt(core.getInput('min-coverage') || '75')\n        });\n\n        // Phase 1: Simulate\n        core.info('Phase 1: Simulation (Check-Only)');\n        const draftContract = await adapter.simulate();\n        await adapter.writeContract(draftContract);\n\n        // Check if execution was successful\n        const invocation = draftContract.runs[0].invocations[0];\n        if (!invocation.executionSuccessful) {\n            core.setFailed('Simulation failed');\n            return;\n        }\n\n        // Phase 2: Check governance - look for blocking violations\n        const blockingResults = draftContract.runs[0].results.filter((r) =&gt; r.level === 'error');\n\n        if (blockingResults.length &gt; 0) {\n            const messages = blockingResults.map((r) =&gt; r.message.text).join('; ');\n            core.setFailed(`Governance violations: ${messages}`);\n            return;\n        }\n\n        // Phase 3: Execute\n        core.info('Phase 2: Execution (Quick Deploy)');\n        const deploymentId = draftContract.runs[0].invocations[0].properties.glassops.deploymentId;\n        const finalContract = await adapter.execute(deploymentId);\n        await adapter.writeContract(finalContract);\n\n        const finalInvocation = finalContract.runs[0].invocations[0];\n        if (!finalInvocation.executionSuccessful) {\n            core.setFailed('Deployment failed');\n            return;\n        }\n\n        core.info('\u2705 Deployment successful');\n        core.setOutput('deployment-id', finalInvocation.properties.glassops.deploymentId);\n\n        // Extract coverage from results if present\n        const coverageResult = finalContract.runs[0].results.find((r) =&gt; r.ruleId === 'COVERAGE_THRESHOLD');\n        if (coverageResult?.properties?.coverage) {\n            core.setOutput('coverage', coverageResult.properties.coverage.actual);\n        }\n    } catch (error) {\n        core.setFailed(error.message);\n    }\n}\n\nrun();\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#step-4-create-actionyml","title":"Step 4: Create action.yml","text":"<pre><code>name: 'GlassOps MyTool Adapter'\ndescription: 'Execute governed deployments using MyTool'\nauthor: 'Your Name'\n\ninputs:\n    source-dir:\n        description: 'Source directory containing metadata'\n        required: true\n    test-level:\n        description: 'Test level (NoTestRun, RunSpecifiedTests, RunLocalTests, RunAllTestsInOrg)'\n        required: false\n        default: 'RunLocalTests'\n    min-coverage:\n        description: 'Minimum code coverage required'\n        required: false\n        default: '75'\n\noutputs:\n    deployment-id:\n        description: 'Salesforce deployment ID'\n    coverage:\n        description: 'Actual code coverage percentage'\n\nruns:\n    using: 'node20'\n    main: 'dist/index.js'\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#testing-your-adapter","title":"Testing Your Adapter","text":""},{"location":"packages/adapters/docs/adapter-development/#unit-tests","title":"Unit Tests","text":"<pre><code>// test/adapter.test.js\nconst MyToolAdapter = require('../src/adapter');\n\ndescribe('MyToolAdapter', () =&gt; {\n    it('should parse output correctly', () =&gt; {\n        const adapter = new MyToolAdapter({ sourceDir: 'force-app' });\n        const output = JSON.stringify({\n            id: '0Af123',\n            coverage: 85,\n            testResults: { total: 10, passed: 10, failed: 0 }\n        });\n\n        const result = adapter.parseOutput(output);\n        expect(result.coverage).toBe(85);\n    });\n\n    it('should build valid SARIF contract', () =&gt; {\n        const adapter = new MyToolAdapter({\n            sourceDir: 'force-app',\n            minCoverage: 75\n        });\n\n        const contract = adapter.buildContract('draft', {\n            deploymentId: '0Af123',\n            coverage: 85,\n            tests: { total: 10, passed: 10, failed: 0 },\n            componentsDeployed: 5\n        });\n\n        // Validate SARIF structure\n        expect(contract.version).toBe('2.1.0');\n        expect(contract.$schema).toContain('sarif-2.1.0');\n        expect(contract.runs).toHaveLength(1);\n        expect(contract.runs[0].tool.driver.name).toBe('glassops-mytool-adapter');\n\n        // Coverage above threshold should have no error results\n        expect(contract.runs[0].results).toHaveLength(0);\n    });\n\n    it('should add coverage violation when below threshold', () =&gt; {\n        const adapter = new MyToolAdapter({\n            sourceDir: 'force-app',\n            minCoverage: 75\n        });\n\n        const contract = adapter.buildContract('draft', {\n            deploymentId: '0Af123',\n            coverage: 65, // Below threshold\n            tests: { total: 10, passed: 10, failed: 0 },\n            componentsDeployed: 5\n        });\n\n        // Should have coverage violation result\n        expect(contract.runs[0].results).toHaveLength(1);\n        expect(contract.runs[0].results[0].ruleId).toBe('COVERAGE_THRESHOLD');\n        expect(contract.runs[0].results[0].level).toBe('error');\n    });\n});\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#integration-test","title":"Integration Test","text":"<pre><code>#!/bin/bash\n# test/integration-test.sh\n\nset -e\n\necho \"Running integration test...\"\n\n# Set up test environment\nexport GITHUB_ACTOR=\"test-user\"\nexport GITHUB_REPOSITORY=\"test/repo\"\nexport GITHUB_REF=\"refs/heads/main\"\nexport GITHUB_SHA=\"abc123\"\nexport GITHUB_RUN_ID=\"123\"\n\n# Run adapter\nnode src/index.js &lt;&lt;EOF\nsource-dir=force-app\ntest-level=RunLocalTests\nmin-coverage=75\nEOF\n\n# Validate contract exists\nif [ ! -f \".glassops/glassops-contract.sarif.json\" ]; then\n  echo \"\u274c Contract not generated\"\n  exit 1\nfi\n\n# Validate SARIF schema\nif ! jq -e '.version == \"2.1.0\"' .glassops/glassops-contract.sarif.json; then\n  echo \"\u274c Invalid SARIF version\"\n  exit 1\nfi\n\nif ! jq -e '.$schema | contains(\"sarif-2.1.0\")' .glassops/glassops-contract.sarif.json; then\n  echo \"\u274c Invalid SARIF schema reference\"\n  exit 1\nfi\n\necho \"\u2705 Integration test passed\"\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#adapter-development-checklist","title":"Adapter Development Checklist","text":"<p>Use this checklist to ensure your adapter is production-ready:</p>"},{"location":"packages/adapters/docs/adapter-development/#core-functionality","title":"Core Functionality","text":"<ul> <li>[ ] Implements <code>simulate()</code> function</li> <li>[ ] Implements <code>execute()</code> function</li> <li>[ ] Implements <code>normalizeError()</code> function</li> <li>[ ] Emits valid SARIF 2.1.0 JSON (validate against schema)</li> <li>[ ] Writes contract to <code>.glassops/glassops-contract.sarif.json</code></li> <li>[ ] Writes contract atomically (temp file + rename)</li> </ul>"},{"location":"packages/adapters/docs/adapter-development/#error-handling","title":"Error Handling","text":"<ul> <li>[ ] Handles tool crashes gracefully</li> <li>[ ] Handles timeout scenarios</li> <li>[ ] Handles network failures</li> <li>[ ] Handles invalid input</li> <li>[ ] Returns contract even on failure</li> </ul>"},{"location":"packages/adapters/docs/adapter-development/#contract-accuracy","title":"Contract Accuracy","text":"<ul> <li>[ ] Governance findings mapped to <code>results[]</code> array</li> <li>[ ] Deployment metadata in <code>invocations[].properties.glassops</code></li> <li>[ ] Tool information in <code>tool.driver</code> fields</li> <li>[ ] Error-level violations use <code>level: \"error\"</code></li> <li>[ ] File locations use relative paths from repo root</li> <li>[ ] Conforms to Adapter Interface</li> </ul>"},{"location":"packages/adapters/docs/adapter-development/#testing","title":"Testing","text":"<ul> <li>[ ] Unit tests for parsing logic</li> <li>[ ] Unit tests for contract building</li> <li>[ ] Integration test with real tool</li> <li>[ ] Tests failure scenarios</li> <li>[ ] Tests edge cases (zero coverage, no tests, etc.)</li> </ul>"},{"location":"packages/adapters/docs/adapter-development/#documentation","title":"Documentation","text":"<ul> <li>[ ] README with usage examples</li> <li>[ ] Error code reference</li> <li>[ ] Troubleshooting guide</li> <li>[ ] Comparison with other adapters</li> <li>[ ] Migration guide (if replacing existing tool)</li> </ul>"},{"location":"packages/adapters/docs/adapter-development/#distribution","title":"Distribution","text":"<ul> <li>[ ] Published to GitHub</li> <li>[ ] Tagged release with version</li> <li>[ ] action.yml correctly configured</li> <li>[ ] Dependencies properly declared</li> <li>[ ] License file included (Apache 2.0)</li> </ul>"},{"location":"packages/adapters/docs/adapter-development/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"packages/adapters/docs/adapter-development/#1-partial-contract-on-failure","title":"1. Partial Contract on Failure","text":"<p>Problem: Adapter crashes and leaves no contract.</p> <p>Solution: Always emit a contract, even on failure:</p> <pre><code>try {\n    const results = await deploy();\n    return buildContract('success', results);\n} catch (error) {\n    return buildContract('failed', null, error);\n}\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#2-non-atomic-writes","title":"2. Non-Atomic Writes","text":"<p>Problem: Governance layer reads partial JSON.</p> <p>Solution: Use temp file + rename:</p> <pre><code>const tempPath = `${contractPath}.tmp`;\nawait fs.writeFile(tempPath, JSON.stringify(contract));\nawait fs.rename(tempPath, contractPath); // Atomic\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#3-tool-specific-error-codes","title":"3. Tool-Specific Error Codes","text":"<p>Problem: Different adapters use different error formats.</p> <p>Solution: Normalize to standard codes:</p> <pre><code>const ERROR_CODES = {\n    COVERAGE_FAILURE: 'COVERAGE_BELOW_THRESHOLD',\n    TEST_FAILURE: 'TEST_EXECUTION_FAILED',\n    AUTH_FAILURE: 'AUTHENTICATION_FAILED'\n};\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#4-missing-audit-trail","title":"4. Missing Audit Trail","text":"<p>Problem: Can't trace back to source commit.</p> <p>Solution: Always include GitHub context:</p> <pre><code>audit: {\n  triggeredBy: process.env.GITHUB_ACTOR,\n  repository: process.env.GITHUB_REPOSITORY,\n  commit: process.env.GITHUB_SHA\n}\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#example-adapters","title":"Example Adapters","text":""},{"location":"packages/adapters/docs/adapter-development/#minimal-adapter-shell-script","title":"Minimal Adapter (Shell Script)","text":"<pre><code>#!/bin/bash\n# Simplest possible adapter using sf CLI\n\nset -e\n\nSOURCE_DIR=$1\nTEST_LEVEL=$2\nMIN_COVERAGE=${3:-75}\n\n# Simulate\nsf project deploy start \\\n  --source-dir \"$SOURCE_DIR\" \\\n  --test-level \"$TEST_LEVEL\" \\\n  --dry-run \\\n  --json &gt; deploy-result.json\n\n# Parse and build SARIF 2.1.0 contract\njq --arg minCov \"$MIN_COVERAGE\" '{\n  \"$schema\": \"https://schemastore.azurewebsites.net/schemas/json/sarif-2.1.0-rtm.5.json\",\n  \"version\": \"2.1.0\",\n  \"runs\": [{\n    \"tool\": {\n      \"driver\": {\n        \"name\": \"glassops-sf-adapter\",\n        \"version\": \"1.0.0\"\n      }\n    },\n    \"invocations\": [{\n      \"executionSuccessful\": (.result.success == true),\n      \"endTimeUtc\": (now | strftime(\"%Y-%m-%dT%H:%M:%SZ\")),\n      \"properties\": {\n        \"glassops\": {\n          \"deploymentId\": .result.id,\n          \"mode\": \"validate\"\n        }\n      }\n    }],\n    \"results\": (\n      if (.result.coverage &lt; ($minCov | tonumber)) then\n        [{\n          \"ruleId\": \"COVERAGE_THRESHOLD\",\n          \"level\": \"error\",\n          \"message\": {\n            \"text\": \"Coverage \\(.result.coverage)% below threshold \\($minCov)%\"\n          }\n        }]\n      else\n        []\n      end\n    )\n  }]\n}' deploy-result.json &gt; .glassops/glassops-contract.sarif.json\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#full-featured-adapter-nodejs","title":"Full-Featured Adapter (Node.js)","text":"<p>See the complete example in the Step-by-Step section above.</p>"},{"location":"packages/adapters/docs/adapter-development/#publishing-your-adapter","title":"Publishing Your Adapter","text":""},{"location":"packages/adapters/docs/adapter-development/#1-create-repository","title":"1. Create Repository","text":"<pre><code>gh repo create glassops-mytool-adapter --public\ngit init\ngit add .\ngit commit -m \"feat: initial adapter implementation\"\ngit branch -M main\ngit remote add origin https://github.com/yourusername/glassops-mytool-adapter.git\ngit push -u origin main\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#2-tag-a-release","title":"2. Tag a Release","text":"<pre><code>git tag -a v1.0.0 -m \"Release v1.0.0\"\ngit push origin v1.0.0\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#3-create-release-notes","title":"3. Create Release Notes","text":"<pre><code>## v1.0.0\n\n### Features\n\n- Initial implementation of MyTool adapter\n- Support for check-only and quick deploy\n- Normalized deployment contract\n\n### Usage\n\n\\`\\`\\`yaml\n\n- uses: yourusername/glassops-mytool-adapter@v1\n  with:\n  source-dir: force-app\n  \\`\\`\\`\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#4-submit-to-glassops-registry","title":"4. Submit to GlassOps Registry","text":"<p>Create a PR to <code>glassops-platform/adapters-registry</code>:</p> <pre><code># adapters/mytool.yml\nname: glassops-mytool-adapter\nauthor: Your Name\nrepository: yourusername/glassops-mytool-adapter\nversion: 1.0.0\ntool: MyTool\ndescription: Execute governed deployments using MyTool\n</code></pre>"},{"location":"packages/adapters/docs/adapter-development/#getting-help","title":"Getting Help","text":"<ul> <li>\ud83d\udcac Adapter Development Discussions</li> <li>\ud83d\udcd6 Contract Schema Reference</li> <li>\ud83d\udc1b Report Adapter Issues</li> <li>\ud83d\udce7 Direct questions: @rdbumstead</li> </ul>"},{"location":"packages/adapters/docs/adapter-development/#next-steps","title":"Next Steps","text":"<ol> <li>Review existing adapters for patterns</li> <li>Build a minimal proof-of-concept</li> <li>Test with real Salesforce org</li> <li>Share in Discussions for feedback</li> <li>Submit to registry when ready</li> </ol> <p>Thank you for contributing to the GlassOps ecosystem!</p>"},{"location":"packages/adapters/hardis/","title":"GlassOps Hardis Adapter","text":"<p>Important</p> <p>This adapter invokes sfdx-hardis, licensed under AGPL-3.0. Users must install and comply with the license terms. Failure to do so could result in legal obligations to provide source code to downstream users.</p> <p>High-Velocity Adapter for sfdx-hardis Version: 1.0 (Stable) Effective Date: 2026-01-24 Next Review: 2026-07-24</p> <p>Architecture Role: Integration Layer (Orchestrator) Phase: 4 (Execution)</p>"},{"location":"packages/adapters/hardis/#role-in-glassops-protocol","title":"Role in GlassOps Protocol","text":"<p>The Hardis Adapter wraps the powerful sfdx-hardis orchestration engine. It is designed for teams prioritizing velocity and automated release management simplification.</p> <p>This adapter bridges Hardis's opinionated workflows (like automated packaging and dependency handling) with the rigorous audit requirements of the GlassOps Protocol.</p>"},{"location":"packages/adapters/hardis/#data-flow","title":"\ud83d\udd04 Data Flow","text":"<pre><code>graph LR\n    Input[Git Branch] --&gt;|hardis:release| Hardis[Hardis Adapter]\n    Hardis --&gt;|Transform| Contract[SARIF 2.1.0]\n    Contract --&gt;|Enforce| ControlPlane[GlassOps Policy]</code></pre> <ol> <li>Input: Git Branch / Release Configuration</li> <li>Execution: <code>sf hardis:project:deploy</code> (Orchestrated)</li> <li>Output: SARIF 2.1.0 Governance Contract</li> </ol>"},{"location":"packages/adapters/hardis/#usage","title":"\ud83d\ude80 Usage","text":""},{"location":"packages/adapters/hardis/#github-actions","title":"GitHub Actions","text":"<pre><code>- name: Deploy with Hardis Adapter\n  uses: glassops-platform/glassops-hardis-adapter@v1\n  with:\n      org-alias: production\n      packaging-strategy: automated\n      policy-profile: high-velocity\n</code></pre>"},{"location":"packages/adapters/hardis/#governance-capabilities","title":"\ud83d\udee1\ufe0f Governance Capabilities","text":"Feature Supported Description Dependency Mgmt \u2705 Automatically validates package dependencies Incremental Deploy \u2705 Smart delta deployment mapped to SARIF audit Pre-Validation \u2705 Dry-run simulations included in contract"},{"location":"packages/adapters/hardis/#legal-compliance","title":"\u2696\ufe0f Legal &amp; Compliance","text":"<p>Layer: Integration (Adapter / CLI / Sidecar)</p> <p>Important</p> <p>User Obligation: Users integrating this adapter must ensure that any use of <code>sfdx-hardis</code> complies with AGPL-3.0, including providing access to source code to their downstream users as required by the license.</p>"},{"location":"packages/adapters/hardis/#compliance-checklist","title":"Compliance Checklist","text":"<ul> <li>[x] Runs as isolated process</li> <li>[x] No core linking</li> <li>[x] Official release used</li> <li>[x] License notice provided</li> </ul>"},{"location":"packages/adapters/hardis/#implementation-details","title":"Implementation Details","text":"<p>This adapter runs sfdx-hardis as an isolated subprocess. GlassOps does not modify, bundle, or redistribute sfdx-hardis. Users are responsible for installing a compliant version and ensuring AGPL-3.0 compliance, including making the tool\u2019s source code available to downstream users. Source is available at Hardis GitHub. No code is imported or linked into GlassOps binaries.</p> <p>See the <code>NOTICE</code> file for attribution information and license details.</p>"},{"location":"packages/adapters/hardis/adr/","title":"GlassOps SFDX-Hardis Adapter - Architecture Decision Records","text":"<p>This directory contains Architecture Decision Records (ADRs) specific to the SFDX-Hardis Adapter.</p>"},{"location":"packages/adapters/hardis/adr/#scope","title":"Scope","text":"<p>ADRs in this directory cover decisions related to:</p> <ul> <li>sfdx-hardis CLI integration patterns</li> <li>Quality gate mappings to SARIF</li> <li>Branch protection policy enforcement</li> <li>Metadata quality checks</li> <li>SARIF normalization from hardis outputs</li> </ul>"},{"location":"packages/adapters/hardis/adr/#current-adrs","title":"Current ADRs","text":"Number Title Status Date - No ADRs yet - -"},{"location":"packages/adapters/hardis/adr/#proposed-decisions-to-document","title":"Proposed Decisions to Document","text":"<ol> <li>Hardis Quality Gates \u2192 SARIF Mapping - How to map hardis checks to SARIF results</li> <li>Branch Protection Enforcement - When to block vs warn</li> <li>Metadata Quality Thresholds - What constitutes a violation</li> <li>Integration with Native Adapter - How to combine hardis + native results</li> <li>Performance vs Coverage Trade-off - Skip checks for speed?</li> </ol>"},{"location":"packages/adapters/hardis/adr/#adapter-specific-context","title":"Adapter-Specific Context","text":"<p>Purpose: Extends native Salesforce adapter with advanced quality gates via sfdx-hardis</p> <p>Key Characteristics:</p> <ul> <li>Wraps sfdx-hardis quality commands</li> <li>Emits SARIF 2.1.0 contracts</li> <li>Enforces metadata quality standards</li> <li>Supports branch protection policies</li> </ul> <p>Integration Points:</p> <ul> <li>Consumes: sfdx-hardis CLI</li> <li>Emits: SARIF 2.1.0 contracts to <code>.glassops/glassops-contract.sarif.json</code></li> <li>Can combine with: Native adapter results</li> </ul>"},{"location":"packages/adapters/hardis/adr/#creating-a-new-adr","title":"Creating a New ADR","text":"<p>See the Master ADR Index for the template and guidelines.</p> <p>Related Documentation:</p> <ul> <li>Master ADR Index</li> <li>Platform ADRs</li> <li>Adapter Development Guide</li> <li>SFDX-Hardis Adapter Package README</li> <li>SFDX-Hardis Documentation</li> </ul>"},{"location":"packages/adapters/hardis/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/adapters/megalinter/","title":"MegaLinter Scanner Adapter","text":"<p>Important</p> <p>This adapter invokes MegaLinter, licensed under AGPL-3.0. Users must install and comply with the license terms. Failure to do so could result in legal obligations to provide source code to downstream users.</p> <p>Version: 0.1 (Draft) Effective Date: 2026-01-24 Next Review: 2026-07-24 Architecture Role: Integration Layer (Scanner) Phase: 1.5 (Validation / Gate)</p>"},{"location":"packages/adapters/megalinter/#concept","title":"Concept","text":"<p>This adapter runs MegaLinter to perform static analysis on the codebase. It acts as the Phase 1.5 Gate, ensuring architectural validity before any deployment simulation occurs.</p>"},{"location":"packages/adapters/megalinter/#fail-fast-workflow","title":"Fail-Fast Workflow","text":"<pre><code>graph TD\n    A[PR Opened] --&gt; B[Phase 1.5: MegaLinter Scanner]\n    B --&gt; C{Pass Invariants?}\n    C -- No --&gt; D[BLOCK: Policy Violation]\n    C -- Yes --&gt; E[Phase 2: Simulation/Dry Run]\n    E --&gt; F[Phase 3: Governance Gate]\n    F --&gt; G[Phase 4: Execution/Quick Deploy]</code></pre>"},{"location":"packages/adapters/megalinter/#atomic-contract-integration","title":"Atomic Contract Integration","text":"<p>Since MegaLinter runs first, it is responsible for initializing the Deployment Contract.</p> <ul> <li>It must assume the contract does not exist.</li> <li>It must write the file atomically (write to temp \u2192 rename) to avoid race conditions.</li> <li>This contract serves as the atomic base, allowing subsequent steps to append their results safely.</li> </ul>"},{"location":"packages/adapters/megalinter/#security-governance-the-floor","title":"Security Governance (The Floor)","text":"<p>GlassOps enforces an absolute security floor using GitHub Environment variables.</p> <p>Example: <code>GLASSOPS_BLOCK_ON_SEVERITY=critical</code></p> <p>This ensures that even if a developer ignores a rule in their local config, the platform will block the deployment if a Critical severity issue is found.</p>"},{"location":"packages/adapters/megalinter/#contract-extension-proposed-v11","title":"Contract Extension (Proposed v1.1)","text":"<p>We will extend the <code>quality</code> object in the Deployment Contract:</p> <pre><code>{\n    \"quality\": {\n        \"staticAnalysis\": {\n            \"tool\": \"MegaLinter\",\n            \"format\": \"SARIF-2.1.0\",\n            \"summary\": {\n                \"critical\": 0,\n                \"high\": 2,\n                \"medium\": 5,\n                \"low\": 10\n            },\n            \"blockingViolations\": [],\n            \"met\": true\n        }\n    }\n}\n</code></pre>"},{"location":"packages/adapters/megalinter/#policy-configuration","title":"Policy Configuration","text":"<p>In <code>devops-config.json</code>:</p> <pre><code>\"governance\": {\n    \"staticAnalysis\": {\n        \"enabled\": true,\n        \"blockOn\": [\"critical\", \"high\"],\n        \"ignoreRules\": [\"apex-doc\"]\n    }\n}\n</code></pre>"},{"location":"packages/adapters/megalinter/#legal-compliance","title":"\u2696\ufe0f Legal &amp; Compliance","text":"<p>Layer: Integration (Adapter / CLI / Sidecar)</p> <p>Important</p> <p>User Obligation: Users integrating this adapter must ensure that any use of <code>MegaLinter</code> complies with AGPL-3.0, including providing access to source code to their downstream users as required by the license.</p>"},{"location":"packages/adapters/megalinter/#compliance-checklist","title":"Compliance Checklist","text":"<ul> <li>[x] Runs as isolated process</li> <li>[x] No core linking</li> <li>[x] Official release used</li> <li>[x] License notice provided</li> </ul>"},{"location":"packages/adapters/megalinter/#implementation-details","title":"Implementation Details","text":"<p>This adapter runs MegaLinter as an isolated subprocess. GlassOps does not modify, bundle, or redistribute MegaLinter. Users are responsible for installing a compliant version and ensuring AGPL-3.0 compliance, including making the tool\u2019s source code available to downstream users. Source is available at MegaLinter GitHub. No code is imported or linked into GlassOps binaries.</p> <p>See the <code>NOTICE</code> file for attribution information and license details.</p>"},{"location":"packages/adapters/megalinter/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/adapters/native/","title":"GlassOps Native Adapter","text":"<p>Note</p> <p>This adapter uses standard Salesforce CLI tooling. GlassOps manages governance envelopes but relies on the underlying CLI for execution.</p> <p>Governance-First Adapter for Salesforce CLI (<code>sf</code>)</p>"},{"location":"packages/adapters/native/#role-in-glassops-protocol","title":"Role in GlassOps Protocol","text":"<p>The Native Adapter is the reference implementation for bridging raw Salesforce CLI execution with the GlassOps Control Plane. It executes standard deployment commands while transparently normalizing results into the Universal SARIF Contract.</p> <p>Unlike black-box DevOps tools, this adapter provides maximum transparency\u2014you see exactly what <code>sf</code> commands are running, but with an added layer of governance enforcement.</p>"},{"location":"packages/adapters/native/#data-flow","title":"\ud83d\udd04 Data Flow","text":"<pre><code>graph LR\n    Input[Source Code] --&gt;|sf project deploy| Native[Native Adapter]\n    Native --&gt;|Transform| Contract[SARIF 2.1.0]\n    Contract --&gt;|Enforce| ControlPlane[GlassOps Policy]</code></pre> <ol> <li>Input: Salesforce Metadata (Source Format)</li> <li>Execution: <code>sf project deploy start</code> (System Native)</li> <li>Output: SARIF 2.1.0 Governance Contract (containing component success/failures, code coverage, and test results)</li> </ol>"},{"location":"packages/adapters/native/#usage","title":"\ud83d\ude80 Usage","text":""},{"location":"packages/adapters/native/#github-actions","title":"GitHub Actions","text":"<pre><code>- name: Deploy with Native Adapter\n  uses: glassops-platform/glassops-native-adapter@v1\n  with:\n      target-org: production\n      source-dir: force-app\n      test-level: RunLocalTests\n      wait: 30\n</code></pre>"},{"location":"packages/adapters/native/#governance-capabilities","title":"\ud83d\udee1\ufe0f Governance Capabilities","text":"Feature Supported Description Code Coverage \u2705 Enforces min-coverage policies defined in Control Plane Test Results \u2705 Normalizes JUnit output to SARIF results Component Manifest \u2705 Lists every component deployed in the immutable contract Rollback Support \u26a0\ufe0f Supports standard <code>sf</code> quick deploy rollbacks"},{"location":"packages/adapters/native/adr/","title":"GlassOps Native Adapter - Architecture Decision Records","text":"<p>This directory contains Architecture Decision Records (ADRs) specific to the Native Salesforce Adapter.</p>"},{"location":"packages/adapters/native/adr/#scope","title":"Scope","text":"<p>ADRs in this directory cover decisions related to:</p> <ul> <li>Salesforce CLI integration patterns</li> <li>JWT authentication strategy</li> <li>Deployment metadata extraction</li> <li>Test result normalization to SARIF</li> <li>Coverage threshold enforcement</li> <li>Error handling and retry logic</li> </ul>"},{"location":"packages/adapters/native/adr/#current-adrs","title":"Current ADRs","text":"Number Title Status Date - No ADRs yet - -"},{"location":"packages/adapters/native/adr/#proposed-decisions-to-document","title":"Proposed Decisions to Document","text":"<ol> <li>sf CLI vs @salesforce/core - Direct CLI wrapper vs library usage</li> <li>JWT Key Management - How to securely handle server.key</li> <li>SARIF Mapping Strategy - Deployment results \u2192 SARIF structure</li> <li>Coverage Calculation - Org-wide vs package-specific</li> <li>Deployment Timeout Handling - Async deployments and status polling</li> </ol>"},{"location":"packages/adapters/native/adr/#adapter-specific-context","title":"Adapter-Specific Context","text":"<p>Purpose: Provides native Salesforce deployment governance via <code>sf project deploy</code> commands</p> <p>Key Characteristics:</p> <ul> <li>Protocol-compliant SARIF emission</li> <li>Salesforce-native authentication (JWT-OAuth)</li> <li>Supports both mdapi and source formats</li> <li>Integrates with Salesforce test execution</li> </ul> <p>Integration Points:</p> <ul> <li>Consumes: Salesforce CLI (<code>sf</code>)</li> <li>Emits: SARIF 2.1.0 contracts to <code>.glassops/glassops-contract.sarif.json</code></li> <li>Authenticates: Via JWT (server.key + client ID)</li> </ul>"},{"location":"packages/adapters/native/adr/#creating-a-new-adr","title":"Creating a New ADR","text":"<p>See the Master ADR Index for the template and guidelines.</p> <p>Quick start:</p> <pre><code>cd glassops-adapters/glassops-native-adapter/docs/adr\n# Create new ADR\ncp ../../../../docs/adr/adr-template.md 001-your-decision-title.md\n# Edit the file\n# Update this README\n# Update ../../../../../docs/adr-index.md\n</code></pre> <p>Related Documentation:</p> <ul> <li>Master ADR Index</li> <li>Platform ADRs</li> <li>Adapter Development Guide</li> <li>Native Adapter Package README</li> </ul>"},{"location":"packages/adapters/native/docs/Dockerfile/","title":"Dockerfile Documentation: Native Adapter","text":"<p>This document details the Dockerfile located at <code>F:\\Github\\glassops\\packages\\adapters\\native\\Dockerfile</code>. It describes the build process, image layers, and instructions for building and running the container.</p>"},{"location":"packages/adapters/native/docs/Dockerfile/#base-image-and-rationale","title":"Base Image and Rationale","text":"<p>The Dockerfile employs a multi-stage build. The initial build stage is based on <code>golang:1.21-alpine</code>. This image is selected because it provides a lightweight environment with the Go toolchain pre-installed. Alpine Linux is a security-focused distribution known for its small size, reducing the final image size and attack surface. The second stage uses <code>alpine:3.19</code> for its minimal footprint and security benefits.</p>"},{"location":"packages/adapters/native/docs/Dockerfile/#build-stages","title":"Build Stages","text":"<p>The Dockerfile consists of two stages: <code>builder</code> and the final runtime stage.</p>"},{"location":"packages/adapters/native/docs/Dockerfile/#stage-1-builder","title":"Stage 1: <code>builder</code>","text":"<p>This stage is responsible for compiling the Go application.</p> <ul> <li><code>FROM golang:1.21-alpine AS builder</code>: Defines the base image for this stage as <code>golang:1.21-alpine</code> and assigns it the alias <code>builder</code>.</li> <li><code>WORKDIR /app</code>: Sets the working directory inside the container to <code>/app</code>.</li> <li><code>COPY go.mod go.sum ./</code>: Copies the <code>go.mod</code> and <code>go.sum</code> files to the working directory. These files define the project's dependencies.</li> <li><code>RUN go mod download</code>: Downloads the Go dependencies specified in <code>go.mod</code> and <code>go.sum</code>. This step is performed before copying the source code to leverage Docker's caching mechanism. If the dependency files haven't changed, this layer will be cached, speeding up subsequent builds.</li> <li><code>COPY . .</code>: Copies the entire source code to the working directory.</li> <li><code>RUN go build -o /adapter ./cmd/main.go</code>: Compiles the Go application located in <code>cmd/main.go</code> and outputs the executable to <code>/adapter</code>.</li> </ul>"},{"location":"packages/adapters/native/docs/Dockerfile/#stage-2-runtime-stage","title":"Stage 2: Runtime Stage","text":"<p>This stage creates the final container image with only the necessary runtime dependencies.</p> <ul> <li><code>FROM alpine:3.19</code>: Defines the base image for this stage as <code>alpine:3.19</code>.</li> <li><code>RUN apk add --no-cache ca-certificates git nodejs npm coreutils</code>: Installs required runtime dependencies using the Alpine package manager (<code>apk</code>). <code>--no-cache</code> prevents caching of package lists, further reducing image size. <code>ca-certificates</code> are essential for secure HTTPS connections. <code>git</code>, <code>nodejs</code>, <code>npm</code>, and <code>coreutils</code> are added to support the Salesforce CLI and any related functionalities.</li> <li><code>RUN npm install -g @salesforce/cli</code>: Installs the Salesforce CLI globally using npm.</li> <li><code>RUN addgroup -g 1000 glassops &amp;&amp; adduser -D -u 1000 -G glassops glassops</code>: Creates a non-root user named <code>glassops</code> with user ID (UID) and group ID (GID) of 1000. The <code>-D</code> flag prevents the creation of a home directory, further minimizing the image size. This enhances security by avoiding running the application as root.</li> <li><code>COPY --chown=glassops:glassops --from=builder /adapter /usr/local/bin/adapter</code>: Copies the compiled binary from the <code>builder</code> stage to <code>/usr/local/bin/adapter</code> and changes the ownership to the <code>glassops</code> user and group.</li> <li><code>USER glassops</code>: Specifies that the container should run as the <code>glassops</code> user.</li> <li><code>ENTRYPOINT [\"/usr/local/bin/adapter\"]</code>: Defines the entry point for the container, which is the compiled Go application.</li> </ul>"},{"location":"packages/adapters/native/docs/Dockerfile/#key-instructions-and-purpose","title":"Key Instructions and Purpose","text":"<ul> <li><code>FROM</code>: Specifies the base image for each stage.</li> <li><code>WORKDIR</code>: Sets the working directory inside the container.</li> <li><code>COPY</code>: Copies files and directories from the host machine to the container.</li> <li><code>RUN</code>: Executes commands inside the container.</li> <li><code>go mod download</code>: Downloads Go dependencies.</li> <li><code>go build</code>: Compiles the Go application.</li> <li><code>apk add</code>: Installs packages using the Alpine package manager.</li> <li><code>addgroup</code>, <code>adduser</code>: Creates a user and group.</li> <li><code>chown</code>: Changes the ownership of files and directories.</li> <li><code>USER</code>: Specifies the user to run the container as.</li> <li><code>ENTRYPOINT</code>: Defines the command to execute when the container starts.</li> </ul>"},{"location":"packages/adapters/native/docs/Dockerfile/#security-considerations","title":"Security Considerations","text":"<ul> <li>Non-Root User: The application runs as a non-root user (<code>glassops</code>), reducing the potential impact of security vulnerabilities.</li> <li>Minimal Base Images: Alpine Linux is used as the base image due to its small size and security focus.</li> <li>Dependency Caching: Caching Go dependencies speeds up builds and reduces the risk of downloading malicious packages.</li> <li><code>--no-cache</code> with <code>apk</code>: Prevents caching of package lists during installation, reducing image size and potential attack surface.</li> <li>HTTPS: The inclusion of <code>ca-certificates</code> ensures secure HTTPS connections.</li> </ul>"},{"location":"packages/adapters/native/docs/Dockerfile/#building-and-running-the-container","title":"Building and Running the Container","text":"<p>Building the image:</p> <p>You can build the Docker image using the following command:</p> <pre><code>docker build -t native-adapter .\n</code></pre> <p>This command builds the image and tags it as <code>native-adapter</code>.</p> <p>Running the container:</p> <p>You can run the container using the following command:</p> <pre><code>docker run -it --rm native-adapter\n</code></pre> <p>This command runs the container in interactive mode (<code>-it</code>), removes the container after it exits (<code>--rm</code>), and uses the <code>native-adapter</code> image. You may need to add volume mounts or environment variables depending on the application's requirements.</p>"},{"location":"packages/adapters/native/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/adapters/native/docs/cmd-main/","title":"Main Command","text":""},{"location":"packages/adapters/native/docs/cmd-main/#adapter-command-line-interface-documentation","title":"Adapter Command-Line Interface Documentation","text":"<p>This document describes the functionality and design of the adapter command-line interface (CLI). This CLI serves as an entry point for interacting with a native adapter, currently focused on Salesforce data. It provides commands to retrieve adapter information, transform data, and validate data.</p>"},{"location":"packages/adapters/native/docs/cmd-main/#package-purpose","title":"Package Purpose","text":"<p>The primary responsibility of this package is to provide a command-line interface for interacting with the adapter. It parses command-line arguments, invokes the appropriate adapter logic, and formats the output. This CLI acts as a bridge between external systems and the core adapter functionality.</p>"},{"location":"packages/adapters/native/docs/cmd-main/#key-types","title":"Key Types","text":"<p>The following types define the data structures used for communication:</p> <ul> <li><code>InfoResponse</code>: Represents the adapter's information, including its name, version, and supported capabilities.     <pre><code>type InfoResponse struct {\n    Name         string   `json:\"name\"`\n    Version      string   `json:\"version\"`\n    Capabilities []string `json:\"capabilities\"`\n}\n</code></pre></li> <li><code>TransformResponse</code>:  Encapsulates the result of a transformation operation, including status, adapter metadata, and output details.     <pre><code>type TransformResponse struct {\n    Status  string          `json:\"status\"`\n    Adapter AdapterMetadata `json:\"adapter\"`\n    Output  OutputMetadata  `json:\"output\"`\n}\n</code></pre></li> <li><code>AdapterMetadata</code>: Contains metadata about the adapter itself, such as its name, version, and the underlying data substrate.     <pre><code>type AdapterMetadata struct {\n    Name      string `json:\"name\"`\n    Version   string `json:\"version\"`\n    Substrate string `json:\"substrate\"`\n}\n</code></pre></li> <li><code>OutputMetadata</code>:  Provides details about the transformation output, including the path to the generated SARIF file, a trace ID, and any additional metadata.     <pre><code>type OutputMetadata struct {\n    SarifPath string                 `json:\"sarif_path\"`\n    TraceID   string                 `json:\"trace_id\"`\n    Metadata  map[string]interface{} `json:\"metadata\"`\n}\n</code></pre></li> </ul>"},{"location":"packages/adapters/native/docs/cmd-main/#important-functions","title":"Important Functions","text":"<ul> <li><code>main()</code>: This is the entry point of the application. It parses command-line arguments and dispatches execution to the appropriate handler function based on the provided command (<code>info</code>, <code>transform</code>, <code>validate</code>). If no command or an unknown command is provided, it prints usage instructions and exits.</li> <li><code>handleInfo()</code>:  This function handles the <code>info</code> command. It creates an <code>InfoResponse</code> object with the adapter's details and prints it as a JSON string to standard output.</li> <li><code>handleTransform()</code>: This function handles the <code>transform</code> command. It uses the <code>flag</code> package to parse command-line arguments specific to the transform operation (input path, output path, policy reference). It validates that the required <code>--input</code> and <code>--output</code> flags are provided. Currently, it includes a mock implementation that prints a message indicating the transformation process and then constructs and prints a <code>TransformResponse</code> object as a JSON string.</li> <li><code>handleValidate()</code>: This function handles the <code>validate</code> command. It uses the <code>flag</code> package to parse the <code>--input</code> flag. It validates that the <code>--input</code> flag is provided. Currently, it includes a mock implementation that prints a message indicating the validation process and then prints a simple JSON string indicating validation success with an empty violations list.</li> </ul>"},{"location":"packages/adapters/native/docs/cmd-main/#error-handling","title":"Error Handling","text":"<p>The CLI employs basic error handling:</p> <ul> <li>If the user provides insufficient arguments or an invalid command, an error message is printed to standard output, and the program exits with a non-zero exit code (1).</li> <li>Within <code>handleTransform</code> and <code>handleValidate</code>, missing required flags result in an error message and program exit.</li> <li>JSON marshaling errors are currently ignored (represented by the blank assignment <code>_</code> in <code>json.MarshalIndent</code>). In a production environment, these errors should be handled more robustly.</li> </ul>"},{"location":"packages/adapters/native/docs/cmd-main/#concurrency","title":"Concurrency","text":"<p>This CLI does not currently employ any concurrency patterns (goroutines or channels). All operations are performed sequentially within the <code>main</code> function and its handler functions.</p>"},{"location":"packages/adapters/native/docs/cmd-main/#design-decisions","title":"Design Decisions","text":"<ul> <li>Command-Based Structure: The CLI is structured around a command-based approach, allowing for easy extension with new functionalities in the future.</li> <li>Flag Parsing: The <code>flag</code> package is used for parsing command-line arguments, providing a standard and convenient way to handle options and parameters.</li> <li>JSON Output:  The CLI outputs data in JSON format, making it easy to integrate with other systems and tools.</li> <li>Mock Implementations: The <code>transform</code> and <code>validate</code> commands currently contain mock implementations. This allows for initial development and testing without requiring the full adapter logic to be implemented. You will need to replace these with actual adapter calls.</li> </ul>"},{"location":"packages/adapters/scanner/","title":"GlassOps Scanner Adapter","text":"<p>Note</p> <p>This adapter invokes scanning tools as external execution engines. GlassOps does not bundle, modify, or redistribute these tools. Users are responsible for providing compliant installations or images.</p> <p>Universal Code Quality Adapter (SARIF-Native)</p>"},{"location":"packages/adapters/scanner/#role-in-glassops-protocol","title":"Role in GlassOps Protocol","text":"<p>The Scanner Adapter is the \"eyes\" of the governance platform. It runs static analysis tools (PMD, ESLint, GraphEngine) and normalizes their heterogeneous outputs into a single, unified SARIF stream for policy evaluation.</p> <p>It is key to enforcing Architectural Decision Records (ADRs) as code limits (e.g., \"No DML in Loops\", \"Must use Logger class\").</p>"},{"location":"packages/adapters/scanner/#data-flow","title":"\ud83d\udd04 Data Flow","text":"<pre><code>graph LR\n    Input[Source Code] --&gt;|Scan| Engines[PMD / ESLint]\n    Engines --&gt;|Raw XML/JSON| Adapter[Scanner Adapter]\n    Adapter --&gt;|Normalize| Contract[SARIF 2.1.0]\n    Contract --&gt;|Evaluate| ControlPlane[GlassOps Policy]</code></pre> <ol> <li>Input: Source Code (Apex, JS, XML, etc.)</li> <li>Execution: Multi-engine analysis</li> <li>Output: SARIF 2.1.0 Governance Contract (Violations mapped to Blocking/Warning policies)</li> </ol>"},{"location":"packages/adapters/scanner/#usage","title":"\ud83d\ude80 Usage","text":""},{"location":"packages/adapters/scanner/#github-actions","title":"GitHub Actions","text":"<pre><code>- name: Governance Scan\n  uses: glassops-platform/glassops-scanner-adapter@v1\n  with:\n      target: force-app\n      engines: pmd, eslint, retire-js\n      severity-threshold: 2\n</code></pre>"},{"location":"packages/adapters/scanner/#governance-capabilities","title":"\ud83d\udee1\ufe0f Governance Capabilities","text":"Feature Supported Description ADR Enforcement \u2705 Maps static rules to Architectural Decision Records Security Gates \u2705 Blocks on CVEs and critical vulnerabilities Tech Debt Vis \u2705 Quantifies debt in the governance dashboard"},{"location":"packages/adapters/scanner/docs/","title":"GlassOps Scanner Adapter Documentation","text":"<ul> <li>Architecture Decision Records</li> </ul>"},{"location":"packages/adapters/scanner/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/adapters/scanner/docs/adr/","title":"GlassOps Scanner Adapter - Architecture Decision Records","text":"<p>This directory contains Architecture Decision Records (ADRs) specific to the Scanner Adapter.</p>"},{"location":"packages/adapters/scanner/docs/adr/#scope","title":"Scope","text":"<p>ADRs in this directory cover decisions related to:</p> <ul> <li>Static analysis tool integration (MegaLinter, Code Analyzer, etc.)</li> <li>SARIF aggregation from multiple scanners</li> <li>Scanner selection and prioritization</li> <li>Performance optimization (parallel execution)</li> <li>False positive filtering</li> </ul>"},{"location":"packages/adapters/scanner/docs/adr/#current-adrs","title":"Current ADRs","text":"Number Title Status Date - No ADRs yet - -"},{"location":"packages/adapters/scanner/docs/adr/#proposed-decisions-to-document","title":"Proposed Decisions to Document","text":"<ol> <li>MegaLinter vs Individual Linters - Orchestrator vs direct integration</li> <li>SARIF Aggregation Strategy - How to merge multiple SARIF outputs</li> <li>Scanner Priority/Weighting - Which findings take precedence</li> <li>Performance Optimization - Parallel vs sequential execution</li> <li>Baseline/Suppression Strategy - How to handle false positives</li> </ol>"},{"location":"packages/adapters/scanner/docs/adr/#adapter-specific-context","title":"Adapter-Specific Context","text":"<p>Purpose: Provides static analysis governance by orchestrating code quality scanners</p> <p>Key Characteristics:</p> <ul> <li>Orchestrates multiple static analysis tools</li> <li>Aggregates SARIF outputs from scanners</li> <li>Normalizes findings to common severity levels</li> <li>Supports incremental/differential scanning</li> </ul> <p>Integration Points:</p> <ul> <li>Consumes: MegaLinter, Salesforce Code Analyzer, ESLint, PMD, etc.</li> <li>Emits: Aggregated SARIF 2.1.0 contracts to <code>.glassops/glassops-contract.sarif.json</code></li> <li>Can filter: Based on baseline or suppression rules</li> </ul>"},{"location":"packages/adapters/scanner/docs/adr/#creating-a-new-adr","title":"Creating a New ADR","text":"<p>See the Master ADR Index for the template and guidelines.</p> <p>Related Documentation:</p> <ul> <li>Master ADR Index</li> <li>Platform ADRs</li> <li>Adapter Development Guide</li> <li>Scanner Adapter README</li> <li>MegaLinter Adapter Spec</li> </ul>"},{"location":"packages/control-plane/","title":"GlassOps Control Plane (<code>@glassops/control-plane</code>)","text":"<p>The Brain of the Operation.</p> <p>The Control Plane is responsible for Decision Making. It does not execute deployments; it decides if they should execute.</p>"},{"location":"packages/control-plane/#1-core-logic-policy-resolution","title":"1. Core Logic: Policy Resolution","text":"<p>The Control Plane implements the Additive Governance Model.</p> <pre><code>graph TD\n    A[GitHub Floor] --&gt;|75%| Merge\n    B[Team Config] --&gt;|80%| Merge\n    C[Org CMDT] --&gt;|90%| Merge\n    Merge --&gt;|Result: 90%| Effective[Effective Policy]</code></pre>"},{"location":"packages/control-plane/#the-invariant","title":"The Invariant","text":"<p>\"Policy can strictly be raised, never lowered.\"</p> <p>If GitHub says <code>minCoverage: 75</code>, a <code>devops-config.json</code> requesting <code>50</code> will be ignored (or blocked). The merge function is strictly <code>MAX(sources)</code>.</p>"},{"location":"packages/control-plane/#2-ingestion-sarif-specification","title":"2. Ingestion &amp; SARIF Specification","text":"<p>GlassOps standardizes on SARIF 2.1.0 for all governance findings.</p>"},{"location":"packages/control-plane/#21-why-sarif","title":"2.1 Why SARIF?","text":"<ol> <li>Standardization: Adopted by Microsoft, GitHub, Google.</li> <li>Interoperability: Visualized natively by GitHub Security tab.</li> <li>Future-Proofing: Compatible with future AI analysis tools.</li> </ol>"},{"location":"packages/control-plane/#22-standard-ingestion-payload","title":"2.2 Standard Ingestion Payload","text":"<p>The Control Plane accepts specific SARIF structures.</p> <pre><code>{\n    \"$schema\": \"https://schemastore.azurewebsites.net/schemas/json/sarif-2.1.0-rtm.5.json\",\n    \"version\": \"2.1.0\",\n    \"runs\": [\n        {\n            \"tool\": {\n                \"driver\": { \"name\": \"GlassOps Adapter\" }\n            },\n            \"results\": [\n                {\n                    \"ruleId\": \"GOV-001\",\n                    \"level\": \"error\",\n                    \"message\": { \"text\": \"Coverage 72% &lt; 75%\" },\n                    \"locations\": [\n                        {\n                            \"physicalLocation\": {\n                                \"artifactLocation\": { \"uri\": \"force-app/classes/AccountTrigger.cls\" }\n                            }\n                        }\n                    ]\n                }\n            ]\n        }\n    ]\n}\n</code></pre>"},{"location":"packages/control-plane/#23-cloudtrail-to-sarif-mapping","title":"2.3 CloudTrail to SARIF Mapping","text":"<p>For cloud events (like AWS CloudTrail), we map concepts as follows:</p> CloudTrail Field SARIF Field Meaning <code>eventName</code> <code>ruleId</code> The type of violation (e.g., UNAUTHORIZED_S3). <code>requestParameters</code> <code>physicalLocation</code> The resource that drifted. <code>userIdentity</code> <code>message</code> Who caused the drift."},{"location":"packages/control-plane/#3-data-model-storage","title":"3. Data Model &amp; Storage","text":"<ul> <li>Policy Store: Git (Versioned) + Object Storage (Snapshot).</li> <li>Audit Store: Immutable S3/Blob artifacts (SARIF + OTel trace links).</li> <li>Index: Lightweight SQL/DynamoDB pointer record (DeploymentID -&gt; ArtifactURI).</li> </ul>"},{"location":"packages/control-plane/#4-components","title":"4. Components","text":""},{"location":"packages/control-plane/#resolve-policy","title":"<code>resolve-policy</code>","text":"<ul> <li>Input: <code>devops-config.json</code>, GitHub Context.</li> <li>Output: <code>policy.json</code> (The rules for this run).</li> </ul>"},{"location":"packages/control-plane/#enforce-governance","title":"<code>enforce-governance</code>","text":"<ul> <li>Input: <code>deployment-contract.json</code> (From Adapter), <code>policy.json</code>.</li> <li>Output: <code>Pass</code> / <code>Fail</code>.</li> </ul>"},{"location":"packages/control-plane/adr/","title":"GlassOps Control Plane - Architecture Decision Records","text":"<p>This directory contains Architecture Decision Records (ADRs) specific to the GlassOps Control Plane.</p>"},{"location":"packages/control-plane/adr/#scope","title":"Scope","text":"<p>ADRs in this directory cover decisions related to:</p> <ul> <li>Control plane architecture and technology choices</li> <li>Policy store implementation</li> <li>Kubernetes operator patterns</li> <li>Multi-tenant isolation</li> <li>API design and versioning</li> </ul>"},{"location":"packages/control-plane/adr/#current-adrs","title":"Current ADRs","text":"Number Title Status Date - No ADRs yet - -"},{"location":"packages/control-plane/adr/#proposed-decisions-to-document","title":"Proposed Decisions to Document","text":"<ol> <li>Go vs Python for Control Plane - Language choice rationale</li> <li>PostgreSQL vs TimescaleDB - Policy store database selection</li> <li>Kubernetes Operator Pattern - CRD and controller design</li> <li>Multi-Tenant Isolation Strategy - Namespace vs cluster isolation</li> <li>Policy Resolution Algorithm - How effective policy is calculated</li> <li>API Versioning Strategy - v1alpha1, v1beta1, v1 progression</li> </ol>"},{"location":"packages/control-plane/adr/#creating-a-new-adr","title":"Creating a New ADR","text":"<p>See the Master ADR Index for the template and guidelines.</p> <p>Related Documentation:</p> <ul> <li>Master ADR Index</li> <li>Platform ADRs</li> <li>Control Plane Docs</li> </ul>"},{"location":"packages/control-plane/adr/001-kubernetes-operator-pattern/","title":"ADR 001: Kubernetes Operator Pattern","text":"<p>Status: Accepted Date: 2026-01-24 Context: GlassOps Control Plane Architecture</p>"},{"location":"packages/control-plane/adr/001-kubernetes-operator-pattern/#context","title":"Context","text":"<p>GlassOps needs a way to \"continuously reconcile\" the state of infrastructure against governance policy. We moved away from \"CI-only\" governance because CI is ephemeral. We need a persistent control plane.</p>"},{"location":"packages/control-plane/adr/001-kubernetes-operator-pattern/#decision","title":"Decision","text":"<p>We will implement the GlassOps Control Plane using the Kubernetes Operator Pattern.</p> <ul> <li>Policy as Data: Governance rules will be defined as Custom Resource Definitions (CRDs).</li> <li>Continuous Reconciliation: A custom Controller will watch these CRDs and enforce state.</li> <li>Event-Driven: The Operator will react to CloudEvents (Layer 3) to trigger reconciliation loops.</li> </ul>"},{"location":"packages/control-plane/adr/001-kubernetes-operator-pattern/#rationale","title":"Rationale","text":"<ol> <li>Drift Detection: Operators run in a loop. If someone manually changes a setting (drift), the Operator sees it and alerts/reverts. CI pipelines only run on commit.</li> <li>Kubernetes Native: Inherits K8s RBAC, audit logs, and scalability.</li> <li>Declarative Governance: Allows us to define <code>GovernancePolicy</code> objects that look like K8s manifests.</li> </ol>"},{"location":"packages/control-plane/adr/001-kubernetes-operator-pattern/#structure","title":"Structure","text":"<pre><code>apiVersion: glassops.io/v1alpha1\nkind: GovernancePolicy\nmetadata:\n    name: no-dml-in-loops\nspec:\n    enforcement: block\n    rules:\n        - engine: pmd\n          ruleId: 'OperationWithLimitsInLoop'\n</code></pre>"},{"location":"packages/control-plane/adr/001-kubernetes-operator-pattern/#consequences","title":"Consequences","text":"<ul> <li>Positive: Real-time governance, drift handling, standard API.</li> <li>Negative: Complexity. Requires a running K8s cluster (even if local via kind).</li> <li>Mitigation: The \"GlassOps Runtime\" (GitHub Action) can run without the Operator for simpler use cases (Level 1/2 adoption).</li> </ul> <p>Author: Ryan Bumstead</p>"},{"location":"packages/control-plane/adr/001-kubernetes-operator-pattern/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"packages/control-plane/docs/contract-contract/","title":"Contract contract","text":""},{"location":"packages/control-plane/docs/contract-contract/#deployment-contract-package-documentation","title":"Deployment Contract Package Documentation","text":"<p>This package defines the <code>DeploymentContract</code> data structure, which represents the complete state of a deployment operation within the system. It serves as a standardized format for communicating deployment results and associated metadata between different components of the platform. We designed this contract to provide a clear, consistent view of deployment outcomes, enabling effective monitoring, auditing, and decision-making.</p> <p>Key Types</p> <ul> <li> <p><code>DeploymentContract</code>: This is the central type. It encapsulates all information related to a deployment, including its status, quality metrics, and audit trail.</p> <ul> <li><code>SchemaVersion</code>: A string indicating the version of the contract schema used. This allows for future evolution of the contract without breaking compatibility.</li> <li><code>Meta</code>: Contains metadata about the deployment itself.</li> <li><code>Status</code>: A string representing the overall deployment status. Possible values include \"Succeeded\", \"Failed\", and \"Blocked\".</li> <li><code>Quality</code>: Holds quality-related metrics for the deployment.</li> <li><code>Audit</code>: Stores information about the deployment's origin and context.</li> </ul> </li> <li> <p><code>Meta</code>:  Provides contextual information about how the deployment was executed.</p> <ul> <li><code>Adapter</code>: The name of the adapter used to initiate the deployment.</li> <li><code>Engine</code>: The deployment engine used (e.g., \"native\", \"hardis\", \"custom\").</li> <li><code>Timestamp</code>: The time the deployment was triggered.</li> <li><code>Trigger</code>:  Indicates what caused the deployment (e.g., a pull request, a manual trigger).</li> </ul> </li> <li> <p><code>Quality</code>:  Aggregates quality assurance data.</p> <ul> <li><code>Coverage</code>:  Details about code coverage.<ul> <li><code>Actual</code>: The actual code coverage achieved.</li> <li><code>Required</code>: The minimum required code coverage.</li> <li><code>Met</code>: A boolean indicating whether the required coverage was met.</li> </ul> </li> <li><code>Tests</code>:  Information about the executed tests.<ul> <li><code>Total</code>: The total number of tests executed.</li> <li><code>Passed</code>: The number of tests that passed.</li> <li><code>Failed</code>: The number of tests that failed.</li> </ul> </li> <li><code>StaticAnalysis</code>: (Optional, introduced in Phase 1.5) Results from static analysis tools.</li> </ul> </li> <li> <p><code>StaticAnalysis</code>: Represents the output of static analysis tools like MegaLinter or similar scanners.</p> <ul> <li><code>Tool</code>: The name of the static analysis tool used.</li> <li><code>Met</code>: A boolean indicating whether the static analysis criteria were met.</li> <li><code>CriticalViolations</code>: The number of critical violations found.</li> <li><code>HighViolations</code>: The number of high-severity violations found.</li> <li><code>BlockingViolations</code>: A list of strings describing violations that are blocking the deployment.</li> </ul> </li> <li> <p><code>Audit</code>:  Provides traceability information.</p> <ul> <li><code>TriggeredBy</code>: The user or system that initiated the deployment.</li> <li><code>OrgID</code>: The organization ID associated with the deployment.</li> <li><code>Repository</code>: The repository where the code was deployed from.</li> <li><code>Commit</code>: The commit hash associated with the deployment.</li> </ul> </li> </ul> <p>Important Functions</p> <p>This package currently focuses on data structures and does not include any functions. Future iterations may include functions for validating or manipulating <code>DeploymentContract</code> instances.</p> <p>Error Handling</p> <p>This package does not currently define any error types or error handling logic. Error handling is expected to be implemented in the components that consume and process the <code>DeploymentContract</code> data.</p> <p>Concurrency</p> <p>This package does not employ any concurrency patterns (goroutines or channels) as it primarily defines data structures.</p> <p>Design Decisions</p> <ul> <li>Schema Versioning: The inclusion of <code>SchemaVersion</code> in the <code>DeploymentContract</code> is a deliberate design choice to support future evolution of the contract. This allows us to introduce changes without breaking compatibility with existing systems.</li> <li>Optional Static Analysis: The <code>StaticAnalysis</code> field is optional (<code>omitempty</code>) to accommodate scenarios where static analysis is not performed or not available.</li> <li>Clear Status Values: The <code>Status</code> field uses a limited set of predefined values (\"Succeeded\", \"Failed\", \"Blocked\") to ensure clarity and consistency in reporting deployment outcomes.</li> </ul>"},{"location":"packages/control-plane/docs/policy-policy/","title":"Policy policy","text":""},{"location":"packages/control-plane/docs/policy-policy/#policy-package-documentation","title":"Policy Package Documentation","text":"<p>This package manages the resolution and merging of security and governance policies. It provides a mechanism to combine locally defined policies with a baseline established by a remote source (represented by the GitHub Floor). The core principle is \u201cHighest Value Wins,\u201d meaning more restrictive settings take precedence.</p> <p>Package Responsibilities:</p> <ul> <li>Loading policy configurations from a file.</li> <li>Merging a local policy with a remote baseline (GitHub Floor).</li> <li>Ensuring minimum governance coverage requirements are met.</li> <li>Providing a structured representation of governance rules.</li> </ul> <p>Key Types:</p> <ul> <li><code>ProtocolConfig</code>: This is the top-level structure representing the complete policy configuration. It contains a single field, <code>Governance</code>.</li> <li><code>Governance</code>: This structure defines the core governance rules.<ul> <li><code>Enabled</code>: A boolean indicating whether governance checks are active.</li> <li><code>MinCoverage</code>: A float64 representing the minimum acceptable code coverage percentage. This value is influenced by the GitHub Floor.</li> <li><code>StaticAnalysis</code>: A <code>StaticAnalysis</code> struct containing settings for static code analysis.</li> <li><code>PluginWhitelist</code>: A slice of strings listing allowed plugins.</li> </ul> </li> <li><code>StaticAnalysis</code>: This structure configures static code analysis behavior.<ul> <li><code>Enabled</code>: A boolean indicating whether static analysis is enabled.</li> <li><code>BlockOn</code>: A slice of strings specifying severity levels that should block deployments (e.g., \u201ccritical\u201d, \u201chigh\u201d).</li> </ul> </li> </ul> <p>Important Functions:</p> <ul> <li><code>ResolvePolicy(localPath string, githubFloor float64) (ProtocolConfig, error)</code>: This function is the primary entry point for resolving the final policy configuration.<ul> <li><code>localPath</code>: The file path to the local policy configuration file (e.g., \u201cdevops-config.json\u201d).</li> <li><code>githubFloor</code>: The baseline minimum coverage value enforced by the remote source.</li> <li>Behavior:<ol> <li>It attempts to read and parse the policy from the specified <code>localPath</code>.</li> <li>If the file does not exist or parsing fails, it returns a <code>ProtocolConfig</code> with only the <code>MinCoverage</code> set to the <code>githubFloor</code> value. This provides a default policy.</li> <li>If the file is successfully parsed, it merges the local configuration with the <code>githubFloor</code>. Specifically, it ensures that the <code>MinCoverage</code> in the local configuration is not lower than the <code>githubFloor</code>. The <code>githubFloor</code> value always takes precedence.</li> <li>It returns the resolved <code>ProtocolConfig</code> and a potential error.</li> </ol> </li> </ul> </li> </ul> <p>Error Handling:</p> <ul> <li>The <code>ResolvePolicy</code> function returns an error if it fails to parse the JSON policy file. The error is wrapped using <code>fmt.Errorf</code> to provide context.</li> <li>If the policy file is missing, no error is returned; instead, a default configuration based on the <code>githubFloor</code> is returned.</li> </ul> <p>Design Decisions:</p> <ul> <li>Highest Value Wins: The merging strategy prioritizes more restrictive settings. This ensures that the final policy is at least as secure as the baseline.</li> <li>GitHub Floor as a Minimum: The <code>githubFloor</code> acts as a lower bound for <code>MinCoverage</code>. This prevents local configurations from relaxing security requirements below an acceptable level.</li> <li>Fallback Mechanism: The package provides a fallback to a default policy if the local configuration file is unavailable or invalid. This ensures that the system continues to operate with reasonable defaults.</li> </ul>"},{"location":"packages/control-plane/docs/resolver-main/","title":"Resolver main","text":""},{"location":"packages/control-plane/docs/resolver-main/#glassops-control-plane-resolver-documentation","title":"GlassOps Control Plane Resolver Documentation","text":"<p>This document describes the functionality of the GlassOps Control Plane Resolver, a command-line tool responsible for validating deployments against defined policies. It acts as a gatekeeper, ensuring deployments adhere to quality and architectural standards before proceeding.</p> <p>Package Purpose:</p> <p>The <code>main</code> package implements the core logic for the resolver. It reads a deployment contract generated by the runtime environment, resolves a relevant policy, and then enforces rules based on that policy against the contract data. If the deployment does not meet the policy requirements, the resolver blocks further progress.</p> <p>Key Types:</p> <ul> <li><code>contract.DeploymentContract</code>: This type, defined in the <code>github.com/glassops-platform/glassops-control-plane/internal/contract</code> package, represents the state of a deployment as reported by the runtime. It contains information about code coverage, static analysis results, and other quality metrics.</li> <li><code>policy.EffectivePolicy</code>: This type, defined in the <code>github.com/glassops-platform/glassops-control-plane/internal/policy</code> package, represents the resolved policy against which the deployment will be evaluated. It includes governance rules such as minimum code coverage and static analysis requirements.</li> </ul> <p>Important Functions:</p> <ul> <li><code>main()</code>: This is the entry point of the resolver. It performs the following steps:<ol> <li>Loads the Deployment Contract: Reads the deployment contract from the file <code>.glassops/deployment-contract.json</code>.  An error is logged and the program exits if the file is not found.</li> <li>Resolves Policy: Calls <code>policy.ResolvePolicy(\"devops-config.json\", 80.0)</code> to load and resolve a policy from the <code>devops-config.json</code> file, using a floor of 80% for policy enforcement. The resolved policy is stored in the <code>effPolicy</code> variable.</li> <li>Enforces Code Coverage Policy: Checks if the actual code coverage reported in the deployment contract (<code>dc.Quality.Coverage.Actual</code>) meets the minimum coverage requirement defined in the resolved policy (<code>effPolicy.Governance.MinCoverage</code>). If the coverage is insufficient, a message is printed to the console, and the program exits with a non-zero exit code (1).</li> <li>Enforces Static Analysis Policy: Checks if static analysis is enabled in the resolved policy (<code>effPolicy.Governance.StaticAnalysis.Enabled</code>) and if the deployment contract indicates that static analysis passed (<code>dc.Quality.StaticAnalysis.Met</code>). If static analysis is enabled and has not passed, a message is printed to the console, including the tool used for static analysis, and the program exits with a non-zero exit code (1).</li> <li>Reports Success: If all checks pass, a success message is printed to the console.</li> </ol> </li> </ul> <p>Error Handling:</p> <p>The resolver employs basic error handling. Specifically:</p> <ul> <li>File reading errors (when attempting to read the deployment contract) are handled by logging a fatal error message and exiting the program.</li> <li>The <code>policy.ResolvePolicy</code> function's error return is currently ignored. We should consider handling this error in a production environment.</li> <li>Policy violations result in informative error messages printed to the console, followed by program termination with a non-zero exit code.</li> </ul> <p>Concurrency:</p> <p>This version of the resolver does not employ concurrency (goroutines or channels). All operations are performed sequentially.</p> <p>Design Decisions:</p> <ul> <li>Policy as Code: The resolver leverages a policy-as-code approach, allowing governance rules to be defined and managed as configuration files.</li> <li>Contract-Based Governance: The use of a deployment contract provides a standardized way for the runtime environment to communicate deployment state to the resolver.</li> <li>Fail-Fast Principle: The resolver is designed to fail quickly if any policy violations are detected, preventing non-compliant deployments from proceeding.</li> <li>Configuration File Location: The deployment contract is expected to be located at a fixed path (<code>.glassops/deployment-contract.json</code>). The policy file is also expected to be at a fixed path (<code>devops-config.json</code>). You may need to adjust these paths based on your environment.</li> </ul>"},{"location":"packages/glassspec/","title":"GlassOps Protocol Specification (<code>@glassops-platform/glassspec</code>)","text":"<p>The Universal Language of Governance.</p> <p>This package defines the interfaces, schemas, and contracts that allow independent components to work together.</p>"},{"location":"packages/glassspec/#1-the-layered-contract-model","title":"1. The Layered Contract Model","text":"<p>GlassOps uses different standards for different signal types to avoid \"Square Peg, Round Hole\" problems.</p> Layer Standard Component Purpose 1. Governance SARIF 2.1.0 Policy Engine Static analysis, findings, violations. 2. Telemetry OpenTelemetry Observability Metrics (CPU, Duration) and Traces. 3. Transport CloudEvents Event Bus Lifecycle notifications (\"Deploy Started\"). 4. Native Native JSON/XML Edge Storage Raw tool data (AWS CloudTrail, Salesforce Metadata)."},{"location":"packages/glassspec/#the-invariant","title":"The Invariant","text":"<p>\"SARIF is Authoritative.\" If a finding is not in the SARIF contract, it does not exist for governance purposes.</p>"},{"location":"packages/glassspec/#2-adapter-interface","title":"2. Adapter Interface","text":"<p>GlassOps Adapters are stateless workers that translate Native output into the Layered Contract.</p>"},{"location":"packages/glassspec/#21-command-line-contract","title":"2.1 Command Line Contract","text":"<p>To be a compliant adapter, the container must accept standard arguments:</p> <pre><code># INPUT: The Policy to enforce\n--policy-in &lt;path/to/policy.json&gt;\n\n# OUTPUT: The Contract to emit\n--contract-out &lt;path/to/contract.json&gt;\n</code></pre>"},{"location":"packages/glassspec/#22-behavior-contract","title":"2.2 Behavior Contract","text":"<ol> <li>Stateless: Adapters must not store state between runs.</li> <li>Swallow Crashes: If the underlying tool crashes, the Adapter MUST catch it and emit a <code>Failed</code> Contract, not just exit 1.</li> <li>No Bypass: The Adapter must not offer flags to skip governance checks.</li> <li>Atomic Write: Write to a temp file and rename to avoid partial reads.</li> </ol>"},{"location":"packages/glassspec/#23-schema-mapping-native-sarif","title":"2.3 Schema Mapping (Native -&gt; SARIF)","text":"<p>Adapters must map tool concepts to SARIF fields:</p> Tool Concept SARIF Field Notes Violation ID <code>result.ruleId</code> Must be stable and queryable. Severity <code>result.level</code> Map to <code>error</code>, <code>warning</code>, <code>note</code>. Message <code>result.message.text</code> Human-readable explanation. File Path <code>physicalLocation.uri</code> Relative path from repo root."},{"location":"packages/glassspec/#3-deployment-contract-schema","title":"3. Deployment Contract Schema","text":"<p>File: <code>.glassops/deployment-contract.json</code></p> <p>Every adapter determines the deployment status by emitting this contract.</p> <pre><code>{\n    \"schemaVersion\": \"1.0\",\n    \"meta\": {\n        \"adapter\": \"glassops-native-adapter\",\n        \"version\": \"1.0.0\",\n        \"timestamp\": \"2026-01-25T12:00:00Z\"\n    },\n    \"status\": \"Succeeded\",\n    \"quality\": {\n        \"coverage\": {\n            \"actual\": 85,\n            \"required\": 75,\n            \"met\": true\n        },\n        \"tests\": {\n            \"total\": 120,\n            \"failed\": 0\n        }\n    },\n    \"policy\": {\n        \"source\": { \"githubFloor\": 75 },\n        \"effective\": 75\n    },\n    \"results\": [\n        // Array of SARIF result objects\n        {\n            \"ruleId\": \"GOV-001\",\n            \"level\": \"note\",\n            \"message\": { \"text\": \"Deployment passed all checks.\" }\n        }\n    ]\n}\n</code></pre>"},{"location":"packages/glassspec/#4-contributing","title":"4. Contributing","text":"<p>See <code>schemas/</code> directory for raw JSON Schema definitions.</p>"},{"location":"packages/glassspec/adr/","title":"GlassSpec Protocol - Architecture Decision Records","text":"<p>This directory contains Architecture Decision Records (ADRs) specific to the GlassSpec Protocol specification.</p>"},{"location":"packages/glassspec/adr/#scope","title":"Scope","text":"<p>ADRs in this directory cover decisions related to:</p> <ul> <li>Protocol specification and standards</li> <li>SARIF 2.1.0 adoption and usage</li> <li>Layered Contract Model design</li> <li>Anti-pattern definitions</li> <li>Protocol versioning strategy</li> </ul>"},{"location":"packages/glassspec/adr/#current-adrs","title":"Current ADRs","text":"Number Title Status Date 001 Layered Contract Model Accepted 2026-01-26"},{"location":"packages/glassspec/adr/#proposed-decisions-to-document","title":"Proposed Decisions to Document","text":"<ol> <li>SARIF 2.1.0 as Canonical Format - Why SARIF over custom schemas</li> <li>Layered Contract Model - SARIF + OTel + CloudEvents + Native</li> <li>Anti-Pattern Scope Boundaries - What NOT to normalize into SARIF</li> <li>Protocol Versioning Strategy - Semantic versioning for Protocol changes</li> <li>Adapter Interface Stability - Backward compatibility guarantees</li> </ol>"},{"location":"packages/glassspec/adr/#protocol-authority","title":"Protocol Authority","text":"<p>Important</p> <p>ADRs in this directory define the Protocol (Law), not the implementation.</p> <ul> <li>glassspec/protocol.md is authoritative</li> <li>glassspec/adapter-interface.md is canonical</li> <li>All implementations (glassops/, glassops-runtime/, glassops-control-plane/) must defer to these specifications</li> </ul>"},{"location":"packages/glassspec/adr/#creating-a-new-adr","title":"Creating a New ADR","text":"<p>See the Master ADR Index for the template and guidelines.</p> <p>Note</p> <p>Protocol ADRs require careful consideration as they affect the entire ecosystem.</p> <p>Related Documentation:</p> <ul> <li>Master ADR Index</li> <li>GlassOps ADRs</li> <li>GlassSpec Protocol</li> <li>Adapter Interface</li> </ul>"},{"location":"packages/glassspec/adr/001-layered-contract-model/","title":"ADR 001: Layered Contract Model","text":"<p>Status: Accepted Date: 2026-01-24 Context: GlassSpec Protocol Definition</p>"},{"location":"packages/glassspec/adr/001-layered-contract-model/#context","title":"Context","text":"<p>A core challenge in creating a \"Universal Governance Protocol\" is that no single data format fits all use cases.</p> <ul> <li>SARIF is excellent for static analysis and policy decisions but poor for time-series metrics.</li> <li>OpenTelemetry is the standard for metrics and traces but lacks the semantic richness for governance policy.</li> <li>CloudEvents is perfect for transport but doesn't define payload schemas.</li> <li>Native Logs (e.g., AWS CloudTrail types) are necessary for audit fidelity but impossible to govern consistently.</li> </ul> <p>Trying to force all these into one schema (e.g., \"Putting CPU metrics into SARIF properties\") leads to bloated, unqueryable contracts.</p>"},{"location":"packages/glassspec/adr/001-layered-contract-model/#decision","title":"Decision","text":"<p>We will adopt a Layered Contract Model that strictly separates concerns into four layers:</p> Layer Purpose Standard 1. Governance Decisions, Violations, Findings SARIF 2.1.0 2. Telemetry Metrics, Traces, Signals OpenTelemetry 3. Transport Events, Correlation CloudEvents 4. Native Raw edge data Native Schemas <p>All layers are linked by a common <code>correlation_id</code>.</p>"},{"location":"packages/glassspec/adr/001-layered-contract-model/#rationale","title":"Rationale","text":"<ol> <li>Separation of Concerns: Policies only evaluate Layer 1 (SARIF). Use dashboards for Layer 2 (OTel).</li> <li>Ecosystem Compatibility:<ul> <li>Security tools output SARIF natively.</li> <li>Observability tools consume OTel natively.</li> <li>Event buses route CloudEvents natively.</li> </ul> </li> <li>Governance Stability: The Governance Layer (Layer 1) changes slowly (human time). The Telemetry Layer (Layer 2) changes rapidly (machine time). Decoupling them prevents \"audit log noise.\"</li> </ol>"},{"location":"packages/glassspec/adr/001-layered-contract-model/#consequences","title":"Consequences","text":"<ul> <li>Positive: We stop fighting file formats. Metrics go where metrics belong.</li> <li>Negative: Requires correlation logic to link SARIF findings to OTel traces.</li> <li>Neutral: Adapters must be disciplined about what goes where (see- Original Protocol Spec).</li> </ul> <p>Author: Ryan Bumstead</p>"},{"location":"packages/glassspec/adr/001-layered-contract-model/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"packages/knowledge/","title":"GlassOps Knowledge Package","text":"<p>This package manages the Retrieval-Augmented Generation (RAG) pipeline for GlassOps. It handles document discovery, embedding generation, vector indexing, and drift detection.</p>"},{"location":"packages/knowledge/#structure","title":"Structure","text":"<ul> <li>ingestion/: Fetches and chunks markdown files from the monorepo.</li> <li>embeddings/: Generates vector embeddings using Google Gemini (via <code>google-generativeai</code>).</li> <li>drift/: Detects semantic drift in documentation over time.</li> <li>rag/: Provides a query engine for retrieving context-aware answers.</li> </ul>"},{"location":"packages/knowledge/#usage","title":"Usage","text":""},{"location":"packages/knowledge/#1-setup","title":"1. Setup","text":"<p>Ensure you have a <code>.env</code> file in the project root with your API key:</p> <pre><code>GOOGLE_API_KEY=your_key_here\n</code></pre>"},{"location":"packages/knowledge/#2-run-the-pipeline","title":"2. Run the Pipeline","text":"<p>To scan docs, generate embeddings, and update the index:</p> <pre><code># Using npm script (easiest)\nnpm run knowledge:pipeline\n</code></pre>"},{"location":"packages/knowledge/#3-query-the-knowledge-base","title":"3. Query the Knowledge Base","text":"<p>To avoid argument parsing issues with npm (especially on Windows), use the Python executable directly:</p> <pre><code># Direct Python command (Recommended)\npackages\\knowledge\\venv\\Scripts\\python.exe packages/knowledge/main.py --query \"What is the update policy for ADRs?\"\n\n# NPM alternative (may require extra escaping on Windows)\nnpm run knowledge:pipeline -- --query \"What is the update policy for ADRs?\"\n</code></pre>"},{"location":"packages/knowledge/#4-force-re-indexing","title":"4. Force Re-indexing","text":"<p>To force a full re-index:</p> <pre><code>npm run knowledge:pipeline -- --index\n</code></pre>"},{"location":"packages/knowledge/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/knowledge/docs/__init__/","title":"Init","text":""},{"location":"packages/knowledge/docs/__init__/#knowledge-package-documentation","title":"Knowledge Package Documentation","text":"<p>This package provides tools for building and maintaining a knowledge base, enabling applications to answer questions based on a collection of documents. It handles document ingestion, embedding generation, index creation, drift detection, and querying.</p> <p>Module Responsibilities:</p> <p>The <code>knowledge</code> package serves as the central component for managing document-based knowledge. It orchestrates the process of transforming raw documents into a searchable and queryable format. The core functionality revolves around creating and maintaining a vector index, which allows for efficient similarity searches.</p> <p>Key Components:</p> <p>The package exposes several key functions and is structured around distinct stages of the knowledge management process.</p> <ul> <li> <p><code>run_pipeline</code>: This is the primary entry point for the entire knowledge pipeline. It coordinates the ingestion, embedding, indexing, and drift detection steps. The specific behavior of this function is defined in the <code>main</code> module.</p> </li> <li> <p><code>get_embeddings_for_docs</code>: This function takes a list of documents as input and generates vector embeddings for each document. These embeddings represent the semantic meaning of the documents and are used for similarity searches. It returns a list of embeddings.</p> </li> <li> <p><code>discover_and_chunk_docs</code>: This function is responsible for locating documents from a specified source (e.g., a directory, a website) and splitting them into smaller, manageable chunks. This chunking process is important for handling large documents and improving search relevance. It returns a list of document chunks.</p> </li> <li> <p><code>build_or_update_index</code>: This function creates a vector index from a list of document embeddings. If an index already exists, it updates it with new or modified embeddings. This index is the core data structure used for querying.</p> </li> <li> <p><code>detect_drift</code>: This function monitors the knowledge base for concept drift, which occurs when the underlying data distribution changes over time. Detecting drift is important for maintaining the accuracy and relevance of the knowledge base. It returns a drift score or indicator.</p> </li> <li> <p><code>query_index</code>: This function allows you to search the vector index with a given query. It returns the most relevant documents or chunks based on semantic similarity.</p> </li> <li> <p><code>hash_file</code>: This utility function calculates a hash value for a given file. This is used to detect changes in documents and avoid re-processing unchanged files. It returns a string representing the file's hash.</p> </li> <li> <p><code>batch_items</code>: This utility function takes a list of items and divides them into smaller batches. This is useful for processing large datasets in a memory-efficient manner. It returns an iterator of batches.</p> </li> </ul> <p>Type Hints:</p> <p>The functions within this package are annotated with type hints. These hints specify the expected data types for function arguments and return values. This improves code readability, maintainability, and allows for static analysis to catch potential errors. For example, <code>get_embeddings_for_docs</code> might have a signature like <code>get_embeddings_for_docs(docs: List[str]) -&gt; List[List[float]]</code>, indicating that it takes a list of strings (documents) and returns a list of lists of floats (embeddings).</p> <p>Design Decisions:</p> <p>The package is designed with a modular approach, separating concerns into distinct functions and modules. This makes the code easier to understand, test, and maintain. The use of vector embeddings and a vector index allows for efficient similarity searches, enabling applications to quickly find relevant information. The drift detection functionality ensures that the knowledge base remains up-to-date and accurate over time. We aim for flexibility, allowing you to integrate different embedding models and data sources.</p>"},{"location":"packages/knowledge/docs/adapters-__init__/","title":"Adapters   init","text":""},{"location":"packages/knowledge/docs/adapters-__init__/#knowledge-adapter-package-documentation","title":"Knowledge Adapter Package Documentation","text":"<p>This package provides a set of language adapters designed to facilitate documentation generation from various source code formats. The core responsibility of these adapters is to parse code in a specific language and extract relevant information for documentation purposes.</p> <p>Key Classes and Roles:</p> <ul> <li><code>BaseAdapter</code>: This is an abstract base class that defines the common interface for all language adapters. All adapters inherit from <code>BaseAdapter</code> and must implement its abstract methods. It establishes a consistent way to interact with different codebases.</li> <li><code>GoAdapter</code>:  Specifically handles Go source code. It inherits from <code>BaseAdapter</code> and implements the necessary logic to parse Go files and extract documentation elements.</li> <li><code>PythonAdapter</code>:  Designed for Python source code. It parses Python files, recognizing docstrings and other relevant constructs for documentation.</li> <li><code>TypeScriptAdapter</code>:  Handles TypeScript code, parsing files to identify documentation comments and code structure.</li> <li><code>YAMLAdapter</code>:  Parses YAML files, extracting data and comments suitable for documentation.</li> <li><code>JSONAdapter</code>:  Processes JSON files, extracting data and potentially associated descriptions.</li> <li><code>DockerAdapter</code>:  Interprets Dockerfiles, extracting instructions and comments for documentation related to containerization.</li> <li><code>TerraformAdapter</code>:  Parses Terraform configuration files, extracting resource definitions and comments for infrastructure documentation.</li> <li><code>ApexAdapter</code>:  Handles Apex code (Salesforce\u2019s proprietary language), parsing files to extract documentation elements.</li> <li><code>LWCAdapter</code>:  Specifically designed for Lightning Web Component (LWC) code, parsing files to extract documentation.</li> </ul> <p>Important Functions and Behavior:</p> <p>The primary behavior of each adapter is defined by the methods inherited from <code>BaseAdapter</code>. These methods typically include:</p> <ul> <li>Parsing the source code.</li> <li>Extracting documentation elements (e.g., comments, docstrings).</li> <li>Transforming the extracted information into a standardized format.</li> </ul> <p>Each adapter implements these methods according to the specific syntax and conventions of the target language. The exact function signatures and behavior are defined within each adapter class.</p> <p>Type Hints:</p> <p>The code makes extensive use of type hints (e.g., <code>str</code>, <code>List[str]</code>). These hints improve code readability and maintainability. They allow for static analysis, helping to catch potential errors during development. They also serve as documentation, clearly indicating the expected data types for function arguments and return values.</p> <p>Design Decisions and Patterns:</p> <p>The package employs an adapter pattern. This pattern allows us to add support for new languages without modifying the core documentation generation logic. Each adapter encapsulates the language-specific parsing and extraction logic, providing a consistent interface to the rest of the system. The <code>BaseAdapter</code> class enforces this consistency.</p> <p>The <code>__all__</code> list explicitly defines the public interface of the package, controlling which classes and functions are imported when a user imports the <code>knowledge.adapters</code> module. This promotes a clean and well-defined API.</p>"},{"location":"packages/knowledge/docs/adapters-apex_adapter/","title":"Apex","text":""},{"location":"packages/knowledge/docs/adapters-apex_adapter/#apex-adapter-documentation","title":"Apex Adapter Documentation","text":"<p>This document details the functionality of the Apex Adapter, a component designed for generating documentation from Salesforce Apex code. It serves as an interface for processing Apex class and trigger files, preparing them for documentation generation by a language model.</p> <p>Module Responsibilities:</p> <p>The primary responsibility of this adapter is to read Apex code, split it into manageable chunks if necessary, and format it into a structure suitable for input to a documentation generation process. It also provides a prompt template tailored for instructing a language model to document Apex code effectively.</p> <p>Key Classes:</p> <ul> <li>ApexAdapter: This class inherits from the <code>BaseAdapter</code> and implements the specific logic for handling Apex files. It determines if a file can be processed, parses the file content into chunks, validates the content (currently a no-op), formats the chunks, and constructs a prompt for the language model.</li> </ul> <p>Important Functions:</p> <ul> <li><code>can_handle(file_path: Path) -&gt; bool</code>: This function checks if the adapter can process a given file based on its extension. It returns <code>True</code> if the file extension is <code>.cls</code> (Apex class) or <code>.trigger</code> (Apex trigger), and <code>False</code> otherwise. The <code>file_path</code> argument is a <code>Path</code> object representing the file's location.</li> <li><code>parse(file_path: Path, content: str) -&gt; List[str]</code>: This function takes the file path and content as input and splits the content into chunks if the content exceeds <code>TARGET_CHUNK_SIZE</code> (24000 characters). It returns a list of strings, where each string represents a chunk of the original content. The function ensures that chunks are created at logical breaks (newlines) to avoid splitting code mid-line. If the content is smaller than the target size, it returns a list containing the entire content as a single chunk.</li> <li><code>validate_content(content: str) -&gt; List[str]</code>: This function currently performs no validation and returns an empty list. It is reserved for future implementation of content validation checks.</li> <li><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>: This private function formats a single chunk of Apex code into a string that includes the file path, file type (Apex Class or Apex Trigger), and an optional part number if the content was split into multiple chunks. The code is enclosed in a Markdown code block with the <code>apex</code> language identifier.</li> <li><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>: This function constructs a prompt that will be sent to the language model. The prompt instructs the model to act as a Salesforce architect and document the provided Apex code, focusing on purpose, key methods, governor limits, integration points, and test coverage. It includes strict rules for the model\u2019s output, prohibiting conversational text, specific words, and the mention of certain names. The <code>parsed_content</code> argument is the Apex code chunk that will be documented.</li> </ul> <p>Type Hints:</p> <p>The code extensively uses type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; List[str]</code>) to improve code readability and maintainability. These hints specify the expected data types for function arguments and return values, enabling static analysis and helping to prevent type-related errors.</p> <p>Notable Patterns and Design Decisions:</p> <ul> <li>Adapter Pattern: The <code>ApexAdapter</code> follows the Adapter pattern, inheriting from a <code>BaseAdapter</code> class. This allows for a consistent interface for handling different file types and promotes code reusability.</li> <li>Chunking: The <code>parse</code> function implements a chunking mechanism to handle large Apex code files that might exceed the input limits of the language model. This ensures that the entire file can be processed, even if it requires splitting it into multiple parts.</li> <li>Markdown Formatting: The <code>_format_chunk</code> function formats the Apex code within Markdown code blocks, making it easy to render and display the code in documentation.</li> <li>Prompt Engineering: The <code>get_prompt</code> function is carefully crafted to provide clear instructions to the language model, guiding it to generate high-quality documentation that is specific to Apex code and Salesforce best practices.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-base/","title":"Base","text":""},{"location":"packages/knowledge/docs/adapters-base/#knowledge-adapter-base-class-documentation","title":"Knowledge Adapter Base Class Documentation","text":"<p>This document describes the base class for adapters used in the documentation generation process. These adapters are responsible for handling different programming languages or file types. The core purpose is to provide a consistent interface for parsing, prompting, and processing source code to create documentation.</p> <p>Module Responsibilities:</p> <p>The <code>knowledge.adapters.base</code> module defines an abstract base class, <code>BaseAdapter</code>, that all language-specific adapters must inherit from. This ensures that each adapter implements a standardized set of methods for interacting with source code and a language model.</p> <p>Key Classes:</p> <ul> <li><code>BaseAdapter</code>: This is an abstract base class (ABC) defining the interface for all documentation adapters. It cannot be instantiated directly. It enforces that any concrete adapter provides implementations for the <code>can_handle</code>, <code>parse</code>, <code>get_prompt</code>, <code>validate_content</code>, and <code>post_process</code> methods.</li> </ul> <p>Important Functions:</p> <ul> <li> <p><code>can_handle(file_path: Path) -&gt; bool</code>: This method determines if a specific adapter is capable of processing a given file. It takes the file path as input and returns <code>True</code> if the adapter supports the file type, and <code>False</code> otherwise. You should implement this to check file extensions or content types.</p> </li> <li> <p><code>parse(file_path: Path, content: str) -&gt; List[str]</code>: This method takes the file path and the raw content of the file as input. It is responsible for breaking down the content into smaller, manageable chunks suitable for processing by a language model. The method returns a list of strings, where each string represents a single chunk.</p> </li> <li> <p><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>: This method generates the prompt that will be sent to the language model. It takes the file path and a single chunk of parsed content as input. The prompt should be crafted to instruct the language model to generate documentation for the given content. It returns the prompt string.</p> </li> <li> <p><code>validate_content(content: str) -&gt; List[str]</code>: This method validates the input code content for potential issues like syntax errors or style violations. It accepts the code content as a string and returns a list of error messages. If the content is valid, it returns an empty list.</p> </li> <li> <p><code>post_process(file_path: Path, outputs: List[str]) -&gt; str</code>: This method combines the outputs generated by the language model for each chunk of code. It takes the file path and a list of output strings as input. The default implementation simply joins the outputs with double newlines (<code>\\n\\n</code>), but you can override this method to implement more sophisticated combination logic.</p> </li> </ul> <p>Type Hints:</p> <p>The code makes extensive use of type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; bool</code>). These hints improve code readability and allow for static analysis, helping to catch potential errors during development. The <code>Path</code> type from the <code>pathlib</code> module is used to represent file paths in a platform-independent manner. <code>List[str]</code> indicates a list containing strings.</p> <p>Design Decisions and Patterns:</p> <ul> <li>Abstract Base Class: The use of an abstract base class enforces a consistent interface for all adapters, promoting code maintainability and extensibility.</li> <li>Separation of Concerns: Each adapter is responsible for handling a specific language or file type, keeping the code modular and organized.</li> <li>Chunking: The <code>parse</code> method breaks down large files into smaller chunks to avoid exceeding the language model's input length limitations.</li> <li>Prompt Engineering: The <code>get_prompt</code> method allows for customization of the prompt sent to the language model, enabling fine-tuning of the documentation generation process.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-docker_adapter/","title":"Docker","text":""},{"location":"packages/knowledge/docs/adapters-docker_adapter/#dockerfile-adapter-documentation","title":"Dockerfile Adapter Documentation","text":"<p>This document details the functionality of the Dockerfile adapter, a component designed for automated documentation generation from Dockerfile content. It inherits from the <code>BaseAdapter</code> class and provides specific logic for handling Dockerfile files.</p> <p>Module Purpose:</p> <p>The primary responsibility of this module is to identify, parse, and prepare Dockerfile content for documentation generation by a larger system. It handles the specific characteristics of Dockerfiles, such as their typical small size and unique syntax.</p> <p>Key Classes:</p> <ul> <li><code>DockerAdapter</code>: This class is the core of the adapter. It extends <code>BaseAdapter</code> and implements the necessary methods to handle Dockerfile files.<ul> <li><code>TARGET_CHUNK_SIZE</code>: A constant set to 24000. While defined, it is currently unused due to the typical small size of Dockerfiles. It is included for potential future use if larger Dockerfiles require chunking.</li> </ul> </li> </ul> <p>Important Functions:</p> <ul> <li><code>can_handle(file_path: Path) -&gt; bool</code>: This function determines if the adapter can process a given file. It returns <code>True</code> if the filename is exactly \"Dockerfile\" or starts with \"Dockerfile.\", and <code>False</code> otherwise. The <code>file_path</code> argument is a <code>Path</code> object representing the file's location.</li> <li><code>parse(file_path: Path, content: str) -&gt; List[str]</code>: This function parses the Dockerfile content. Given a <code>file_path</code> (a <code>Path</code> object) and the <code>content</code> of the file (a string), it formats the entire content into a single chunk and returns it as a list containing that single chunk.  Because Dockerfiles are generally small, no chunking is performed.</li> <li><code>validate_content(content: str) -&gt; List[str]</code>: This function currently performs no validation and always returns an empty list. It is included for potential future content validation logic. The <code>content</code> argument is the Dockerfile content as a string.</li> <li><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>: This protected function formats a single chunk of Dockerfile content. It constructs a string that includes the filename (with a part number if applicable) and the content wrapped in a code block using the <code>dockerfile</code> language specifier. The <code>file_path</code> is a <code>Path</code> object, <code>content</code> is the chunk's content (string), and <code>part</code> is an optional integer indicating the chunk number.</li> <li><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>: This function generates a prompt to be used with a language model (like Gemma 12b IT) to document the Dockerfile. It constructs a detailed instruction set for the model, specifying the desired output format (Markdown), the information to extract (base image, stages, instructions, security, build/run instructions), and constraints (no conversational text, specific word restrictions, and exclusion of certain names). The <code>file_path</code> is a <code>Path</code> object, and <code>parsed_content</code> is the formatted Dockerfile content.</li> </ul> <p>Type Hints:</p> <p>The code extensively uses type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; List[str]</code>). These hints improve code readability and allow for static analysis, helping to catch potential errors during development.</p> <p>Design Decisions and Patterns:</p> <ul> <li>Adapter Pattern: The <code>DockerAdapter</code> follows the Adapter pattern, allowing the system to work with Dockerfiles in a standardized way without needing to know the specifics of the Dockerfile format.</li> <li>Chunking Strategy: The adapter currently avoids chunking Dockerfiles due to their typically small size. The <code>TARGET_CHUNK_SIZE</code> constant is retained for potential future expansion.</li> <li>Prompt Engineering: The <code>get_prompt</code> function demonstrates careful prompt engineering to guide the language model towards generating high-quality, focused documentation. The prompt includes explicit instructions on output format, content requirements, and constraints.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-go/","title":"Go","text":""},{"location":"packages/knowledge/docs/adapters-go/#go-adapter-documentation","title":"Go Adapter Documentation","text":"<p>This module provides an adapter for processing Go source files for documentation generation. It inherits from the <code>BaseAdapter</code> class and implements specific logic for parsing and validating Go code.</p> <p>Responsibilities:</p> <ul> <li>Identifying Go files based on their <code>.go</code> extension.</li> <li>Parsing Go file content into smaller chunks suitable for large language models.</li> <li>Validating Go code syntax using the <code>go fmt</code> tool.</li> <li>Formatting chunks with file context for inclusion in prompts.</li> <li>Constructing prompts for documentation generation.</li> </ul> <p>Key Classes:</p> <ul> <li><code>GoAdapter</code>: This class encapsulates the logic for handling Go files. It extends <code>BaseAdapter</code> and overrides methods to provide Go-specific functionality.</li> </ul> <p>Important Functions:</p> <ul> <li><code>can_handle(file_path: Path) -&gt; bool</code>:  Determines if the adapter can process a given file based on its extension. It returns <code>True</code> if the file has a <code>.go</code> extension, and <code>False</code> otherwise. The <code>file_path</code> argument is a <code>Path</code> object representing the file's location.</li> <li><code>parse(file_path: Path, content: str) -&gt; List[str]</code>: Parses the content of a Go file into a list of string chunks.  The function attempts to split the content at semantic boundaries, such as function or type declarations, to maintain context within each chunk. If the file is small enough, it returns a single chunk containing the entire content.  If semantic splitting isn't possible or the file is very large, it falls back to line-based chunking. The <code>file_path</code> argument is a <code>Path</code> object, and <code>content</code> is the string content of the file. The return value is a list of strings, where each string represents a chunk of the original content.</li> <li><code>validate_content(content: str) -&gt; List[str]</code>: Validates the Go code syntax using the <code>go fmt</code> tool. It checks if the <code>go</code> executable is available in the system's PATH. If <code>go fmt</code> reports errors, the function returns a list of error messages. If <code>go</code> is not found, it returns a message indicating that validation was skipped. The <code>content</code> argument is the string content of the Go file. The return value is a list of strings, where each string represents a validation error message.</li> <li><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>: Formats a chunk of Go code with file context. It adds the file path and an optional part number to the beginning of the chunk, and wraps the code in a markdown code block. The <code>file_path</code> argument is a <code>Path</code> object, <code>content</code> is the string content of the chunk, and <code>part</code> is an optional integer representing the chunk number. The return value is a formatted string.</li> <li><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>: Constructs a prompt for a large language model to generate documentation for the given Go code. The prompt includes instructions on the desired documentation style, focus areas (package purpose, key types, functions, error handling, concurrency), and strict rules for the output format. The <code>file_path</code> argument is a <code>Path</code> object, and <code>parsed_content</code> is the string content of the chunk to be documented. The return value is a string containing the prompt.</li> </ul> <p>Type Hints:</p> <p>The code makes extensive use of type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; List[str]</code>). These hints improve code readability and allow for static analysis, helping to catch potential errors during development.</p> <p>Notable Patterns and Design Decisions:</p> <ul> <li>Adapter Pattern: The <code>GoAdapter</code> class follows the adapter pattern, allowing the documentation generation system to work with Go files in a consistent manner, regardless of the specific file format.</li> <li>Chunking Strategy: The <code>parse</code> function employs a sophisticated chunking strategy that attempts to split the code at semantic boundaries to preserve context. This is important for generating accurate and meaningful documentation.</li> <li>External Tool Validation: The <code>validate_content</code> function leverages the <code>go fmt</code> tool for syntax validation, ensuring that only valid Go code is processed.</li> <li>Prompt Engineering: The <code>get_prompt</code> function carefully crafts a prompt that guides the large language model to generate high-quality documentation.</li> <li>Error Handling: The <code>validate_content</code> function includes robust error handling to gracefully handle cases where the <code>go</code> executable is not found or when <code>go fmt</code> encounters errors.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-json_adapter/","title":"JSON","text":""},{"location":"packages/knowledge/docs/adapters-json_adapter/#json-adapter-documentation","title":"JSON Adapter Documentation","text":"<p>This document describes the JSON Adapter, a component designed to process JSON files for documentation generation. It inherits from the <code>BaseAdapter</code> class and provides specific functionality for handling JSON-formatted content.</p> <p>Module Purpose:</p> <p>The primary responsibility of this module is to read, parse, validate, and format JSON files into chunks suitable for processing by a language model to generate technical documentation. It filters out common project files like <code>package.json</code> and <code>tsconfig.json</code> to avoid irrelevant documentation.</p> <p>Key Classes:</p> <ul> <li><code>JSONAdapter</code>: This class implements the adapter pattern for JSON files. It extends <code>BaseAdapter</code> and provides methods for determining if a file can be handled, parsing its content, validating its structure, and formatting it for input to a language model.</li> </ul> <p>Important Functions:</p> <ul> <li><code>can_handle(file_path: Path) -&gt; bool</code>:     This function determines whether the adapter can process a given file based on its path. It returns <code>True</code> if the file has a <code>.json</code> extension and is not one of the excluded files (<code>package.json</code>, <code>package-lock.json</code>, <code>tsconfig.json</code>). The <code>file_path</code> argument is a <code>Path</code> object representing the file's location.</li> <li><code>parse(file_path: Path, content: str) -&gt; List[str]</code>:     This function parses the content of a JSON file and splits it into chunks if the content exceeds <code>TARGET_CHUNK_SIZE</code> (24000 characters). It iterates through the lines of the content, building chunks until the <code>TARGET_CHUNK_SIZE</code> is reached. The <code>file_path</code> argument is a <code>Path</code> object, and <code>content</code> is a string containing the file's content. The function returns a list of strings, where each string represents a chunk of the file content.</li> <li><code>validate_content(content: str) -&gt; List[str]</code>:     This function validates the JSON syntax of the provided content. It attempts to parse the content using <code>json.loads()</code>. If the parsing is successful, it returns an empty list, indicating no errors. If a <code>json.JSONDecodeError</code> occurs, it returns a list containing an error message with details about the syntax error, including the error message and line number. The <code>content</code> argument is a string containing the JSON content.</li> <li><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>:     This is a helper function that formats a chunk of JSON content into a string suitable for input to a language model. It includes the file path and an optional part number in the formatted string. The <code>file_path</code> argument is a <code>Path</code> object, <code>content</code> is the chunk of JSON content, and <code>part</code> is an optional integer representing the chunk number. The function returns a formatted string.</li> <li><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>:     This function constructs a prompt for a language model, instructing it to document the provided JSON schema or data structure. The prompt includes specific instructions regarding the desired output format (Markdown), content focus (data representation, required/optional fields, use cases), and restrictions (no conversational text, no mention of specific names, no emojis, and avoidance of certain words). The <code>file_path</code> argument is a <code>Path</code> object, and <code>parsed_content</code> is the JSON content to be documented. The function returns a string containing the prompt.</li> </ul> <p>Type Hints:</p> <p>The code extensively uses type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; List[str]</code>). These hints improve code readability and allow for static analysis, helping to catch potential errors during development.</p> <p>Notable Patterns and Design Decisions:</p> <ul> <li>Adapter Pattern: The <code>JSONAdapter</code> class implements the adapter pattern, allowing the documentation generation process to work with different file types in a consistent manner.</li> <li>Chunking: The <code>parse</code> function splits large JSON files into smaller chunks to avoid exceeding the input limits of the language model.</li> <li>Error Handling: The <code>validate_content</code> function provides basic JSON syntax validation and returns informative error messages.</li> <li>Prompt Engineering: The <code>get_prompt</code> function carefully crafts a prompt to guide the language model towards generating high-quality documentation.</li> <li>File Exclusion: The <code>can_handle</code> function excludes common project files that are not relevant for documentation.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-lwc_adapter/","title":"LWC","text":""},{"location":"packages/knowledge/docs/adapters-lwc_adapter/#lightning-web-component-lwc-adapter-documentation","title":"Lightning Web Component (LWC) Adapter Documentation","text":"<p>This document details the functionality of the LWC Adapter, a component within a larger documentation generation system. It is responsible for processing Salesforce Lightning Web Component files (.js, .html, .css) and preparing them for documentation creation using large language models.</p> <p>Module Purpose:</p> <p>The LWC Adapter serves as a bridge between the core documentation generation pipeline and Salesforce\u2019s LWC technology. It handles file identification, content parsing into manageable chunks, basic content validation, and prompt engineering for optimal documentation results.</p> <p>Key Classes:</p> <ul> <li><code>LWCAdapter</code>: This class inherits from <code>BaseAdapter</code> and implements the specific logic for handling LWC files. It encapsulates the parsing, validation, and formatting processes tailored to LWC structures.</li> </ul> <p>Important Functions:</p> <ul> <li><code>can_handle(file_path: Path) -&gt; bool</code>:  This function determines if the adapter is capable of processing a given file. It checks if the file path contains \"lwc\" in its parts (indicating it resides within an LWC directory) and if the file extension is one of the supported types: \".js\", \".html\", or \".css\". The <code>file_path</code> argument is a <code>Path</code> object representing the file's location.</li> <li><code>parse(file_path: Path, content: str) -&gt; List[str]</code>: This function takes the file path and content of an LWC file as input and splits the content into smaller chunks. This is necessary because large language models have input length limitations. The <code>TARGET_CHUNK_SIZE</code> constant (set to 24000 characters) defines the maximum size of each chunk. The function returns a list of strings, where each string represents a chunk of the original content.</li> <li><code>validate_content(content: str) -&gt; List[str]</code>: This function performs basic validation of the LWC content. Currently, it checks for valid XML syntax if the content appears to be an HTML template (starts with <code>&lt;template</code>).  If the content is not valid XML, it returns a list containing an error message.  It returns an empty list if validation passes.</li> <li><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>: This is a helper function that formats a chunk of LWC content into a string suitable for inclusion in a prompt to a language model. It includes the file path, an optional part number (if the content was chunked), and wraps the content in a code block with the appropriate language identifier (javascript, html, or css).</li> <li><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>: This function constructs a prompt that will be sent to a language model (like Gemma 12b IT) to generate documentation for the LWC file. The prompt instructs the model to act as a Salesforce Lightning expert and to document the component's purpose, properties, wire adapters, event handling, lifecycle hooks, and CSS styling. It includes strict rules for the model's output, prohibiting conversational text, emojis, and specific words. The <code>parsed_content</code> argument is a string representing the content of the LWC file.</li> </ul> <p>Type Hints:</p> <p>The code extensively uses type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; List[str]</code>). These hints improve code readability and allow for static analysis, helping to catch potential errors during development.</p> <p>Notable Patterns and Design Decisions:</p> <ul> <li>Adapter Pattern: The <code>LWCAdapter</code> follows the Adapter pattern, inheriting from a <code>BaseAdapter</code> class. This allows for a consistent interface for handling different file types and promotes code reusability.</li> <li>Chunking: The <code>parse</code> function implements a chunking mechanism to handle large files that exceed the input limits of large language models.</li> <li>Prompt Engineering: The <code>get_prompt</code> function demonstrates careful prompt engineering to guide the language model towards generating high-quality documentation. The prompt includes specific instructions, constraints, and a clear definition of the desired output format.</li> <li>Content Validation: The <code>validate_content</code> function provides a basic level of content validation to prevent errors during documentation generation.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-python/","title":"Python","text":""},{"location":"packages/knowledge/docs/adapters-python/#python-adapter-documentation","title":"Python Adapter Documentation","text":"<p>This module provides a language adapter for generating documentation from Python source files. It is designed to be part of a larger documentation generation system.</p> <p>Responsibilities:</p> <p>The <code>PythonAdapter</code> handles the parsing, chunking, validation, and prompt formatting specific to Python code. It prepares Python source code for processing by a language model to produce documentation.</p> <p>Key Classes:</p> <ul> <li><code>PythonAdapter</code>: This class inherits from <code>BaseAdapter</code> and implements the logic for handling Python files. It defines methods for determining if a file can be handled, parsing the file content into chunks, validating the content, and formatting prompts for a language model.</li> </ul> <p>Important Functions:</p> <ul> <li> <p><code>can_handle(file_path: Path) -&gt; bool</code>:     This function checks if the adapter can handle a given file based on its extension. It returns <code>True</code> if the file has a <code>.py</code> extension, and <code>False</code> otherwise.</p> </li> <li> <p><code>parse(file_path: Path, content: str) -&gt; List[str]</code>:     This function parses the content of a Python file into smaller chunks. It aims to split the content intelligently, respecting class and function boundaries to maintain context. The <code>TARGET_CHUNK_SIZE</code> constant (set to 24000 characters, approximately 6k tokens) controls the maximum size of each chunk. If the file content is smaller than this size, it returns a single chunk containing the entire content. Otherwise, it splits the content into multiple chunks, attempting to break at logical points (e.g., the end of a function or class definition) to avoid splitting code in the middle of a statement. The function returns a list of strings, where each string represents a chunk of the original content.</p> </li> <li> <p><code>validate_content(content: str) -&gt; List[str]</code>:     This function validates the Python content using the <code>ast</code> (Abstract Syntax Trees) module. It checks for syntax errors and, potentially, undefined variables. If any errors are found, they are returned as a list of error messages. Currently, the undefined variable check is disabled to reduce false positives with code snippets.</p> </li> <li> <p><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>:     This is a helper function that formats a chunk of Python code with file context. It adds a header indicating the file path and, if applicable, the chunk number. The code content is enclosed in a code block using backticks.</p> </li> <li> <p><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>:     This function constructs a prompt for a language model. The prompt includes instructions for the model, specifying its role as a principal architect and outlining the desired documentation style and content. It also includes the parsed content of the Python file.</p> </li> </ul> <p>Type Hints:</p> <p>The code makes extensive use of type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; List[str]</code>). These hints improve code readability and allow for static analysis, helping to catch potential errors during development.</p> <p>Notable Patterns and Design Decisions:</p> <ul> <li>Adapter Pattern: The <code>PythonAdapter</code> follows the adapter pattern, inheriting from a <code>BaseAdapter</code> class. This allows for easy extension to support other languages by creating new adapter classes.</li> <li>Chunking Strategy: The <code>parse</code> function employs a line-based chunking strategy with awareness of code structure. This approach balances the need to keep chunks within a manageable size for the language model with the desire to preserve context.</li> <li>Error Handling: The <code>validate_content</code> function includes basic error handling to catch syntax errors and potential issues with the Python code.</li> <li>Prompt Engineering: The <code>get_prompt</code> function carefully crafts a prompt to guide the language model in generating high-quality documentation. The prompt includes specific instructions, constraints, and a clear definition of the desired output format.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-terraform_adapter/","title":"Terraform","text":""},{"location":"packages/knowledge/docs/adapters-terraform_adapter/#terraform-adapter-documentation","title":"Terraform Adapter Documentation","text":"<p>This document details the Terraform Adapter, a component designed for generating documentation from Terraform configuration files. It is part of a larger system for knowledge management and documentation across various infrastructure-as-code formats.</p> <p>Module Purpose and Responsibilities</p> <p>The Terraform Adapter\u2019s primary responsibility is to ingest Terraform files (.tf extension), split them into manageable chunks if necessary, and prepare them for processing by a language model. It also formats the input for the language model with a specific prompt designed to elicit detailed documentation. The adapter handles file-specific parsing and formatting, abstracting away the details of the Terraform language from the core documentation generation process.</p> <p>Key Classes and Their Roles</p> <ul> <li>TerraformAdapter: This class inherits from the <code>BaseAdapter</code> class and implements the adapter-specific logic for Terraform files. It defines how Terraform files are identified, parsed, and formatted for documentation generation.</li> </ul> <p>Important Functions and Their Behavior</p> <ul> <li><code>can_handle(file_path: Path) -&gt; bool</code>: This function determines if the adapter can process a given file based on its extension. It returns <code>True</code> if the file path\u2019s suffix is \".tf\", indicating a Terraform file, and <code>False</code> otherwise.</li> <li><code>parse(file_path: Path, content: str) -&gt; List[str]</code>: This function takes the file path and content of a Terraform file as input. It splits the content into chunks if the file exceeds <code>TARGET_CHUNK_SIZE</code> (currently 24000 characters). Each chunk is then formatted using the <code>_format_chunk</code> method. The function returns a list of strings, where each string represents a chunk of the Terraform configuration. If the content is smaller than the target size, it returns a list containing a single formatted chunk.</li> <li><code>validate_content(content: str) -&gt; List[str]</code>: This function currently returns an empty list. It is intended for future implementation of content validation checks specific to Terraform files.</li> <li><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>: This private helper function formats a chunk of Terraform configuration into a string suitable for input to the language model. It includes the file path and an optional part number if the file was split into multiple chunks. The content is wrapped in a code block using the HCL (HashiCorp Configuration Language) syntax highlighter.</li> <li><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>: This function constructs the prompt that is sent to the language model. The prompt instructs the model to act as an Infrastructure as Code expert and document the provided Terraform configuration. It specifies the areas of focus for the documentation (resources, variables, outputs, dependencies, security) and includes strict rules for the model\u2019s output, prohibiting conversational text, emojis, and specific words. It also explicitly forbids mentioning the project name.</li> </ul> <p>Type Hints and Their Significance</p> <p>The code extensively uses type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; List[str]</code>). These hints improve code readability and maintainability by clearly specifying the expected data types for function arguments and return values. They also enable static analysis tools to catch type-related errors during development.</p> <p>Notable Patterns or Design Decisions</p> <ul> <li>Adapter Pattern: The <code>TerraformAdapter</code> follows the adapter pattern, allowing the system to work with different infrastructure-as-code formats without modifying the core documentation generation logic.</li> <li>Chunking: The <code>parse</code> function implements a chunking mechanism to handle large Terraform files that might exceed the input limits of the language model. This ensures that even large configurations can be processed.</li> <li>Prompt Engineering: The <code>get_prompt</code> function demonstrates careful prompt engineering to guide the language model towards generating high-quality, focused documentation. The prompt includes specific instructions and constraints to ensure the desired output format and content.</li> <li>HCL Highlighting: The <code>_format_chunk</code> function uses HCL syntax highlighting to improve the readability of the Terraform code within the documentation.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-typescript/","title":"Typescript","text":""},{"location":"packages/knowledge/docs/adapters-typescript/#typescript-adapter-documentation","title":"TypeScript Adapter Documentation","text":"<p>This module provides an adapter for processing TypeScript and JavaScript source files during documentation generation. It is designed to split files into manageable chunks and format them for input to a language model. The adapter\u2019s functionality is inspired by a TypeScript implementation.</p> <p>Responsibilities:</p> <ul> <li>Determine if a file can be handled based on its extension.</li> <li>Parse file content into chunks of a defined size.</li> <li>Format chunks with file context for inclusion in prompts.</li> <li>Provide a base for content validation (currently a placeholder).</li> <li>Construct a prompt for a language model to generate documentation.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-typescript/#typescriptadapter-class","title":"TypeScriptAdapter Class","text":"<p>The <code>TypeScriptAdapter</code> class inherits from <code>BaseAdapter</code> and implements the core logic for handling TypeScript and JavaScript files.</p> <p>Attributes:</p> <ul> <li><code>TARGET_CHUNK_SIZE</code>: An integer representing the maximum size of a chunk in characters (currently 24000). This value is intended to correspond to approximately 6000 tokens.</li> </ul> <p>Methods:</p> <ul> <li> <p><code>can_handle(file_path: Path) -&gt; bool</code>:     This method checks if the adapter can handle a given file based on its extension. It returns <code>True</code> if the file extension is one of <code>.ts</code>, <code>.js</code>, <code>.mjs</code>, <code>.tsx</code>, or <code>.jsx</code>; otherwise, it returns <code>False</code>.</p> </li> <li> <p><code>parse(file_path: Path, content: str) -&gt; List[str]</code>:     This method parses the content of a TypeScript or JavaScript file into a list of chunks. It splits the content into chunks that are no larger than <code>TARGET_CHUNK_SIZE</code>. If the entire content is smaller than <code>TARGET_CHUNK_SIZE</code>, it returns a list containing a single chunk with the entire content. The method iterates through the lines of the content, adding them to the current chunk until the <code>TARGET_CHUNK_SIZE</code> is exceeded. It then creates a new chunk and continues.</p> </li> <li> <p><code>validate_content(content: str) -&gt; List[str]</code>:     This method is currently a placeholder for content validation. It always returns an empty list. We intend to add functionality to validate the TypeScript content in future versions.</p> </li> <li> <p><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>:     This private method formats a chunk of content with file context. It adds the file path and an optional part number to the beginning of the chunk, and wraps the content in a code block with the <code>typescript</code> language identifier. The <code>part</code> argument is used to indicate the chunk number when a file is split into multiple chunks.</p> </li> <li> <p><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>:     This method constructs a prompt for a language model. The prompt instructs the model to act as a principal architect and translate the provided TypeScript/JavaScript code into high-level documentation. It includes specific instructions regarding the desired output format and constraints, such as avoiding certain words and phrases. The <code>parsed_content</code> is inserted directly into the prompt.</p> </li> </ul>"},{"location":"packages/knowledge/docs/adapters-typescript/#type-hints","title":"Type Hints","text":"<p>The code makes extensive use of type hints to improve code readability and maintainability. For example:</p> <ul> <li><code>file_path: Path</code> indicates that the <code>file_path</code> argument should be a <code>Path</code> object.</li> <li><code>content: str</code> indicates that the <code>content</code> argument should be a string.</li> <li><code>-&gt; List[str]</code> indicates that the method returns a list of strings.</li> </ul> <p>These type hints help to prevent errors and make the code easier to understand.</p>"},{"location":"packages/knowledge/docs/adapters-typescript/#design-decisions","title":"Design Decisions","text":"<ul> <li>Chunking Strategy: The <code>parse</code> method uses a line-based chunking strategy to avoid splitting lines of code. This helps to maintain the integrity of the code and makes it easier to understand.</li> <li>File Context: The <code>_format_chunk</code> method adds file context to each chunk, which helps the language model to understand the origin of the code.</li> <li>Prompt Engineering: The <code>get_prompt</code> method carefully crafts a prompt that instructs the language model to generate high-quality documentation. The prompt includes specific instructions regarding the desired output format and constraints.</li> </ul>"},{"location":"packages/knowledge/docs/adapters-yaml_adapter/","title":"YAML","text":""},{"location":"packages/knowledge/docs/adapters-yaml_adapter/#yaml-adapter-documentation","title":"YAML Adapter Documentation","text":"<p>This document details the functionality of the YAML Adapter, a component designed for processing YAML configuration files within a documentation generation pipeline. It handles parsing, validation, and formatting of YAML content to prepare it for documentation by a language model.</p> <p>Module Responsibilities:</p> <p>The primary responsibility of this module is to read YAML files, split them into manageable chunks if they exceed a defined size limit, validate their syntax, and format them into a prompt suitable for a language model. This adapter ensures that large YAML files can be processed without exceeding the context window limitations of the language model.</p> <p>Key Classes:</p> <ul> <li> <p><code>YAMLAdapter</code>: This class inherits from <code>BaseAdapter</code> and implements the specific logic for handling YAML files. It encapsulates the parsing, validation, and formatting processes.</p> <ul> <li><code>TARGET_CHUNK_SIZE</code>: A class-level constant set to 24000, defining the maximum size (in characters) of a single chunk of YAML content. This value is used to split large files into smaller, more manageable pieces.</li> </ul> </li> </ul> <p>Important Functions:</p> <ul> <li> <p><code>can_handle(file_path: Path) -&gt; bool</code>: This function determines whether the adapter can process a given file based on its extension. It returns <code>True</code> if the file path has a <code>.yml</code> or <code>.yaml</code> extension, and <code>False</code> otherwise. The <code>file_path</code> argument is a <code>Path</code> object representing the file's location.</p> </li> <li> <p><code>parse(file_path: Path, content: str) -&gt; List[str]</code>: This function parses the YAML content of a file and splits it into chunks if necessary. It takes the <code>file_path</code> (a <code>Path</code> object) and the file <code>content</code> (a string) as input. If the content's length is within the <code>TARGET_CHUNK_SIZE</code>, it returns a list containing the entire content formatted as a single chunk. Otherwise, it splits the content into multiple chunks, ensuring no chunk exceeds the size limit. Each chunk is then formatted using the <code>_format_chunk</code> function. The function returns a list of strings, where each string represents a chunk of YAML content.</p> </li> <li> <p><code>validate_content(content: str) -&gt; List[str]</code>: This function validates the YAML syntax of the provided content. It attempts to parse the <code>content</code> (a string) using <code>yaml.safe_load()</code>. If the parsing is successful, it returns an empty list, indicating no errors. If a <code>yaml.YAMLError</code> occurs, it catches the exception and returns a list containing an error message describing the syntax error.</p> </li> <li> <p><code>_format_chunk(file_path: Path, content: str, part: int = None) -&gt; str</code>: This is a helper function that formats a single chunk of YAML content into a string suitable for inclusion in a prompt. It takes the <code>file_path</code> (a <code>Path</code> object), the <code>content</code> (a string), and an optional <code>part</code> number (an integer) as input. It constructs a string that includes the file path, an optional part number (e.g., \" (Part 1)\"), and the YAML content enclosed in a code block.</p> </li> <li> <p><code>get_prompt(file_path: Path, parsed_content: str) -&gt; str</code>: This function generates a prompt for the language model, incorporating the parsed YAML content. It takes the <code>file_path</code> (a <code>Path</code> object) and the <code>parsed_content</code> (a string) as input. The prompt instructs the language model to act as a DevOps engineer and technical writer, documenting the provided YAML configuration. It emphasizes the need for valid Markdown output and explicitly prohibits certain phrasing and content.</p> </li> </ul> <p>Type Hints:</p> <p>The code extensively uses type hints (e.g., <code>file_path: Path</code>, <code>content: str</code>, <code>-&gt; List[str]</code>). These hints improve code readability and allow for static analysis, helping to catch potential errors during development. They clearly define the expected data types for function arguments and return values.</p> <p>Design Decisions and Patterns:</p> <ul> <li>Adapter Pattern: The <code>YAMLAdapter</code> class follows the Adapter pattern, allowing the system to work with YAML files without needing to know the specifics of the YAML format. This promotes loose coupling and makes it easy to add support for other configuration file types in the future.</li> <li>Chunking: The implementation of chunking addresses the limitation of language model context windows. By splitting large YAML files into smaller chunks, the adapter ensures that the entire file can be processed without exceeding the model's capacity.</li> <li>Validation: The inclusion of YAML syntax validation helps to prevent errors and ensures that the language model receives valid input.</li> <li>Prompt Engineering: The <code>get_prompt</code> function demonstrates careful prompt engineering, providing clear instructions to the language model and specifying desired output characteristics.</li> </ul>"},{"location":"packages/knowledge/docs/config-config/","title":"Knowledge Configuration","text":"<p>This document details the configuration options for the knowledge retrieval system. This system powers intelligent responses within the GlassOps platform by indexing documentation and providing relevant context to language models.</p>"},{"location":"packages/knowledge/docs/config-config/#overview","title":"Overview","text":"<p>The configuration file defines how documentation is processed, stored, and retrieved. It specifies the embedding models used to create vector representations of the documentation, the vector database for storage, the source locations for documentation, and parameters controlling the retrieval process.</p>"},{"location":"packages/knowledge/docs/config-config/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"packages/knowledge/docs/config-config/#embedding_models","title":"<code>embedding_models</code>","text":"<p>This section configures the embedding models used to convert text into vector representations.</p> <ul> <li><code>primary</code> (string, required): Specifies the primary embedding model.  Currently set to <code>gemini-embedding-1.0</code>. This model is preferred for generating embeddings.</li> <li><code>fallback</code> (string, required): Specifies a fallback embedding model. Currently set to <code>gemma-3-12b-it</code>. This model is used if the primary model is unavailable or encounters an error.</li> </ul>"},{"location":"packages/knowledge/docs/config-config/#vector_store","title":"<code>vector_store</code>","text":"<p>This section configures the vector database used to store and retrieve document embeddings.</p> <ul> <li><code>type</code> (string, required): Specifies the type of vector database. Currently set to <code>chroma</code>.</li> <li><code>persist_dir</code> (string, required): Specifies the directory where the vector database will store its data. Currently set to <code>glassops-index</code>.  You should ensure this directory is writable.</li> </ul>"},{"location":"packages/knowledge/docs/config-config/#federated_doc_paths","title":"<code>federated_doc_paths</code>","text":"<p>This is a list of file paths or glob patterns that define the locations of documentation to be indexed.</p> <ul> <li><code>federated_doc_paths</code> (array of strings, required):  Each string represents a path or pattern.<ul> <li><code>docs/</code>: Indexes the main documentation directory.</li> <li><code>packages/**/adr</code>: Indexes Architecture Decision Records (ADR) within any package.</li> <li><code>packages/**/docs</code>: Indexes documentation within any package.</li> </ul> </li> </ul>"},{"location":"packages/knowledge/docs/config-config/#retrieval_triggers","title":"<code>retrieval_triggers</code>","text":"<p>This section maps specific query types (triggers) to a specific documentation file.</p> <ul> <li><code>audit</code> (string, required): Path to the drift report for \"audit\" related queries.</li> <li><code>backup</code> (string, required): Path to the drift report for \"backup\" related queries.</li> <li><code>legacy</code> (string, required): Path to the drift report for \"legacy\" related queries.</li> <li><code>overlap</code> (string, required): Path to the drift report for \"overlap\" related queries.</li> <li><code>drift</code> (string, required): Path to the drift report for \"drift\" related queries.</li> </ul> <p>All triggers currently point to <code>packages/knowledge/docs/generated/drift_report.md</code>.</p>"},{"location":"packages/knowledge/docs/config-config/#batch_size","title":"<code>batch_size</code>","text":"<p>This parameter controls the number of documents processed in each batch during indexing.</p> <ul> <li><code>batch_size</code> (integer, required):  Currently set to <code>10</code>.  Adjusting this value can impact indexing performance.</li> </ul>"},{"location":"packages/knowledge/docs/config-config/#drift_threshold","title":"<code>drift_threshold</code>","text":"<p>This parameter defines the threshold for determining significant drift between documentation versions.</p> <ul> <li><code>drift_threshold</code> (float, required): Currently set to <code>0.85</code>. This value is used in the drift report generation process.</li> </ul>"},{"location":"packages/knowledge/docs/config-config/#system_context","title":"<code>system_context</code>","text":"<p>This parameter provides the initial context given to the language model when answering questions.</p> <ul> <li><code>system_context</code> (string, required): A multi-line string that sets the role of the language model and provides information about the documentation structure and how to handle specific query types (overlap, backup, legacy, drift).  It instructs the model to prioritize the <code>drift_report.md</code> file when relevant queries are detected.</li> </ul>"},{"location":"packages/knowledge/docs/config-prompts/","title":"Prompts Configuration Documentation","text":"<p>This YAML file configures the prompts used by the GlassOps documentation agent. It defines different system and user prompts for various adapter types, allowing the agent to generate documentation tailored to specific file types and technologies.</p>"},{"location":"packages/knowledge/docs/config-prompts/#structure","title":"Structure","text":"<p>The file is structured around a top-level key <code>prompts</code>. This key contains a dictionary where each key represents an adapter type (e.g., <code>go</code>, <code>py</code>, <code>ts</code>).  A special key <code>_shared_rules</code> defines common instructions applied to all prompts. A <code>default</code> adapter is also provided as a fallback.</p>"},{"location":"packages/knowledge/docs/config-prompts/#key-definitions","title":"Key Definitions","text":""},{"location":"packages/knowledge/docs/config-prompts/#prompts","title":"<code>prompts</code>","text":"<p>The main container for all prompt configurations.</p>"},{"location":"packages/knowledge/docs/config-prompts/#_shared_rules","title":"<code>_shared_rules</code>","text":"<p>This key holds a string containing a set of strict rules that are prepended to every system prompt. These rules govern the style and content of the generated documentation.  The rules include constraints on language, formatting, and attribution.  The value is a multi-line string.</p>"},{"location":"packages/knowledge/docs/config-prompts/#adapter-types-go-py-ts-yml-json-dockerfile-tf-apex-lwc-default","title":"Adapter Types (<code>go</code>, <code>py</code>, <code>ts</code>, <code>yml</code>, <code>json</code>, <code>dockerfile</code>, <code>tf</code>, <code>apex</code>, <code>lwc</code>, <code>default</code>)","text":"<p>Each adapter type defines a <code>system</code> and <code>user</code> prompt.</p>"},{"location":"packages/knowledge/docs/config-prompts/#system","title":"<code>system</code>","text":"<p>A string containing instructions for the language model. This prompt defines the role the model should assume (e.g., \"principal architect\", \"DevOps engineer\") and the specific tasks it should perform.  It also includes the <code>{{shared_rules}}</code> placeholder, which is replaced with the content of the <code>_shared_rules</code> key during prompt construction.  The <code>system</code> prompt emphasizes generating only the document content, avoiding conversational elements.</p>"},{"location":"packages/knowledge/docs/config-prompts/#user","title":"<code>user</code>","text":"<p>A string containing the instructions for the user. This prompt provides the context for the documentation task, typically including a placeholder <code>{{content}}</code> where the file content to be documented will be inserted.</p>"},{"location":"packages/knowledge/docs/config-prompts/#go","title":"<code>go</code>","text":"<p>Configures the documentation generation for Go source code. The system prompt instructs the model to act as a principal architect and platform engineer, focusing on package purpose, key types, functions, error handling, and concurrency.</p>"},{"location":"packages/knowledge/docs/config-prompts/#py","title":"<code>py</code>","text":"<p>Configures documentation for Python source code. The system prompt instructs the model to act as a principal architect and AI/ML expert, focusing on module purpose, classes, functions, type hints, and design patterns.</p>"},{"location":"packages/knowledge/docs/config-prompts/#ts","title":"<code>ts</code>","text":"<p>Configures documentation for TypeScript/JavaScript files. The system prompt instructs the model to act as a principal architect, emphasizing a pristine and coherent document.</p>"},{"location":"packages/knowledge/docs/config-prompts/#yml","title":"<code>yml</code>","text":"<p>Configures documentation for YAML configuration files. The system prompt instructs the model to act as a DevOps engineer and technical writer, focusing on the purpose, structure, and key controls of the configuration.</p>"},{"location":"packages/knowledge/docs/config-prompts/#json","title":"<code>json</code>","text":"<p>Configures documentation for JSON schemas or data structures. The system prompt instructs the model to act as a technical documentation expert, focusing on data representation, required fields, and use cases.</p>"},{"location":"packages/knowledge/docs/config-prompts/#dockerfile","title":"<code>dockerfile</code>","text":"<p>Configures documentation for Dockerfiles. The system prompt instructs the model to act as a DevOps expert, focusing on the base image, stages, instructions, security, and build/run processes.</p>"},{"location":"packages/knowledge/docs/config-prompts/#tf","title":"<code>tf</code>","text":"<p>Configures documentation for Terraform configurations. The system prompt instructs the model to act as an Infrastructure as Code expert, focusing on resources, variables, outputs, dependencies, and security.</p>"},{"location":"packages/knowledge/docs/config-prompts/#apex","title":"<code>apex</code>","text":"<p>Configures documentation for Salesforce Apex code. The system prompt instructs the model to act as a Salesforce architect, focusing on class/trigger purpose, methods, governor limits, and integration points.</p>"},{"location":"packages/knowledge/docs/config-prompts/#lwc","title":"<code>lwc</code>","text":"<p>Configures documentation for Salesforce Lightning Web Components. The system prompt instructs the model to act as a Salesforce Lightning expert, focusing on component purpose, properties, wire adapters, event handling, and lifecycle hooks.</p>"},{"location":"packages/knowledge/docs/config-prompts/#default","title":"<code>default</code>","text":"<p>Provides a fallback configuration for file types not explicitly defined. It instructs the model to act as a principal architect and generate a high-level document.</p>"},{"location":"packages/knowledge/docs/drift-__init__/","title":"Drift   init","text":""},{"location":"packages/knowledge/docs/drift-__init__/#knowledge-drift-detection-package-documentation","title":"Knowledge Drift Detection Package Documentation","text":"<p>This document describes the <code>knowledge.drift</code> package, designed for identifying changes in data distributions that may affect the performance of knowledge-based systems. We refer to these changes as \u201cdrift.\u201d This package provides a simple API for detecting drift, enabling proactive model maintenance and ensuring continued accuracy.</p> <p>Module Purpose:</p> <p>The primary responsibility of this package is to offer a function for detecting drift between two datasets. This is particularly important in scenarios where the data used to train a model evolves over time, potentially leading to degraded performance.</p> <p>Key Components:</p> <p>The package exposes a single function: <code>detect_drift</code>.</p> <p><code>detect_drift</code> Function:</p> <p>The <code>detect_drift</code> function is the core of this package. </p> <p>Signature: <code>detect_drift(reference_data, current_data, alpha=0.05)</code></p> <p>Behavior: This function compares two datasets, <code>reference_data</code> and <code>current_data</code>, to determine if a statistically significant drift exists between them. It employs a statistical test (details of the specific test are within the <code>detect_drift</code> function\u2019s implementation) to assess the difference in distributions.</p> <p>Parameters:</p> <pre><code>* `reference_data`:  The baseline dataset, representing the expected data distribution. The type is not strictly enforced, but it should be a format suitable for comparison (e.g., a list of numerical values, a Pandas DataFrame).\n* `current_data`: The dataset being evaluated for drift.  Similar type expectations as `reference_data`.\n* `alpha`: (Optional) The significance level for the drift test.  Defaults to 0.05. This value represents the probability of incorrectly identifying drift when it does not exist (a Type I error).  You can adjust this value based on your risk tolerance.\n</code></pre> <p>Return Value: The function returns a boolean value: <code>True</code> if drift is detected, and <code>False</code> otherwise.</p> <p>Design Decisions:</p> <p>The package is intentionally kept minimal. We focused on providing a single, easy-to-use function for drift detection. The specific statistical test used within <code>detect_drift</code> is an implementation detail and may be subject to change as we explore more effective methods. The package does not currently include functionality for handling different data types or providing detailed drift reports, but these are potential areas for future expansion.</p> <p>Type Hints:</p> <p>While not extensively used in this initial version, type hints are planned for future releases to improve code clarity and maintainability. They will help to clearly define the expected input and output types for each function, reducing the potential for errors.</p>"},{"location":"packages/knowledge/docs/drift-detect_drift/","title":"Drift detect drift","text":""},{"location":"packages/knowledge/docs/drift-detect_drift/#knowledge-drift-detection-documentation","title":"Knowledge Drift Detection Documentation","text":"<p>This module is responsible for comparing newly ingested document embeddings against previously established embeddings to identify potential drift in the knowledge base. Drift, in this context, refers to significant changes in the content or meaning of documents that could impact the performance of retrieval-augmented generation (RAG) systems.</p> <p>Core Functionality:</p> <p>The primary function, <code>detect_drift</code>, analyzes a list of document embeddings and identifies documents that exhibit characteristics indicative of drift. Currently, the implementation simulates drift detection by identifying near-duplicate documents, which suggests redundancy or conflicting information. A report detailing the findings is generated.</p> <p>Key Components:</p> <ul> <li> <p><code>cosine_similarity(a, b)</code>: This function calculates the cosine similarity between two vectors <code>a</code> and <code>b</code>. It returns a value between -1 and 1, where 1 indicates perfect similarity and 0 indicates orthogonality (no similarity). This function is a utility for measuring the similarity between embeddings.</p> <ul> <li><code>a</code>: A numpy array representing the first embedding vector.</li> <li><code>b</code>: A numpy array representing the second embedding vector.</li> <li>Returns: A float representing the cosine similarity between <code>a</code> and <code>b</code>.</li> </ul> </li> <li> <p><code>detect_drift(embeddings, threshold=0.85)</code>: This is the main function for drift detection. It takes a list of document embeddings as input and returns a list of document paths that are considered to have drifted.</p> <ul> <li><code>embeddings</code>: A list of tuples, where each tuple contains a document dictionary (<code>doc_dict</code>) and its corresponding embedding vector. The <code>doc_dict</code> is expected to have a \"hash\" key for content identification and a \"path\" key for document location.</li> <li><code>threshold</code>: A float representing the similarity threshold. Documents with a similarity score below this threshold are considered to have drifted. The default value is 0.85.</li> <li>Returns: A list of strings, where each string is the path to a document that has drifted.</li> </ul> </li> </ul> <p>Drift Detection Process:</p> <ol> <li>Near-Duplicate Detection: The function iterates through the provided embeddings, maintaining a dictionary (<code>seen_hashes</code>) to track document hashes and their corresponding paths. If a duplicate hash is encountered, the corresponding document paths are flagged as potential conflicts.</li> <li>Report Generation: A markdown report is generated at <code>../docs/generated/drift_report.md</code>. This report summarizes the findings of the drift detection process.<ul> <li>If near-duplicate documents are found, the report lists the conflicting document paths.</li> <li>If no conflicts are detected, the report indicates that all indexed documents appear unique.</li> <li>A \"Drift Status\" section currently states that no significant semantic drift has been detected, as full drift detection is not yet implemented.</li> </ul> </li> <li>Return Value: The function currently returns an empty list (<code>drifted</code>) as the full drift detection logic is not yet implemented. In a future version, this list will contain the paths of documents identified as having drifted based on semantic similarity comparisons.</li> </ol> <p>Design Considerations:</p> <ul> <li>Type Hints: The code uses type hints (e.g., <code>embeddings: list[tuple[dict, np.ndarray]]</code>, <code>threshold: float</code>) to improve code readability and maintainability. These hints help clarify the expected data types for function arguments and return values.</li> <li>Future Expansion: The current implementation is a placeholder for a more robust drift detection mechanism. The <code>TODO</code> comment indicates that the function will eventually load previous embedding snapshots and compare them to the current embeddings to identify semantic drift.</li> <li>Report-Driven Approach: The module adopts a report-driven approach to communicate drift detection results. This allows for easy monitoring and analysis of the knowledge base health.</li> <li>Hash-Based Duplicate Detection: The current method for identifying potential conflicts relies on document hashes. This is a quick and efficient way to detect exact duplicates, but it does not account for near-duplicates or semantic changes.</li> </ul>"},{"location":"packages/knowledge/docs/embeddings-__init__/","title":"Init","text":""},{"location":"packages/knowledge/docs/embeddings-__init__/#knowledge-embeddings-package-documentation","title":"Knowledge Embeddings Package Documentation","text":"<p>This package provides tools for generating embeddings from text data, a process that represents text as numerical vectors. These vectors capture the semantic meaning of the text, enabling applications like semantic search, document similarity analysis, and question answering. We offer several embedding models and a routing function to select the appropriate model for your needs.</p> <p>Key Components:</p> <ul> <li> <p><code>GeminiEmbedding</code> Class: This class interfaces with the Gemini model to produce text embeddings. It handles the communication with the Gemini API and returns embedding vectors for input text.</p> </li> <li> <p><code>Gemma12bItEmbedding</code> Class: This class utilizes the Gemma 12b IT (Instruction Tuned) model to generate text embeddings. Similar to <code>GeminiEmbedding</code>, it manages the API interaction and provides embedding vectors.  The IT designation indicates the model has been specifically tuned for instruction-following tasks, potentially improving embedding quality for certain applications.</p> </li> <li> <p><code>get_embeddings_for_docs</code> Function: This function acts as a router, selecting the best embedding model based on the input documents and returning their corresponding embeddings.  </p> </li> </ul> <p>Function Signatures and Behavior:</p> <ul> <li><code>get_embeddings_for_docs(docs: list[str]) -&gt; list[list[float]]</code>:<ul> <li>Purpose:  Generates embeddings for a list of documents.</li> <li>Parameters:<ul> <li><code>docs</code>: A list of strings, where each string represents a document.</li> </ul> </li> <li>Return Value: A list of lists of floats. Each inner list represents the embedding vector for the corresponding document in the input list.</li> </ul> </li> </ul> <p>Type Hints:</p> <p>Throughout the package, type hints (e.g., <code>list[str]</code>, <code>list[list[float]]</code>) are used to improve code readability and maintainability. They specify the expected data types for function parameters and return values, aiding in error detection and code understanding.</p> <p>Design Considerations:</p> <p>The package is designed with modularity in mind. Each embedding model is encapsulated in its own class, allowing for easy addition of new models without modifying existing code. The <code>get_embeddings_for_docs</code> function provides a single entry point for generating embeddings, abstracting away the complexity of model selection.</p> <p>Usage:</p> <p>You can access the embedding models and the routing function directly from the <code>knowledge.embeddings</code> module. For example:</p> <p>```python from knowledge.embeddings import get_embeddings_for_docs</p> <p>documents = [\"This is the first document.\", \"This is the second document.\"] embeddings = get_embeddings_for_docs(documents) print(embeddings)</p>"},{"location":"packages/knowledge/docs/embeddings-gemini_embedding/","title":"Gemini","text":""},{"location":"packages/knowledge/docs/embeddings-gemini_embedding/#geminiembedding-documentation","title":"GeminiEmbedding Documentation","text":"<p>This module provides a class for generating text embeddings using the Gemini models offered through the Google Generative AI API. Embeddings are vector representations of text, useful for semantic search, clustering, and other machine learning tasks.</p> <p>Module Responsibilities:</p> <p>The primary responsibility of this module is to encapsulate the logic for interacting with the Gemini embedding models. It handles API key management, error handling, and provides a consistent interface for obtaining embeddings from text data. It includes a fallback mechanism to sequential processing and mock data generation if the API is unavailable or encounters issues.</p> <p>GeminiEmbedding Class:</p> <p>The <code>GeminiEmbedding</code> class is the core component of this module.</p> <ul> <li> <p><code>__init__(self)</code>:</p> <ul> <li>Initializes the <code>GeminiEmbedding</code> object.</li> <li>Retrieves the Google API key from the <code>GOOGLE_API_KEY</code> environment variable.</li> <li>If the API key is not found, a warning message is printed, and the class will return mock embeddings.</li> <li>If the API key is present and the <code>google.generativeai</code> library is imported successfully, it configures the Gemini API with the provided key.</li> <li>Type hints are not used for self, as is standard practice.</li> </ul> </li> <li> <p><code>get_embeddings(self, texts: list[str]) -&gt; list[list[float]]</code>:</p> <ul> <li>This function takes a list of strings (<code>texts</code>) as input and returns a list of embeddings, where each embedding is a list of floats.</li> <li>It first attempts a batched call to the Gemini API to generate embeddings for all input texts simultaneously. This is the preferred method for performance.</li> <li>It handles potential <code>Exception</code>s during the batched call. If a batched call fails, it falls back to sequential processing.</li> <li>If the API key is not set or the <code>google.generativeai</code> library is not available, it generates mock embeddings (random 768-dimensional vectors) for each input text.</li> <li>The function uses the <code>models/text-embedding-004</code> model for generating embeddings.</li> <li>The <code>task_type</code> is set to \"retrieval_document\".</li> <li>The return type is explicitly annotated as <code>list[list[float]]</code>, indicating a list of lists of floating-point numbers, representing the embeddings.</li> <li>The function includes logic to handle different response structures from the API, ensuring compatibility with both older and newer versions of the <code>google.generativeai</code> SDK. It checks if the response contains an 'embedding' key and verifies the structure of the returned data.</li> </ul> </li> </ul> <p>Design Decisions and Patterns:</p> <ul> <li>Environment Variable for API Key: The API key is loaded from an environment variable (<code>GOOGLE_API_KEY</code>) to avoid hardcoding sensitive information in the code.</li> <li>Fallback Mechanism: The code includes a fallback mechanism to sequential processing and mock data generation to ensure robustness in case of API errors or unavailability.</li> <li>Error Handling:  The code includes <code>try...except</code> blocks to catch potential exceptions during API calls and handle them gracefully.  Errors during sequential embedding are logged, and a random vector is returned to maintain alignment with the input list length.</li> <li>Type Hints: Type hints (<code>list[str]</code>, <code>list[list[float]]</code>) are used to improve code readability and maintainability, and to enable static analysis.</li> <li>Warning Suppression:  The code suppresses <code>FutureWarning</code>s from the <code>google.generativeai</code> and <code>google.auth</code> modules to avoid noisy output.</li> <li>Batching: The code prioritizes batched embedding calls for improved performance.</li> <li>Mock Data: When the API is unavailable, the code generates mock embeddings to allow for testing and development without requiring an active API connection.</li> </ul>"},{"location":"packages/knowledge/docs/embeddings-gemma_12b_it_embedding/","title":"Gemma","text":""},{"location":"packages/knowledge/docs/embeddings-gemma_12b_it_embedding/#gemma-12b-it-embedding-module-documentation","title":"Gemma 12b IT Embedding Module Documentation","text":"<p>This module provides a class for generating text embeddings using the Google GenAI API, specifically designed as an alternative to GeminiEmbedding when working with Gemma 12b IT models. It handles API key configuration, embedding generation, and fallback mechanisms to ensure robustness.</p> <p>Module Responsibilities:</p> <p>The primary responsibility of this module is to convert text into numerical vector representations (embeddings). These embeddings capture the semantic meaning of the text and are suitable for tasks like semantic search, similarity comparison, and machine learning.  The module prioritizes using the Google GenAI API but includes fallback strategies if the API is unavailable or encounters errors.</p> <p>Key Classes:</p> <ul> <li> <p><code>Gemma12bItEmbedding</code>: This class encapsulates the logic for interacting with the Google GenAI API to generate embeddings.</p> <ul> <li> <p><code>__init__(self)</code>: The constructor initializes the class. It attempts to retrieve the Google API key from the environment variable <code>GOOGLE_API_KEY</code>. If the API key is found, it configures the <code>genai</code> library. If the API key is missing, a warning message is printed, and the class will return mock data when embeddings are requested. It also handles the case where the <code>google.generativeai</code> library is not installed.</p> </li> <li> <p><code>get_embeddings(self, texts: list[str]) -&gt; list[list[float]]</code>: This method takes a list of strings (<code>texts</code>) as input and returns a list of embeddings. Each embedding is a list of floats representing the vector representation of the corresponding text.</p> <ul> <li>Input: <code>texts</code> \u2013 A list of strings to be embedded. The type hint <code>list[str]</code> clearly indicates the expected input type.</li> <li>Output: A list of lists of floats, where each inner list represents an embedding vector. The type hint <code>list[list[float]]</code> specifies the output type.</li> <li>Behavior:<ol> <li>API Call (Batch): First, it attempts to generate embeddings for all texts in a single batch using the <code>genai.embed_content</code> function with the <code>models/text-embedding-004</code> model and <code>retrieval_document</code> task type.</li> <li>API Call (Sequential): If the batch call fails, it falls back to embedding each text sequentially. This handles potential issues with large input sizes or API limitations. Error handling is included within the loop, and if an individual embedding fails, a random vector is used as a placeholder.</li> <li>Mock Data: If the API key is not set or the <code>genai</code> library is not available, the method generates random embedding vectors as a fallback. This ensures the application can still function, albeit with reduced accuracy.</li> </ol> </li> <li>Error Handling: The code includes <code>try...except</code> blocks to catch potential exceptions during the API calls. This prevents the application from crashing and allows it to gracefully fall back to alternative strategies.</li> </ul> </li> </ul> </li> </ul> <p>Notable Design Decisions:</p> <ul> <li>Fallback Mechanisms: The module incorporates multiple fallback mechanisms (sequential embedding and mock data) to ensure robustness and prevent failures due to API unavailability or errors.</li> <li>Type Hints: The use of type hints (<code>list[str]</code>, <code>list[list[float]]</code>) improves code readability and maintainability, and allows for static analysis to catch potential type errors.</li> <li>Environment Variable for API Key: Storing the API key in an environment variable (<code>GOOGLE_API_KEY</code>) is a secure practice that avoids hardcoding sensitive information in the code.</li> <li>Warning Message: The module provides a warning message if the API key is not set, informing the user that mock data will be used.</li> <li>Model Selection: The code explicitly uses the <code>models/text-embedding-004</code> model, which is currently the most capable text embedding model available through the GenAI API.</li> <li>Suppression of Warnings: The code suppresses <code>FutureWarning</code> messages from the <code>google.generativeai</code> and <code>google.auth</code> modules to avoid cluttering the logs with irrelevant warnings.</li> </ul>"},{"location":"packages/knowledge/docs/embeddings-router_embedding/","title":"Router","text":""},{"location":"packages/knowledge/docs/embeddings-router_embedding/#router-embedding-documentation","title":"Router Embedding Documentation","text":"<p>This module provides a routing mechanism for generating embeddings from a collection of documents. It prioritizes a primary embedding model and seamlessly falls back to a secondary model if rate limits are encountered with the primary. This ensures continuous operation even when facing API restrictions.</p> <p>Module Responsibilities:</p> <p>The primary responsibility of this module is to abstract the complexity of managing multiple embedding models and their associated limitations. It handles batch processing of documents and intelligently switches between models to maximize throughput and reliability.</p> <p>Key Classes:</p> <ul> <li><code>RPDLimitError</code>: A custom exception class. This is raised by the <code>GeminiEmbedding</code> class when its rate limits are reached. We catch this exception to trigger the fallback mechanism.</li> <li><code>GeminiEmbedding</code>: (From <code>gemini_embedding.py</code>) This class encapsulates the logic for interacting with the Gemini embedding model. It is the primary embedding provider.</li> <li><code>Gemma12bItEmbedding</code>: (From <code>gemma_12b_it_embedding.py</code>) This class encapsulates the logic for interacting with the Gemma 12b IT embedding model. It serves as the fallback embedding provider.</li> </ul> <p>Important Functions:</p> <ul> <li> <p><code>get_embeddings_for_docs(docs, batch_size=10)</code>: This is the core function of the module. It takes a list of documents (<code>docs</code>) and an optional <code>batch_size</code> as input.</p> <ul> <li>Parameters:<ul> <li><code>docs</code>: A list of dictionaries, where each dictionary represents a document and is expected to have a <code>\"content\"</code> key containing the text to be embedded.  Type: <code>list[dict]</code>.</li> <li><code>batch_size</code>: The number of documents to process in each batch.  Defaults to 10. Type: <code>int</code>.</li> </ul> </li> <li>Behavior:<ol> <li>Initializes instances of <code>GeminiEmbedding</code> (primary) and <code>Gemma12bItEmbedding</code> (fallback).</li> <li>Iterates through the <code>docs</code> list in batches of the specified <code>batch_size</code>.</li> <li>For each batch, it first attempts to generate embeddings using the <code>GeminiEmbedding</code> model.</li> <li>If a <code>RPDLimitError</code> is raised (indicating the Gemini model has reached its rate limit), it falls back to using the <code>Gemma12bItEmbedding</code> model for that batch.</li> <li>The function extends the <code>embeddings</code> list with tuples containing the original document and its corresponding embedding.</li> <li>Prints progress updates to the console during processing.</li> <li>Returns a list of tuples, where each tuple contains a document (dictionary) and its embedding (list of floats). Type: <code>list[tuple[dict, list[float]]]</code>.</li> </ol> </li> <li> <p>Example:</p> <pre><code>docs = [{\"content\": \"This is the first document.\"}, {\"content\": \"This is the second document.\"}]\nembeddings = get_embeddings_for_docs(docs, batch_size=1)\nprint(embeddings)\n</code></pre> </li> </ul> </li> </ul> <p>Type Hints:</p> <p>The code extensively uses type hints (e.g., <code>docs: list[dict]</code>, <code>batch_size: int</code>). These hints improve code readability and allow for static analysis, helping to catch potential errors during development.</p> <p>Design Decisions and Patterns:</p> <ul> <li>Fallback Mechanism: The core design pattern is a fallback mechanism. This enhances the robustness of the embedding process by providing an alternative when the primary model is unavailable due to rate limits.</li> <li>Batch Processing: Processing documents in batches improves efficiency by reducing the number of API calls. The <code>batch_size</code> parameter allows you to tune performance based on your specific needs and the API limits of the embedding models.</li> <li>Exception Handling: The use of a custom exception (<code>RPDLimitError</code>) allows for specific and targeted error handling, making the code more maintainable and easier to understand.</li> <li>Clear Separation of Concerns: The module focuses solely on routing embedding requests. The actual embedding logic is encapsulated within the <code>GeminiEmbedding</code> and <code>Gemma12bItEmbedding</code> classes, promoting modularity and reusability.</li> </ul>"},{"location":"packages/knowledge/docs/generation-__init__/","title":"Generation","text":""},{"location":"packages/knowledge/docs/generation-__init__/#glassops-knowledge-pipeline-generation-module-documentation","title":"GlassOps Knowledge Pipeline: Generation Module Documentation","text":"<p>This document describes the <code>generation</code> module within the GlassOps Knowledge Pipeline. This module is responsible for creating and verifying knowledge artifacts. It provides tools for generating content and ensuring its quality before integration into the broader knowledge base.</p> <p>Module Purpose:</p> <p>The primary function of this module is to offer a structured approach to knowledge creation. It separates the processes of content generation and validation, promoting maintainability and reliability. This allows for flexible content creation strategies alongside robust quality control.</p> <p>Key Classes:</p> <ol> <li> <p><code>Generator</code>:</p> <ul> <li>Responsibility: This class handles the creation of knowledge content. It encapsulates the logic for transforming source data into a standardized knowledge format.</li> <li>Details: The <code>Generator</code> class likely contains methods for accepting input data, applying transformations, and producing the final knowledge artifact. Specific implementation details regarding input types and output formats are defined within the class itself.</li> <li>Example:  A <code>Generator</code> instance might take raw log data and produce a summarized incident report.</li> </ul> </li> <li> <p><code>Validator</code>:</p> <ul> <li>Responsibility: This class is dedicated to verifying the quality and correctness of generated knowledge. It ensures that the content adheres to predefined standards and constraints.</li> <li>Details: The <code>Validator</code> class likely includes methods for performing checks such as format validation, content completeness, and consistency with existing knowledge. It may raise exceptions or return validation reports indicating any issues found.</li> <li>Example: A <code>Validator</code> instance might check that a generated document includes all required sections and that dates are in a consistent format.</li> </ul> </li> </ol> <p>Important Functions (via Classes):</p> <p>While the <code>generation</code> module itself doesn't expose standalone functions, the core functionality resides within the methods of the <code>Generator</code> and <code>Validator</code> classes. </p> <ul> <li><code>Generator.generate(input_data: Any) -&gt; Any</code> (Conceptual):  This method (likely present within the <code>Generator</code> class) would take input data of any type (<code>Any</code>) and return the generated knowledge artifact, also of any type (<code>Any</code>). The specific types are determined by the implementation of the <code>Generator</code>.</li> <li><code>Validator.validate(knowledge_artifact: Any) -&gt; bool</code> (Conceptual): This method (likely present within the <code>Validator</code> class) would accept a knowledge artifact of any type (<code>Any</code>) and return a boolean value (<code>bool</code>) indicating whether the artifact is valid.</li> </ul> <p>Type Hints:</p> <p>The use of type hints (e.g., <code>input_data: Any</code>, <code>-&gt; Any</code>) is a significant design choice. They improve code readability and maintainability by explicitly defining the expected data types for function arguments and return values. This helps prevent errors and makes it easier to understand the flow of data within the module. The use of <code>Any</code> indicates flexibility in data types, but specific implementations within the classes will likely refine these to more precise types.</p> <p>Design Decisions &amp; Patterns:</p> <p>The module employs a clear separation of concerns. The <code>Generator</code> focuses solely on content creation, while the <code>Validator</code> focuses on quality assurance. This division promotes modularity and allows for independent development and testing of each component. The use of classes encapsulates the related functionality and data, making the code more organized and reusable. The <code>__all__</code> variable explicitly defines the public interface of the module, controlling which classes are accessible to external code. This practice enhances encapsulation and prevents unintended dependencies.</p>"},{"location":"packages/knowledge/docs/generation-generator/","title":"Generator","text":""},{"location":"packages/knowledge/docs/generation-generator/#documentation-generator-documentation","title":"Documentation Generator Documentation","text":"<p>This document describes the functionality and design of the documentation generator tool. It is intended for both technical users who will maintain and extend the tool, and non-technical users who want to understand how it works.</p>"},{"location":"packages/knowledge/docs/generation-generator/#module-purpose","title":"Module Purpose","text":"<p>The primary purpose of this module is to automate the generation of documentation for a codebase. It scans source files, identifies their type, uses Large Language Models (LLMs) to create documentation, and writes the documentation to files. The tool supports multiple languages and file formats, and provides a configurable system for prompts and caching.</p>"},{"location":"packages/knowledge/docs/generation-generator/#key-classes-and-roles","title":"Key Classes and Roles","text":"<ul> <li>Generator: This is the central class responsible for orchestrating the entire documentation generation process. It handles file scanning, adapter selection, LLM interaction, caching, and output writing.</li> <li>BaseAdapter: An abstract base class that defines the interface for adapters. Adapters are responsible for parsing source code, generating prompts, and post-processing LLM output for specific file types.</li> <li>GoAdapter, PythonAdapter, TypeScriptAdapter, YAMLAdapter, JSONAdapter, DockerAdapter, TerraformAdapter, ApexAdapter, LWCAdapter: Concrete adapter implementations for different languages and file formats. Each adapter implements the <code>BaseAdapter</code> interface.</li> <li>LLMClient: A client for interacting with a Large Language Model (LLM). It handles sending prompts to the LLM and receiving responses.</li> <li>Validator: A class responsible for validating the generated documentation.</li> </ul>"},{"location":"packages/knowledge/docs/generation-generator/#important-functions-and-their-behavior","title":"Important Functions and Their Behavior","text":"<ul> <li><code>Generator.__init__(root_dir: str, output_dir: Optional[str] = None)</code>: The constructor for the <code>Generator</code> class. It initializes the generator with the root directory of the codebase and an optional output directory for generated documentation. It also loads the LLM client, cache, and prompts.</li> <li><code>Generator.scan_files(patterns: List[str]) -&gt; List[Path]</code>: Scans the codebase for files matching the provided glob patterns. It respects ignore patterns defined in <code>.gitignore</code> and a set of hardcoded ignored directories.</li> <li><code>Generator.generate_for_file(file_path: Path) -&gt; Optional[str]</code>: Generates documentation for a single file. It selects the appropriate adapter, parses the file content, generates a prompt, interacts with the LLM, and post-processes the LLM output.</li> <li><code>Generator.run(patterns: List[str]) -&gt; None</code>: Runs the documentation generation process for all files matching the provided patterns. It scans the files, generates documentation for each file, and writes the documentation to the output directory.</li> <li><code>BaseAdapter.can_handle(file_path: Path) -&gt; bool</code>: A method implemented by each adapter to determine if it can handle a given file.</li> <li><code>BaseAdapter.parse(file_path: Path, content: str) -&gt; List[str]</code>: Parses the file content into chunks that can be processed by the LLM.</li> <li><code>BaseAdapter.get_prompt(file_path: Path, chunk: str) -&gt; str</code>: Generates a prompt for the LLM based on the file path and content chunk.</li> <li><code>BaseAdapter.post_process(file_path: Path, outputs: List[str]) -&gt; str</code>: Post-processes the LLM output to create the final documentation string.</li> </ul>"},{"location":"packages/knowledge/docs/generation-generator/#type-hints-and-their-significance","title":"Type Hints and Their Significance","text":"<p>The code makes extensive use of type hints (e.g., <code>root_dir: str</code>, <code>output_dir: Optional[str]</code>, <code>patterns: List[str]</code>). These type hints improve code readability, maintainability, and help catch errors during development. They also enable static analysis tools to verify the correctness of the code.</p>"},{"location":"packages/knowledge/docs/generation-generator/#notable-patterns-and-design-decisions","title":"Notable Patterns and Design Decisions","text":"<ul> <li>Adapter Pattern: The use of the <code>BaseAdapter</code> class and concrete adapter implementations promotes loose coupling and extensibility. New languages and file formats can be supported by simply creating new adapters.</li> <li>Caching: The tool uses a cache to store previously generated documentation. This reduces the load on the LLM and speeds up the documentation generation process.</li> <li>Prompt Configuration: Prompts are loaded from a YAML file, allowing for easy customization and experimentation.</li> <li>Configuration-Driven: The tool relies on configuration files for prompts and ignored directories, making it adaptable to different projects without code changes.</li> <li>Error Handling: The code includes error handling to gracefully handle file reading errors, cache loading errors, and LLM failures.</li> <li>Frontmatter Generation: The tool generates YAML frontmatter for each documentation file, providing metadata such as the source file path, hash, and generation timestamp. This metadata can be used for version control and other purposes.</li> <li>Validation: The generated documentation is validated to ensure it meets certain quality standards.</li> </ul>"},{"location":"packages/knowledge/docs/generation-validator/","title":"Validator","text":""},{"location":"packages/knowledge/docs/generation-validator/#documentation-validator-module","title":"Documentation Validator Module","text":"<p>This module provides functionality to validate generated documentation content for quality and syntax issues. It aims to ensure documentation is professional, concise, and free of common problems like conversational filler or banned terminology.</p> <p>Key Classes:</p> <ul> <li>Validator: This class contains the core validation logic. It is designed as a collection of class methods, offering a centralized point for performing various checks on the documentation content.  It does not require instantiation.</li> </ul> <p>Important Functions:</p> <ul> <li><code>get_adapter_for_lang(cls, lang: str) -&gt; Optional[BaseAdapter]</code>: This class method acts as a factory, returning an appropriate adapter object based on the detected programming language of a code block. The <code>lang</code> parameter is a string representing the language (e.g., \"python\", \"go\"). It returns <code>None</code> if no adapter is found for the given language. Type hinting ensures the input is a string and the output is either a <code>BaseAdapter</code> object or <code>None</code>.</li> <li><code>extract_code_blocks(cls, content: str) -&gt; List[tuple[str, str]]</code>: This class method extracts code blocks from markdown content using regular expressions. It identifies blocks enclosed in triple backticks (<code>``) and returns a list of tuples, where each tuple contains the language of the code block and the code itself. The</code>content` parameter is the markdown string to parse. The return value is a list of tuples, each containing a language string and a code string.</li> <li><code>validate(cls, content: str, file_path: str = \"\") -&gt; dict</code>: This is the primary validation function. It takes the documentation <code>content</code> as input, along with an optional <code>file_path</code> for context. It performs a series of checks, including:<ul> <li>Frontmatter presence</li> <li>Detection of banned conversational phrases</li> <li>Detection of banned words</li> <li>Detection of prohibited terms</li> <li>Delegation of code block validation to language-specific adapters. It returns a dictionary containing three lists: <code>passes</code>, <code>warnings</code>, and <code>errors</code>. These lists store the results of each validation check.</li> </ul> </li> <li><code>print_report(results: dict)</code>: This static method takes the dictionary returned by the <code>validate</code> function and prints a formatted report to the console, clearly indicating any errors, warnings, or successful passes.</li> </ul> <p>Type Hints:</p> <p>The code extensively uses type hints (e.g., <code>lang: str</code>, <code>-&gt; List[tuple[str, str]]</code>) to improve code readability and maintainability. These hints specify the expected data types for function parameters and return values, enabling static analysis and helping to prevent type-related errors.</p> <p>Notable Patterns and Design Decisions:</p> <ul> <li>Class Methods: The validation logic is implemented using class methods, allowing access to class-level constants (like <code>BANNED_PHRASES</code> and <code>BANNED_WORDS</code>) without requiring an instance of the <code>Validator</code> class.</li> <li>Adapter Pattern: The use of adapters (e.g., <code>PythonAdapter</code>, <code>GoAdapter</code>) promotes loose coupling and allows for easy extension to support additional languages. Each adapter is responsible for validating code blocks in its specific language.</li> <li>Regular Expressions: Regular expressions are used for extracting code blocks from the markdown content.</li> <li>Dictionary-Based Results: The <code>validate</code> function returns a dictionary to provide a structured and comprehensive report of the validation results.</li> <li>Banned Phrase/Word Lists: The use of lists for banned phrases and words makes it easy to maintain and update the validation rules.</li> <li>Static Method for Reporting: The <code>print_report</code> method is static, meaning it doesn't require an instance of the class to be called, and is solely responsible for formatting and displaying the validation results.</li> </ul> <p>Adapters:</p> <p>The module depends on several adapter classes (defined in <code>glassops.knowledge.adapters</code>) to handle language-specific validation:</p> <ul> <li><code>BaseAdapter</code>:  The base class for all adapters.</li> <li><code>GoAdapter</code>: Validates Go code.</li> <li><code>PythonAdapter</code>: Validates Python code.</li> <li><code>LWCAdapter</code>: Validates HTML/XML content.</li> <li><code>ApexAdapter</code>: Validates Apex code.</li> <li><code>YAMLAdapter</code>: Validates YAML content.</li> <li><code>JSONAdapter</code>: Validates JSON content.</li> <li><code>DockerAdapter</code>: Validates Dockerfile content.</li> <li><code>TerraformAdapter</code>: Validates Terraform code.</li> </ul> <p>You can extend the functionality of this module by creating new adapters for additional languages or file types.</p>"},{"location":"packages/knowledge/docs/ingestion-__init__/","title":"Init","text":""},{"location":"packages/knowledge/docs/ingestion-__init__/#knowledge-ingestion-package-documentation","title":"Knowledge Ingestion Package Documentation","text":"<p>This document describes the <code>knowledge.ingestion</code> package, which provides tools for bringing external data into a system for use by large language models (LLMs). The primary function of this package is to locate documents, prepare them for processing, and create an index to enable efficient retrieval of relevant information.</p> <p>Module Responsibilities:</p> <p>The <code>knowledge.ingestion</code> module handles the initial stages of knowledge integration. It focuses on two main tasks: document discovery and chunking, and index creation or updating. This separation allows for flexibility in data sources and indexing strategies.</p> <p>Key Functions:</p> <ol> <li> <p><code>discover_and_chunk_docs</code>:</p> <ul> <li>Purpose: This function is responsible for locating documents from various sources and dividing them into smaller, manageable pieces (chunks). These chunks are the basic units of information that the LLM will work with.</li> <li>Behavior: The function searches for documents based on a defined configuration. It then loads the content of these documents and splits them into chunks of a specified size, potentially with overlap between chunks to maintain context.</li> <li>Signature: <code>discover_and_chunk_docs()</code></li> <li>Type Hints: The function uses type hints to ensure data consistency and clarity. While the specific type hints are not detailed here, they define the expected input types (e.g., configuration parameters) and the output type (e.g., a list of document chunks).</li> </ul> </li> <li> <p><code>build_or_update_index</code>:</p> <ul> <li>Purpose: This function creates or updates an index that allows for fast and efficient searching of the document chunks. An index is a data structure that maps keywords and concepts to the documents that contain them.</li> <li>Behavior: The function takes the prepared document chunks as input and builds an index using a specified indexing method (e.g., vector database). If an index already exists, it can be updated with the new chunks.</li> <li>Signature: <code>build_or_update_index()</code></li> <li>Type Hints: Similar to <code>discover_and_chunk_docs</code>, type hints are used to define the expected input and output types, ensuring data integrity.</li> </ul> </li> </ol> <p>Design Decisions and Patterns:</p> <ul> <li>Separation of Concerns: The package is designed with a clear separation between document loading/chunking and index building. This makes the system more modular and easier to maintain. You can swap out different chunking or indexing strategies without affecting the other part of the pipeline.</li> <li>Exposed API: The <code>__all__</code> list explicitly defines the public API of the package. This ensures that only the intended functions are accessible to users of the package.</li> <li>Configuration-Driven: Both functions are expected to be driven by configuration parameters, allowing for customization of the ingestion process without modifying the code. We anticipate that these configurations will be defined elsewhere in the system.</li> </ul>"},{"location":"packages/knowledge/docs/ingestion-federated_loader/","title":"Federated Loader","text":""},{"location":"packages/knowledge/docs/ingestion-federated_loader/#federated-document-loader-documentation","title":"Federated Document Loader Documentation","text":"<p>This module provides functionality for discovering, chunking, and hashing documentation files within a repository. It is designed to prepare documentation for use with large language models (LLMs) and knowledge retrieval systems. We aim to ingest documentation from various sources within a project to build a comprehensive knowledge base.</p> <p>Key Responsibilities:</p> <ul> <li>Document Discovery: Locates relevant documentation files based on predefined patterns.</li> <li>Content Chunking: Divides large documents into smaller, more manageable chunks based on semantic headers.</li> <li>Content Hashing: Generates SHA256 hashes for each chunk to ensure data integrity and enable efficient duplicate detection.</li> <li>Metadata Handling: Extracts and associates frontmatter metadata with document chunks.</li> </ul>"},{"location":"packages/knowledge/docs/ingestion-federated_loader/#core-functions","title":"Core Functions","text":"<p>1. <code>hash_content(text: str) -&gt; str</code></p> <p>This function calculates the SHA256 hash of a given text string.</p> <ul> <li>Parameters:<ul> <li><code>text</code> (str): The input text string to be hashed.</li> </ul> </li> <li>Return Value:<ul> <li><code>str</code>: The SHA256 hash of the input text, represented as a hexadecimal string.</li> </ul> </li> <li>Purpose: Provides a consistent and unique identifier for each document chunk.</li> </ul> <p>2. <code>discover_and_chunk_docs(root_dir: str = \".\") -&gt; List[Dict]</code></p> <p>This is the primary function of the module. It scans a specified directory (or the current directory if none is provided) for documentation files, chunks their content, and returns a list of dictionaries containing metadata about each chunk.</p> <ul> <li>Parameters:<ul> <li><code>root_dir</code> (str, optional): The root directory to start the document search. Defaults to the current directory (\".\")</li> </ul> </li> <li>Return Value:<ul> <li><code>List[Dict]</code>: A list of dictionaries, where each dictionary represents a document chunk and contains the following keys:<ul> <li><code>path</code> (str): A unique identifier for the chunk, combining the original file path and a chunk index (e.g., \"path/to/file.md#chunk-0\").</li> <li><code>source_file</code> (str): The original file path from which the chunk was extracted.</li> <li><code>content</code> (str): The text content of the chunk.</li> <li><code>hash</code> (str): The SHA256 hash of the chunk's content.</li> </ul> </li> </ul> </li> <li>Behavior:<ol> <li>Document Discovery: Uses a set of predefined file patterns (e.g., \"docs//*.md\", \"packages//README.md\") to locate potential documentation files within the specified <code>root_dir</code>.  The <code>glob</code> module is used for recursive file searching.</li> <li>Path Deduplication: Removes duplicate file paths to avoid processing the same document multiple times.</li> <li>Ignored Directories: Skips files located within specified ignored directories (e.g., \"node_modules\", \".git\") to avoid including irrelevant content.</li> <li>File Reading: Reads the content of each identified documentation file, handling UTF-8 encoding.</li> <li>Frontmatter Parsing: Attempts to parse YAML frontmatter from the beginning of the file. If successful, the frontmatter metadata is extracted and stored. The frontmatter is then removed from the content before chunking.</li> <li>Content Chunking: Splits the document content into chunks based on header levels. It prioritizes splitting by Level 2 headers (<code>##</code>) to preserve context within sections. If no Level 2 headers are found, it falls back to splitting by Level 1 headers (<code>#</code>).</li> <li>Chunk Metadata Creation: Creates a dictionary for each chunk, including its path, source file, content, and hash.</li> <li>Error Handling: Includes <code>try...except</code> blocks to gracefully handle potential errors during file reading, YAML parsing, and other operations.  Warnings are printed to the console for failed operations.</li> </ol> </li> </ul>"},{"location":"packages/knowledge/docs/ingestion-federated_loader/#design-decisions-and-patterns","title":"Design Decisions and Patterns","text":"<ul> <li>Type Hints: The code extensively uses type hints (e.g., <code>str</code>, <code>List[Dict]</code>) to improve code readability and maintainability. Type hints also enable static analysis tools to catch potential errors.</li> <li>SHA256 Hashing: The use of SHA256 hashing ensures the integrity of the document chunks and allows for efficient duplicate detection.</li> <li>Semantic Chunking: The chunking strategy based on headers aims to create meaningful chunks that preserve context and are suitable for LLM processing.</li> <li>Frontmatter Support: The module supports parsing YAML frontmatter to extract metadata associated with documentation files.</li> <li>Robust Error Handling: The inclusion of <code>try...except</code> blocks and warning messages ensures that the module can handle unexpected errors gracefully.</li> <li>Glob Pattern Flexibility: The use of glob patterns allows for easy customization of the document discovery process.</li> <li>Helper Function for Splitting: The <code>split_by_header</code> function encapsulates the logic for splitting text by regular expression patterns, promoting code reuse and readability.</li> </ul>"},{"location":"packages/knowledge/docs/ingestion-index_builder/","title":"Glassops Knowledge Index Builder Documentation","text":"<p>This document describes the functionality of the <code>index_builder</code> module, which is responsible for creating and updating a vector store used for knowledge retrieval. The module leverages ChromaDB to store and query document embeddings.</p>"},{"location":"packages/knowledge/docs/ingestion-index_builder/#module-purpose","title":"Module Purpose","text":"<p>The primary purpose of this module is to ingest document embeddings and store them in a ChromaDB collection. This allows for efficient similarity searches based on the semantic meaning of the documents. The module handles both initial index creation and updates to existing documents.</p>"},{"location":"packages/knowledge/docs/ingestion-index_builder/#key-classes-and-roles","title":"Key Classes and Roles","text":"<p>The module directly interacts with the <code>chromadb</code> library. While it doesn't define custom classes, the core component is the ChromaDB <code>PersistentClient</code> and <code>Collection</code>.</p> <ul> <li><code>chromadb.PersistentClient</code>: This class provides a client interface to ChromaDB, enabling persistent storage of the vector index to disk.</li> <li><code>chromadb.Collection</code>: Represents a collection within ChromaDB where document embeddings and associated metadata are stored.</li> </ul>"},{"location":"packages/knowledge/docs/ingestion-index_builder/#important-functions-and-their-behavior","title":"Important Functions and Their Behavior","text":""},{"location":"packages/knowledge/docs/ingestion-index_builder/#build_or_update_indexembeddings","title":"<code>build_or_update_index(embeddings)</code>","text":"<p>This function is the main entry point for building or updating the knowledge index.</p> <ul> <li>Purpose:  Takes a list of document-embedding pairs and stores them in the ChromaDB collection.</li> <li>Parameters:<ul> <li><code>embeddings</code>: A list of tuples, where each tuple contains a document dictionary (<code>doc_dict</code>) and its corresponding embedding vector. The <code>doc_dict</code> is expected to have keys like \"path\", \"content\", and \"hash\".</li> </ul> </li> <li>Behavior:<ol> <li>Persistence Directory: Defines the directory where the ChromaDB data will be stored (<code>glassops_index</code> in the current working directory).</li> <li>ChromaDB Initialization: Initializes a <code>PersistentClient</code> to connect to ChromaDB, ensuring data is saved to disk.</li> <li>Collection Management: Retrieves an existing collection named \"glassops_knowledge\" or creates a new one if it doesn't exist. The collection is configured to use cosine similarity for distance calculations (<code>metadata={\"hnsw:space\": \"cosine\"}</code>).</li> <li>Data Preparation: Iterates through the input <code>embeddings</code> list, extracting document IDs, content, metadata, and embedding vectors. The document \"path\" is used as the ID for upserting. Metadata is constructed by combining the document's path and hash, along with any other relevant string, integer, float, or boolean fields present in the document dictionary.</li> <li>Upsert Operation: Uses the <code>collection.upsert()</code> method to add or update documents in the ChromaDB collection.  This operation efficiently handles both new documents and updates to existing ones based on the document ID.</li> <li>Error Handling: Includes a <code>try...except</code> block to catch potential exceptions during the <code>upsert</code> operation and print an error message.</li> </ol> </li> <li>Type Hints:<ul> <li><code>embeddings: list[tuple[dict, list[float]]]</code> \u2013 Specifies that the <code>embeddings</code> parameter is a list of tuples. Each tuple contains a dictionary (representing the document) and a list of floats (representing the embedding vector).</li> </ul> </li> <li>Design Decisions:<ul> <li>The document \"path\" is used as the ID for upserting. This allows for easy updating of documents if their content changes. Using the hash would create immutable entries.</li> <li>Metadata is carefully constructed to include relevant document information while excluding the content itself, as the content is stored separately.</li> <li>The module includes debug print statements to aid in troubleshooting and monitoring.</li> </ul> </li> </ul>"},{"location":"packages/knowledge/docs/ingestion-index_builder/#notable-patterns-and-design-decisions","title":"Notable Patterns and Design Decisions","text":"<p>The module follows a straightforward pattern of data preparation and storage. The use of ChromaDB's <code>upsert</code> operation simplifies the process of both creating and updating the index. The careful handling of metadata ensures that relevant document information is available for filtering and retrieval. The inclusion of error handling improves the robustness of the module.</p>"},{"location":"packages/knowledge/docs/llm-__init__/","title":"Init","text":""},{"location":"packages/knowledge/docs/llm-__init__/#glassops-knowledge-pipeline-llm-module-documentation","title":"GlassOps Knowledge Pipeline: LLM Module Documentation","text":"<p>This document details the purpose and components of the Large Language Model (LLM) module within the GlassOps Knowledge Pipeline. This module provides a standardized interface for interacting with various LLMs.</p> <p>Module Purpose:</p> <p>The primary responsibility of this module is to abstract the complexities of interacting with different LLM providers. It offers a consistent way to send prompts to LLMs and receive responses, regardless of the underlying model or API. This abstraction simplifies integration and allows for easy swapping of LLM backends.</p> <p>Key Classes:</p> <ul> <li> <p><code>LLMClient</code>: This is the central class of the module. It serves as the primary entry point for all LLM interactions. </p> <ul> <li>Role: The <code>LLMClient</code> handles the connection to the LLM provider, prompt formatting, request submission, and response parsing. It encapsulates the details of the specific LLM being used.</li> <li>Initialization:  The client is initialized with parameters defining the LLM provider and any necessary credentials.</li> <li>Methods:  The <code>LLMClient</code> provides methods for sending text prompts and receiving text completions.</li> </ul> </li> </ul> <p>Important Functions:</p> <p>This module primarily exposes the <code>LLMClient</code> class. There are no standalone functions. Interaction happens through instantiation and method calls on the <code>LLMClient</code>.</p> <p>Type Hints:</p> <p>Type hints are used throughout the code to improve readability and maintainability. They specify the expected data types for function arguments and return values, aiding in static analysis and error detection. For example, methods within <code>LLMClient</code> will likely use type hints like <code>str</code> for text inputs and outputs.</p> <p>Design Decisions &amp; Patterns:</p> <ul> <li>Client Pattern: The module employs a client pattern, encapsulating the LLM interaction logic within the <code>LLMClient</code> class. This promotes modularity and simplifies usage.</li> <li>Abstraction: The module abstracts away the specifics of different LLM providers, providing a unified interface. This allows You to switch between models without modifying the core application logic.</li> <li><code>__all__</code> Variable: The <code>__all__</code> variable explicitly defines the public interface of the module, controlling which names are imported when using <code>from llm import *</code>. In this case, only <code>LLMClient</code> is exposed.</li> </ul> <p>We aim to provide a flexible and easy-to-use interface for integrating LLMs into the GlassOps Knowledge Pipeline. Future development will focus on adding support for more LLM providers and enhancing the client's capabilities.</p>"},{"location":"packages/knowledge/docs/llm-client/","title":"Client","text":""},{"location":"packages/knowledge/docs/llm-client/#glassops-knowledge-pipeline-llm-client-documentation","title":"GlassOps Knowledge Pipeline: LLM Client Documentation","text":"<p>This document details the functionality of the LLM Client module, designed to provide a consistent interface for interacting with large language models (LLMs), specifically Google\u2019s Generative AI models. It handles API communication, implements retry mechanisms for resilience, and incorporates rate limiting to ensure responsible usage.</p>"},{"location":"packages/knowledge/docs/llm-client/#module-responsibilities","title":"Module Responsibilities","text":"<p>The primary responsibility of this module is to abstract the complexities of interacting with the Google Generative AI API. It provides a simple <code>generate</code> function for obtaining text completions from a given prompt, while managing potential issues like temporary API errors and rate limits.  The module is designed to be reusable across different components of the GlassOps Knowledge Pipeline.</p>"},{"location":"packages/knowledge/docs/llm-client/#key-classes","title":"Key Classes","text":""},{"location":"packages/knowledge/docs/llm-client/#llmclient","title":"<code>LLMClient</code>","text":"<p>This class encapsulates the logic for interacting with the LLM.</p> <ul> <li>Purpose:  Provides a centralized point for making requests to the LLM, handling retries, and enforcing rate limits.</li> <li>Initialization (<code>__init__</code>):<ul> <li><code>model: str = \"gemma-3-27b-it\"</code>: Specifies the LLM model to use. Defaults to \"gemma-3-27b-it\".</li> <li>Loads the Google API key from the environment (using a <code>.env</code> file in the project root). If the key is not found, the client is disabled.</li> <li>Initializes the <code>genai.Client</code> object if the API key is valid.</li> <li>Initializes internal data structures for request history (<code>_request_history</code>), RPM limit (<code>_rpm_limit</code>), and TPM limit (<code>_tpm_limit</code>).</li> </ul> </li> <li>Attributes:<ul> <li><code>client</code>: An instance of <code>genai.Client</code> if the API key is valid, otherwise <code>None</code>.</li> <li><code>model</code>: The name of the LLM model being used.</li> <li><code>_request_history</code>: A list of dictionaries storing the timestamp and token count of recent requests, used for rate limiting.</li> <li><code>_rpm_limit</code>: The maximum number of requests per minute allowed (set to 28 as a safety buffer).</li> <li><code>_tpm_limit</code>: The maximum number of tokens processed per minute allowed (set to 14000 as a safety buffer).</li> </ul> </li> </ul>"},{"location":"packages/knowledge/docs/llm-client/#important-functions","title":"Important Functions","text":""},{"location":"packages/knowledge/docs/llm-client/#_estimate_tokenstext-str-int","title":"<code>_estimate_tokens(text: str) -&gt; int</code>","text":"<ul> <li>Purpose: Provides a rough estimate of the number of tokens in a given text string.</li> <li>Arguments:<ul> <li><code>text: str</code>: The input text string.</li> </ul> </li> <li>Return Value: An integer representing the estimated token count.  The estimation is based on a simple rule of 4 characters per token.</li> </ul>"},{"location":"packages/knowledge/docs/llm-client/#_throttleestimated_tokens-int-none","title":"<code>_throttle(estimated_tokens: int) -&gt; None</code>","text":"<ul> <li>Purpose: Implements rate limiting to prevent exceeding the API's RPM and TPM limits.</li> <li>Arguments:<ul> <li><code>estimated_tokens: int</code>: The estimated number of tokens for the upcoming request.</li> </ul> </li> <li>Behavior:<ul> <li>Maintains a history of recent requests and their token counts.</li> <li>Checks if the current request would exceed the RPM or TPM limits.</li> <li>If a limit is approaching, it pauses execution using <code>time.sleep()</code> until sufficient headroom is available.</li> <li>Updates the request history with the current request's information.</li> </ul> </li> </ul>"},{"location":"packages/knowledge/docs/llm-client/#generateprompt-str-max_retries-int-3-temperature-float-02-max_output_tokens-int-8192-optionalstr","title":"<code>generate(prompt: str, max_retries: int = 3, temperature: float = 0.2, max_output_tokens: int = 8192) -&gt; Optional[str]</code>","text":"<ul> <li>Purpose: Generates text content from a given prompt using the configured LLM.</li> <li>Arguments:<ul> <li><code>prompt: str</code>: The input prompt for the LLM.</li> <li><code>max_retries: int = 3</code>: The maximum number of times to retry the request if a transient error occurs.</li> <li><code>temperature: float = 0.2</code>: Controls the randomness of the generated text (lower values are more deterministic).</li> <li><code>max_output_tokens: int = 8192</code>: The maximum number of tokens to generate in the response.</li> </ul> </li> <li>Return Value:<ul> <li><code>str</code>: The generated text content if the request is successful.</li> <li><code>None</code>: If the request fails after multiple retries or if the API key is not configured.</li> </ul> </li> <li>Behavior:<ul> <li>Estimates the token count of the prompt and output.</li> <li>Calls the <code>_throttle</code> function to ensure rate limits are respected.</li> <li>Implements a retry loop with exponential backoff for transient errors (429, 503, or \"overloaded\").</li> <li>Sends the prompt to the LLM using <code>self.client.models.generate_content()</code>.</li> <li>Handles potential exceptions during the API call and logs errors.</li> <li>Returns the generated text if successful, or <code>None</code> if all retries fail.</li> </ul> </li> </ul>"},{"location":"packages/knowledge/docs/llm-client/#type-hints","title":"Type Hints","text":"<p>The code extensively uses type hints (e.g., <code>str</code>, <code>int</code>, <code>Optional[str]</code>) to improve code readability and maintainability. These hints clarify the expected data types for function arguments and return values, aiding in static analysis and error detection.</p>"},{"location":"packages/knowledge/docs/llm-client/#design-decisions","title":"Design Decisions","text":"<ul> <li>Rate Limiting: The implementation of rate limiting is a key design decision to ensure responsible API usage and prevent errors caused by exceeding API limits.</li> <li>Retry Logic: The inclusion of retry logic with exponential backoff enhances the robustness of the client by automatically handling transient errors.</li> <li>Configuration via Environment Variables:  Loading the API key from an environment variable promotes security and allows for easy configuration without modifying the code.</li> <li>Token Estimation: The simple token estimation method provides a reasonable approximation for rate limiting purposes.</li> </ul>"},{"location":"packages/knowledge/docs/main/","title":"Main","text":""},{"location":"packages/knowledge/docs/main/#glassops-knowledge-pipeline-documentation","title":"GlassOps Knowledge Pipeline Documentation","text":"<p>This document describes the GlassOps Knowledge Pipeline, a system designed to manage and query documentation from various sources within a software project. The pipeline automates documentation discovery, embedding generation, index creation, drift detection, and retrieval-augmented generation (RAG) querying.</p> <p>Module Purpose:</p> <p>The <code>knowledge</code> package provides tools for building and interacting with a knowledge base derived from source code and other documentation. It supports automated documentation generation, semantic drift monitoring, and efficient information retrieval through vector search.</p> <p>Key Classes and Their Roles:</p> <ul> <li><code>Generator</code>: This class handles the generation of documentation from source code files. It takes a root directory as input and processes files matching specified patterns.</li> <li>Other classes are primarily functions within modules, but represent core pipeline stages:<ul> <li><code>discover_and_chunk_docs</code>: Responsible for locating and dividing documentation into manageable chunks.</li> <li><code>get_embeddings_for_docs</code>: Computes vector embeddings for each document chunk.</li> <li><code>build_or_update_index</code>: Creates or updates a vector store (index) using the generated embeddings.</li> <li><code>detect_drift</code>: Identifies documents that have undergone significant semantic changes.</li> <li><code>query_index</code>: Executes a RAG query against the vector store to retrieve relevant information.</li> </ul> </li> </ul> <p>Important Functions and Their Behavior:</p> <ul> <li><code>run_generate(patterns: list[str]) -&gt; None</code>:  This function initiates the documentation generation process. It takes a list of file patterns (globs) as input, instructing the <code>Generator</code> class to process files matching those patterns. The function prints informational messages to the console during execution.</li> <li><code>run_pipeline()</code>: This is the main function that orchestrates the entire knowledge pipeline. It parses command-line arguments, controls the execution flow, and calls other functions to perform specific tasks.<ul> <li>It supports the following command-line arguments:<ul> <li><code>--query</code> or <code>-q</code>:  Specifies a query string to execute against the knowledge base.</li> <li><code>query_pos</code>: Allows providing the query as positional arguments (joined by spaces).</li> <li><code>--index</code> or <code>-i</code>: Forces a re-indexing of all documents.</li> <li><code>--generate</code> or <code>-g</code>: Triggers documentation generation.</li> <li><code>--pattern</code> or <code>-p</code>: Specifies file patterns for documentation generation (can be used multiple times).</li> </ul> </li> </ul> </li> <li><code>discover_and_chunk_docs() -&gt; list</code>: This function discovers documentation files based on predefined or user-provided patterns and splits them into smaller chunks for embedding. The return value is a list of document chunks.</li> <li><code>get_embeddings_for_docs(docs: list, batch_size: int) -&gt; list</code>: This function takes a list of document chunks and generates vector embeddings for each chunk. It uses a router to select an embedding model (Gemini is primary, Gemma is fallback). The <code>batch_size</code> parameter controls the number of documents processed in each batch.</li> <li><code>build_or_update_index(embeddings: list) -&gt; None</code>: This function builds or updates a vector store (index) using the provided embeddings. The index allows for efficient similarity search.</li> <li><code>detect_drift(embeddings: list, threshold: float) -&gt; list</code>: This function detects semantic drift by comparing the current embeddings to a baseline. It returns a list of documents that have drifted beyond the specified <code>threshold</code>.</li> <li><code>query_index(query: str) -&gt; str</code>: This function executes a RAG query against the vector store. It retrieves the most relevant documents based on the query and generates a response.</li> </ul> <p>Type Hints and Their Significance:</p> <p>The code extensively uses type hints (e.g., <code>patterns: list[str]</code>, <code>batch_size: int</code>) to improve code readability and maintainability. Type hints allow static analysis tools to catch potential errors and provide better code completion suggestions. They also serve as documentation, clarifying the expected data types for function arguments and return values.</p> <p>Notable Patterns and Design Decisions:</p> <ul> <li>Configuration Management: The pipeline loads configuration parameters from a <code>config.json</code> file, allowing for easy customization of settings such as batch size and drift threshold.  It also supports loading environment variables from a <code>.env</code> file.</li> <li>Command-Line Interface: The <code>argparse</code> module is used to create a command-line interface, providing a flexible way to interact with the pipeline.</li> <li>Modularity: The pipeline is structured into separate modules (e.g., <code>ingestion</code>, <code>embeddings</code>, <code>drift</code>, <code>rag</code>, <code>generation</code>), each responsible for a specific task. This promotes code reuse and maintainability.</li> <li>Embedding Router/Fallback: The <code>get_embeddings_for_docs</code> function uses a router to select an embedding model. This allows for easy switching between different models and provides a fallback mechanism in case the primary model is unavailable.</li> <li>Semantic Drift Detection: The inclusion of semantic drift detection helps ensure the knowledge base remains up-to-date and accurate.</li> <li>Path Management: The code uses <code>pathlib.Path</code> for robust and platform-independent path manipulation.</li> <li>Error Handling: While not explicitly shown in the provided snippet, a production system would include comprehensive error handling and logging.</li> </ul>"},{"location":"packages/knowledge/docs/rag-__init__/","title":"Init","text":""},{"location":"packages/knowledge/docs/rag-__init__/#knowledge-retrieval-augmented-generation-rag-package-documentation","title":"Knowledge Retrieval Augmented Generation (RAG) Package Documentation","text":"<p>This document describes the <code>rag</code> package, a component designed for implementing Retrieval Augmented Generation workflows. It provides a simple interface for querying a knowledge index to enhance the responses of large language models.</p> <p>Module Purpose:</p> <p>The primary responsibility of the <code>rag</code> package is to expose functionality for querying a pre-built knowledge index. This index contains information that can be retrieved and provided to a language model alongside a user\u2019s prompt, improving the accuracy and relevance of the model\u2019s output. We aim to provide a streamlined way to integrate external knowledge into generation processes.</p> <p>Key Components:</p> <p>The package currently consists of a single publicly exposed function:</p> <ul> <li><code>query_index</code>: This function is the core of the package. It takes a query string as input and returns relevant information retrieved from the knowledge index.</li> </ul> <p>Function Details:</p> <ul> <li><code>query_index(query: str) -&gt; str</code>:     This function accepts a string <code>query</code> representing the user\u2019s information request. It searches the underlying knowledge index for content related to the query and returns a string containing the retrieved information. The returned string is intended to be appended to the user\u2019s prompt before sending it to a language model.</li> </ul> <p>Design Decisions and Patterns:</p> <p>The package adopts a minimalist approach, exposing only the essential functionality for querying the knowledge index. This design prioritizes simplicity and ease of integration. The <code>__all__</code> list explicitly defines the public interface, ensuring that only intended components are accessible to users.</p> <p>Type Hints:</p> <p>The use of type hints (e.g., <code>query: str</code>, <code>-&gt; str</code>) enhances code readability and maintainability. They also enable static analysis tools to verify the correctness of the code and help prevent errors. We believe that clear type annotations are important for building robust and reliable software.</p> <p>Usage:</p> <p>You can import and use the <code>query_index</code> function as follows:</p> <pre><code>from knowledge.rag import query_index\n\nrelevant_info = query_index(\"What is the capital of France?\")\nprint(relevant_info)\n</code></pre> <p>This will retrieve information about the capital of France from the knowledge index and print it to the console. You would then combine this <code>relevant_info</code> with your prompt to a language model.</p>"},{"location":"packages/knowledge/docs/rag-query_engine/","title":"Query Engine","text":""},{"location":"packages/knowledge/docs/rag-query_engine/#glassops-knowledge-query-engine-documentation","title":"GlassOps Knowledge Query Engine Documentation","text":"<p>This module provides a Retrieval-Augmented Generation (RAG) system for querying a knowledge base. It combines information retrieval from a vector database (ChromaDB) with a large language model (Gemini) to provide informed answers to user questions.</p> <p>Module Responsibilities:</p> <p>The primary function of this module is to accept a user query, retrieve relevant documents from a knowledge base, and generate a concise answer using a language model. It also incorporates a mechanism for injecting content from specific files based on keywords found in the query.</p> <p>Key Classes and Their Roles:</p> <p>This module primarily utilizes external libraries (chromadb, google.genai) and does not define custom classes. ChromaDB\u2019s <code>PersistentClient</code> and <code>Collection</code> are used for vector storage and retrieval.</p> <p>Important Functions and Their Behavior:</p> <ul> <li> <p><code>query_index(query: str, n_results: int = 5) -&gt; str</code>: This is the main function of the module. It takes a user <code>query</code> (string) and an optional <code>n_results</code> parameter (integer, default is 5) specifying the number of relevant documents to retrieve. It returns a string containing the generated answer, or an error message if something goes wrong.</p> <ol> <li>Embedding Generation: The function first generates an embedding vector for the input <code>query</code> using the <code>get_embeddings_for_docs</code> function. This embedding represents the semantic meaning of the query.</li> <li>ChromaDB Query: It then queries a ChromaDB collection named \"glassops_knowledge\" using the generated query embedding. The <code>n_results</code> parameter controls the number of documents retrieved.</li> <li>Context Construction: The retrieved documents and their corresponding IDs are used to construct a context string.</li> <li>Trigger-Based File Injection: The function checks for predefined keywords in the query. If a keyword is found, it attempts to inject the content of a corresponding file (specified in a <code>config.json</code> file) into the context. This allows for dynamic inclusion of up-to-date information.</li> <li>Answer Generation: Finally, it uses the Gemini language model to generate an answer based on the constructed context and the original query. The function includes a system prompt to guide the model's behavior.</li> <li>Error Handling: The function includes robust error handling to catch potential issues during embedding generation, ChromaDB querying, file injection, and answer generation. It returns informative error messages to the user.</li> </ol> </li> </ul> <p>Type Hints and Their Significance:</p> <p>The code uses type hints (e.g., <code>query: str</code>, <code>n_results: int</code>) to improve code readability and maintainability. These hints specify the expected data types for function parameters and return values, allowing for static analysis and early detection of potential errors.</p> <p>Notable Patterns and Design Decisions:</p> <ul> <li>RAG Architecture: The module implements a standard RAG architecture, combining information retrieval with language model generation.</li> <li>Configuration-Based Behavior: The system's behavior is partially configurable through a <code>config.json</code> file, allowing for customization of the system prompt and trigger-based file injection.</li> <li>Error Handling: Comprehensive error handling is implemented throughout the function to provide informative error messages and prevent unexpected crashes.</li> <li>Modular Design: The use of external libraries (chromadb, google.genai) promotes modularity and allows for easy replacement of components.</li> <li>Context Injection: The trigger-based file injection mechanism provides a way to dynamically update the knowledge base with information from external sources.</li> <li>Environment Variables: The API key for the Gemini model is loaded from an environment variable (<code>GOOGLE_API_KEY</code>), enhancing security and flexibility.</li> <li>Debugging: Print statements are included for debugging purposes, providing insights into the query process and file injection events.</li> </ul>"},{"location":"packages/knowledge/docs/tests-conftest/","title":"Conftest","text":""},{"location":"packages/knowledge/docs/tests-conftest/#knowledge-package-test-configuration","title":"Knowledge Package Test Configuration","text":"<p>This document describes the purpose and functionality of the <code>conftest.py</code> file within the knowledge package\u2019s test suite. This file is essential for setting up the testing environment, specifically ensuring that the core knowledge package code is accessible during test execution.</p> <p>Module Purpose:</p> <p>The primary responsibility of this module is to modify the Python import search path (<code>sys.path</code>) to include the root directory of the packages. This is necessary because the test files reside within a nested directory structure (<code>packages/knowledge/tests</code>) and, without modification, Python might not be able to locate the <code>knowledge</code> package itself when tests attempt to import it.</p> <p>Key Components:</p> <ol> <li> <p>Path Definitions:</p> <ul> <li><code>TEST_DIR</code>: A <code>Path</code> object representing the directory containing the current test file (<code>conftest.py</code>). This is determined using <code>Path(__file__).resolve().parent</code>.</li> <li><code>PACKAGES_DIR</code>: A <code>Path</code> object representing the root directory of the packages, located two levels above the test directory. This is calculated as <code>TEST_DIR.parent.parent</code>.</li> </ul> </li> <li> <p><code>sys.path</code> Modification:</p> <ul> <li>The code checks if the string representation of <code>PACKAGES_DIR</code> is already present in <code>sys.path</code>.</li> <li>If <code>PACKAGES_DIR</code> is not in <code>sys.path</code>, it is added to the beginning of the list using <code>sys.path.insert(0, str(PACKAGES_DIR))</code>.  Adding it to the beginning ensures that the packages directory is searched before other potential locations, preventing import conflicts.</li> <li>A print statement informs the user when the directory is added to <code>sys.path</code>.</li> </ul> </li> </ol> <p>Design Decisions and Patterns:</p> <ul> <li>Dynamic Path Resolution: The use of <code>Path(__file__).resolve()</code> ensures that the paths are resolved correctly regardless of how the tests are invoked (e.g., from different working directories).</li> <li>Absolute Paths: Converting <code>PACKAGES_DIR</code> to a string using <code>str()</code> before adding it to <code>sys.path</code> guarantees that an absolute path is used. This avoids ambiguity and ensures consistent behavior.</li> <li>Idempotency: The check <code>if str(PACKAGES_DIR) not in sys.path:</code> prevents the same directory from being added to <code>sys.path</code> multiple times, which could lead to unexpected behavior.</li> </ul> <p>How to Use:</p> <p>You do not directly interact with this file. It is automatically executed by the pytest testing framework when running tests within the <code>knowledge</code> package. Its purpose is to prepare the environment so that your tests can correctly import and function with the <code>knowledge</code> package code.</p>"},{"location":"packages/knowledge/docs/tests-test_validator/","title":"Validator Test","text":""},{"location":"packages/knowledge/docs/tests-test_validator/#knowledge-validator-documentation","title":"Knowledge Validator Documentation","text":"<p>This document details the functionality of the Knowledge Validator, a component designed to assess the quality and adherence to guidelines of knowledge content. It ensures content meets defined standards before being incorporated into a knowledge base.</p>"},{"location":"packages/knowledge/docs/tests-test_validator/#module-responsibilities","title":"Module Responsibilities","text":"<p>The primary responsibility of this module is to validate knowledge content, identifying potential issues such as missing metadata, prohibited language, and code quality concerns. The validator returns a structured report detailing any errors, warnings, or successful validations.</p>"},{"location":"packages/knowledge/docs/tests-test_validator/#key-classes","title":"Key Classes","text":"<p>Validator: This class serves as the central point for content validation. It orchestrates the validation process, including frontmatter checks, banned phrase/word detection, and code block validation via language-specific adapters.</p>"},{"location":"packages/knowledge/docs/tests-test_validator/#important-functions","title":"Important Functions","text":"<p>Validator.validate(content: str) -&gt; dict:</p> <p>This is the core function of the module. It accepts a string <code>content</code> representing the knowledge article and returns a dictionary containing validation results. The dictionary has the following keys:</p> <ul> <li><code>errors</code>: A list of strings, each representing a validation error.</li> <li><code>warnings</code>: A list of strings, each representing a potential issue or guideline violation.</li> <li><code>passes</code>: A list of strings, indicating successful validations (e.g., code block validation).</li> </ul> <p>The function performs the following checks:</p> <ol> <li>Frontmatter Check: Verifies the presence of a frontmatter block (delimited by <code>---</code>).  If missing, an error is reported.</li> <li>Banned Phrase Detection:  Scans the content for conversational phrases. If found, a warning is added to the results.</li> <li>Banned Word Detection:  Scans the content for prohibited words. If found, a warning is added to the results.</li> <li>Banned Term Detection: Scans the content for specific prohibited terms. If found, a warning is added to the results.</li> <li>Code Block Validation: Identifies code blocks within the content and delegates validation to a language-specific adapter.</li> </ol>"},{"location":"packages/knowledge/docs/tests-test_validator/#design-patterns-and-decisions","title":"Design Patterns and Decisions","text":"<ul> <li>Adapter Pattern: The validator employs an adapter pattern for code block validation.  The <code>get_adapter_for_lang</code> method (used in testing) is intended to retrieve an appropriate adapter based on the programming language detected in the code block. This allows for easy extension to support new languages without modifying the core validator logic.</li> <li>Structured Reporting: The use of a dictionary to return validation results provides a clear and organized way to communicate the outcome of the validation process.</li> <li>Type Hints: Type hints (e.g., <code>content: str -&gt; dict</code>) are used to improve code readability and maintainability, and to enable static analysis.</li> </ul>"},{"location":"packages/knowledge/docs/tests-test_validator/#test-cases-overview","title":"Test Cases Overview","text":"<p>The test suite covers the following scenarios:</p> <ul> <li>Basic Validation:  Confirms that valid content passes validation without errors or warnings.</li> <li>Missing Frontmatter:  Verifies that content lacking a frontmatter block is flagged with an error.</li> <li>Banned Phrases/Words:  Tests the detection of prohibited phrases and words, resulting in warnings.</li> <li>Banned Terms: Tests the detection of prohibited terms, resulting in warnings.</li> <li>Code Block Validation (Success):  Demonstrates successful delegation to a code adapter and the reporting of a successful validation.</li> <li>Code Block Validation (Failure):  Tests the handling of errors returned by a code adapter, resulting in an error in the validation report.</li> <li>Unknown Language: Confirms that code blocks with unknown languages are ignored without causing errors.</li> </ul> <p>You can extend the functionality by creating new adapters for different languages and adding more sophisticated validation rules.</p>"},{"location":"packages/knowledge/docs/utils-__init__/","title":"Utils   init","text":""},{"location":"packages/knowledge/docs/utils-__init__/#knowledge-package-utilities-documentation","title":"Knowledge Package Utilities Documentation","text":"<p>This document describes the utility functions provided within the <code>knowledge.utils</code> package. This package offers supporting functions for operations related to knowledge management, specifically focusing on file handling and data processing. We designed these utilities to be reusable components within the larger knowledge ecosystem.</p> <p>Module Responsibilities:</p> <p>The primary responsibility of this module is to expose helper functions that simplify common tasks encountered when working with knowledge artifacts, such as files and collections of data. These functions aim to improve code readability and maintainability by encapsulating frequently used logic.</p> <p>Key Components:</p> <ol> <li> <p><code>hash_file</code> Function:</p> </li> <li> <p>Purpose: This function computes a hash value for a given file. This is useful for verifying file integrity and detecting changes.</p> </li> <li>Signature: <code>hash_file(filepath: str) -&gt; str</code></li> <li>Parameters:<ul> <li><code>filepath</code> (str): The path to the file for which to calculate the hash.</li> </ul> </li> <li>Return Value: A string representing the hexadecimal hash of the file's contents.</li> <li>Type Hints: The type hint <code>str</code> for both the input and output clarifies that the function expects a file path as a string and returns the hash as a string.</li> <li> <p>Behavior: The function reads the file specified by <code>filepath</code>, calculates its SHA256 hash, and returns the hash as a hexadecimal string.</p> </li> <li> <p><code>batch_items</code> Function:</p> </li> <li> <p>Purpose: This function divides a list of items into batches of a specified size. This is helpful when processing large datasets or interacting with APIs that have rate limits or batch size restrictions.</p> </li> <li>Signature: <code>batch_items(items: list, batch_size: int) -&gt; list[list]</code></li> <li>Parameters:<ul> <li><code>items</code> (list): The list of items to be batched.</li> <li><code>batch_size</code> (int): The desired size of each batch.</li> </ul> </li> <li>Return Value: A list of lists, where each inner list represents a batch of items.</li> <li>Type Hints: <code>list</code> and <code>int</code> specify the expected types for the input parameters. <code>list[list]</code> indicates that the function returns a list containing other lists.</li> <li>Behavior: The function iterates through the input <code>items</code> list and creates batches of the specified <code>batch_size</code>. If the number of items is not evenly divisible by <code>batch_size</code>, the last batch will contain the remaining items.</li> </ol> <p>Design Decisions and Patterns:</p> <ul> <li>Explicit Exports: The <code>__all__</code> list explicitly defines the public interface of the module. This ensures that only intended functions are exposed to users of the package.</li> <li>Type Hinting: We have incorporated type hints throughout the module to improve code clarity, enable static analysis, and facilitate easier debugging. You can use these type hints with tools like MyPy to catch potential errors before runtime.</li> <li>Simplicity: The functions are designed to be simple and focused on specific tasks. This promotes reusability and reduces the risk of introducing unintended side effects.</li> </ul>"},{"location":"packages/knowledge/docs/utils-batch/","title":"Batch","text":""},{"location":"packages/knowledge/docs/utils-batch/#knowledge-package-batching-utility-documentation","title":"Knowledge Package: Batching Utility Documentation","text":"<p>This document describes the <code>batch.py</code> module within the knowledge package. This module provides a single function designed to divide a list of items into smaller, manageable batches. This is particularly useful when processing large datasets or interacting with APIs that have rate limits or batch size restrictions.</p> <p>Module Responsibilities:</p> <p>The primary responsibility of this module is to offer a simple and efficient way to iterate over a list of items in batches. It avoids loading the entire list into memory at once, making it suitable for large collections.</p> <p>Key Functions:</p> <ul> <li> <p><code>batch_items(items: list, batch_size: int = 10) -&gt; iter</code></p> <p>This function takes a list of <code>items</code> and an optional <code>batch_size</code> (defaulting to 10) as input. It then yields successive batches of items from the input list.</p> <ul> <li><code>items</code>: This argument represents the list that needs to be divided into batches. The type hint <code>list</code> indicates that it expects a Python list.</li> <li><code>batch_size</code>: This argument determines the maximum number of items in each batch. The type hint <code>int</code> specifies that it should be an integer.  A default value of 10 is provided.</li> <li><code>-&gt; iter</code>: This type hint indicates that the function returns an iterator. Each iteration of this iterator will produce a batch (a slice of the original list).</li> </ul> <p>Behavior:</p> <p>The function iterates through the input <code>items</code> list with a step size equal to <code>batch_size</code>. In each iteration, it yields a slice of the list containing up to <code>batch_size</code> items. If the length of the input list is not perfectly divisible by <code>batch_size</code>, the last batch will contain fewer items.</p> <p>Example:</p> <pre><code>my_list = list(range(25))\nfor batch in batch_items(my_list, 5):\n    print(batch)\n</code></pre> <p>This example will produce the following output:</p> <pre><code>[0, 1, 2, 3, 4]\n[5, 6, 7, 8, 9]\n[10, 11, 12, 13, 14]\n[15, 16, 17, 18, 19]\n[20, 21, 22, 23, 24]\n</code></pre> </li> </ul> <p>Design Decisions:</p> <ul> <li>Iterator-based approach: The function uses a generator (indicated by the <code>yield</code> keyword) to return an iterator. This is memory-efficient, as it only generates batches on demand, rather than creating all batches at once.</li> <li>Default batch size: A default <code>batch_size</code> of 10 is provided for convenience. You can adjust this value based on your specific needs.</li> <li>Type hints: Type hints are used to improve code readability and maintainability, and to enable static analysis tools to catch potential errors.</li> </ul>"},{"location":"packages/knowledge/docs/utils-file_hash/","title":"File Hash","text":""},{"location":"packages/knowledge/docs/utils-file_hash/#file-hash-utility-documentation","title":"File Hash Utility Documentation","text":"<p>This document describes the <code>file_hash</code> utility, a module designed for generating SHA256 hashes of files. It provides a simple and reliable method for verifying file integrity.</p> <p>Module Purpose:</p> <p>The primary responsibility of this module is to compute and return the SHA256 hash of a given file. This hash can be used to confirm that a file has not been altered or corrupted. We designed it to be a standalone function, easily integrated into larger systems requiring file verification.</p> <p>Key Functions:</p> <ul> <li> <p><code>hash_file(path: str) -&gt; str</code>: This function calculates the SHA256 hash of the file located at the specified <code>path</code>.</p> <ul> <li>Parameters:<ul> <li><code>path</code> (str): A string representing the file path to be hashed.</li> </ul> </li> <li>Return Value:<ul> <li>str: A string containing the hexadecimal representation of the SHA256 hash.</li> </ul> </li> <li>Behavior:<ol> <li>The function opens the file in binary read mode (<code>\"rb\"</code>).</li> <li>It reads the entire file content.</li> <li>It computes the SHA256 hash of the file content using the <code>hashlib</code> library.</li> <li>It returns the hash as a hexadecimal string.</li> </ol> </li> </ul> </li> </ul> <p>Type Hints:</p> <p>The function signature <code>hash_file(path: str) -&gt; str</code> employs type hints. These hints improve code readability and allow for static analysis, helping to catch potential errors during development. Specifically:</p> <ul> <li><code>path: str</code> indicates that the <code>path</code> parameter is expected to be a string.</li> <li><code>-&gt; str</code> indicates that the function is expected to return a string value.</li> </ul> <p>Design Decisions:</p> <ul> <li>SHA256 Algorithm: We selected SHA256 as the hashing algorithm due to its strong security properties and widespread adoption.</li> <li>Binary Read Mode: Opening the file in binary read mode (<code>\"rb\"</code>) ensures that the function can handle any type of file, regardless of its encoding.</li> <li>Full File Read: The function reads the entire file into memory before computing the hash. For very large files, this could potentially lead to memory issues. Consider alternative approaches like reading the file in chunks for extremely large files if memory consumption becomes a concern.</li> </ul>"},{"location":"packages/knowledge/docs/generated/drift_report/","title":"Knowledge Base Health Report","text":"<p>Generated: detect_drift.py</p>"},{"location":"packages/knowledge/docs/generated/drift_report/#conflicting-duplicate-documentation-detected","title":"Conflicting / Duplicate Documentation Detected","text":"<p>The following documents have identical content:</p> <ul> <li><code>.\\docs\\adr\\002-github-execution-authority.md#chunk-5</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\003-additive-governance.md#chunk-5</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\004-schema-contract-config.md#chunk-5</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\005-control-plane-architecture.md#chunk-7</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\006-documentation-as-governed-artifact.md#chunk-15</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\007-protocol-supremacy-enforcement.md#chunk-10</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\008-federated-documentation-structure.md#chunk-13</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\009-8-10-vs-10-10-bridge-strategy.md#chunk-13</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\010-identity-contract.md#chunk-14</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\adr\\011-monorepo-strategy.md#chunk-5</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\docs\\scripts-build-docs.md#chunk-1</code> is identical to <code>.\\docs\\scripts-build-docs.md#chunk-0</code></li> <li><code>.\\docs\\scripts-build-docs.md#chunk-2</code> is identical to <code>.\\docs\\scripts-build-docs.md#chunk-0</code></li> <li><code>.\\docs\\scripts-build-docs.md#chunk-3</code> is identical to <code>.\\docs\\scripts-build-docs.md#chunk-0</code></li> <li><code>.\\docs\\scripts-build-docs.md#chunk-4</code> is identical to <code>.\\docs\\scripts-build-docs.md#chunk-0</code></li> <li><code>.\\docs\\scripts-build-docs.md#chunk-5</code> is identical to <code>.\\docs\\scripts-build-docs.md#chunk-0</code></li> <li><code>.\\packages\\adapters\\native\\adr\\README.md#chunk-2</code> is identical to <code>.\\packages\\adapters\\hardis\\adr\\README.md#chunk-2</code></li> <li><code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-1</code> is identical to <code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-2</code> is identical to <code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-3</code> is identical to <code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-4</code> is identical to <code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-5</code> is identical to <code>.\\packages\\adapters\\native\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\adapters\\scanner\\docs\\adr\\README.md#chunk-2</code> is identical to <code>.\\packages\\adapters\\hardis\\adr\\README.md#chunk-2</code></li> <li><code>.\\packages\\control-plane\\adr\\001-kubernetes-operator-pattern.md#chunk-6</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\packages\\control-plane\\adr\\README.md#chunk-2</code> is identical to <code>.\\packages\\adapters\\hardis\\adr\\README.md#chunk-2</code></li> <li><code>.\\packages\\glassspec\\adr\\001-layered-contract-model.md#chunk-5</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\packages\\knowledge\\docs\\embeddings-__init__.md#chunk-1</code> is identical to <code>.\\packages\\knowledge\\docs\\embeddings-__init__.md#chunk-0</code></li> <li><code>.\\packages\\knowledge\\docs\\embeddings-__init__.md#chunk-2</code> is identical to <code>.\\packages\\knowledge\\docs\\embeddings-__init__.md#chunk-0</code></li> <li><code>.\\packages\\knowledge\\docs\\ingestion-index_builder.md#chunk-1</code> is identical to <code>.\\packages\\knowledge\\docs\\ingestion-index_builder.md#chunk-0</code></li> <li><code>.\\packages\\knowledge\\docs\\ingestion-index_builder.md#chunk-2</code> is identical to <code>.\\packages\\knowledge\\docs\\ingestion-index_builder.md#chunk-0</code></li> <li><code>.\\packages\\knowledge\\docs\\ingestion-index_builder.md#chunk-3</code> is identical to <code>.\\packages\\knowledge\\docs\\ingestion-index_builder.md#chunk-0</code></li> <li><code>.\\packages\\knowledge\\docs\\ingestion-index_builder.md#chunk-4</code> is identical to <code>.\\packages\\knowledge\\docs\\ingestion-index_builder.md#chunk-0</code></li> <li><code>.\\packages\\platform\\docs\\sfdx-project.md#chunk-1</code> is identical to <code>.\\packages\\platform\\docs\\sfdx-project.md#chunk-0</code></li> <li><code>.\\packages\\platform\\docs\\sfdx-project.md#chunk-2</code> is identical to <code>.\\packages\\platform\\docs\\sfdx-project.md#chunk-0</code></li> <li><code>.\\packages\\platform\\docs\\sfdx-project.md#chunk-3</code> is identical to <code>.\\packages\\platform\\docs\\sfdx-project.md#chunk-0</code></li> <li><code>.\\packages\\platform\\docs\\sfdx-project.md#chunk-4</code> is identical to <code>.\\packages\\platform\\docs\\sfdx-project.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\adr\\001-six-phase-execution.md#chunk-5</code> is identical to <code>.\\docs\\adr\\001-system-api-primitive.md#chunk-6</code></li> <li><code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-3</code> is identical to <code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-4</code> is identical to <code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-5</code> is identical to <code>.\\packages\\runtime\\docs\\Dockerfile.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\action.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\action.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\action.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\action.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\package.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\package.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\package.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\package.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\package.md#chunk-3</code> is identical to <code>.\\packages\\runtime\\docs\\package.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\tsconfig.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\tsconfig.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\tsconfig.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\tsconfig.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\tsconfig.md#chunk-3</code> is identical to <code>.\\packages\\runtime\\docs\\tsconfig.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-3</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-4</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-5</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-integration-tests.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-release.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-release.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-release.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-release.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-verify-auth-contract.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-verify-auth-contract.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-verify-auth-contract.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-verify-auth-contract.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-verify-governance.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-verify-governance.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-verify-governance.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-verify-governance.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-verify-governance.md#chunk-3</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-verify-governance.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-verify-primitives.md#chunk-1</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-verify-primitives.md#chunk-0</code></li> <li><code>.\\packages\\runtime\\docs\\workflows-verify-primitives.md#chunk-2</code> is identical to <code>.\\packages\\runtime\\docs\\workflows-verify-primitives.md#chunk-0</code></li> <li><code>.\\packages\\tools\\adr-enforcer\\docs\\adr\\README.md#chunk-2</code> is identical to <code>.\\packages\\adapters\\hardis\\adr\\README.md#chunk-2</code></li> <li><code>.\\packages\\tools\\adr-enforcer\\docs\\package.md#chunk-1</code> is identical to <code>.\\packages\\tools\\adr-enforcer\\docs\\package.md#chunk-0</code></li> <li><code>.\\packages\\tools\\adr-enforcer\\docs\\package.md#chunk-2</code> is identical to <code>.\\packages\\tools\\adr-enforcer\\docs\\package.md#chunk-0</code></li> <li><code>.\\packages\\tools\\adr-enforcer\\docs\\package.md#chunk-3</code> is identical to <code>.\\packages\\tools\\adr-enforcer\\docs\\package.md#chunk-0</code></li> </ul>"},{"location":"packages/knowledge/docs/generated/drift_report/#drift-status","title":"Drift Status","text":"<p>No significant semantic drift detected in this run.</p>"},{"location":"packages/platform/","title":"GlassOps Platform","text":"<p>This package serves as a container for platform-level configurations and meta-data.</p>"},{"location":"packages/platform/docs/","title":"GlassOps Platform Documentation","text":"<p>Documentation for the platform configuration and root components.</p>"},{"location":"packages/platform/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/platform/docs/sfdx-project/","title":"SFDX Project Configuration","text":"<p>This document details the structure and purpose of the <code>sfdx-project.json</code> file. This file is the central configuration for projects managed with the Salesforce DX (SFDX) command-line interface. It defines how SFDX interacts with your Salesforce organization and manages your source code.</p>"},{"location":"packages/platform/docs/sfdx-project/#overview","title":"Overview","text":"<p>The <code>sfdx-project.json</code> file provides metadata about your SFDX project. It specifies the package directories, project name, namespace, Salesforce login URL, and the API version of your target Salesforce organization. We use this file to understand the project's structure and dependencies when performing operations like source retrieval, deployment, and testing.</p>"},{"location":"packages/platform/docs/sfdx-project/#schema-details","title":"Schema Details","text":"<p>The <code>sfdx-project.json</code> file is a JSON object with the following key attributes:</p>"},{"location":"packages/platform/docs/sfdx-project/#packagedirectories-array-of-objects-required","title":"<code>packageDirectories</code> (Array of Objects, Required)","text":"<p>This array defines the packages within your project. Each object in the array represents a single package.</p> <ul> <li><code>path</code> (String, Required): The relative path to the directory containing the package's source code.</li> <li><code>default</code> (Boolean, Required):  Indicates whether this package is the default package for SFDX commands. Only one package can be designated as the default.</li> <li><code>package</code> (String, Required): The name of the package. This is the logical name used to identify the package.</li> <li><code>versionName</code> (String, Required): A human-readable version name for the package (e.g., \"ver 1.0\").</li> <li><code>versionNumber</code> (String, Required): The version number of the package, following semantic versioning (e.g., \"1.0.0.NEXT\"). The <code>.NEXT</code> suffix indicates an unreleased version.</li> </ul> <p>In the provided example, two package directories are defined:</p> <ol> <li><code>glassops-platform</code>: Contains the core \"GlassOps\" package. It is not the default package.</li> <li><code>force-app</code>: Contains the \"GlassOps Implementation\" package. This is the default package.</li> </ol>"},{"location":"packages/platform/docs/sfdx-project/#name-string-required","title":"<code>name</code> (String, Required)","text":"<p>The name of the SFDX project. This is a descriptive name for your overall project. In the example, the project name is \"glassops\".</p>"},{"location":"packages/platform/docs/sfdx-project/#namespace-string-required","title":"<code>namespace</code> (String, Required)","text":"<p>The namespace for your Salesforce organization. If you are working in a Developer Edition organization or a scratch org without a namespace, this value will be an empty string (\"\").  You should update this if you are deploying to an organization with a custom namespace.</p>"},{"location":"packages/platform/docs/sfdx-project/#sfdcloginurl-string-required","title":"<code>sfdcLoginUrl</code> (String, Required)","text":"<p>The URL used to log in to your Salesforce organization. The default value is <code>https://login.salesforce.com</code> for production environments. You may need to change this for sandboxes or other specific environments.</p>"},{"location":"packages/platform/docs/sfdx-project/#sourceapiversion-string-required","title":"<code>sourceApiVersion</code> (String, Required)","text":"<p>The API version of the target Salesforce organization. This ensures compatibility between your source code and the organization.  In the example, the source API version is \"60.0\". You should update this to match the API version of the organization you are deploying to.</p>"},{"location":"packages/platform/docs/sfdx-project/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Project Setup: When you initialize a new SFDX project, we create this file to define the project's initial configuration.</li> <li>Source Management:  SFDX uses this file to determine which directories contain Salesforce source code and how to manage those sources.</li> <li>Deployment: During deployment, SFDX uses the <code>packageDirectories</code> information to package and deploy your code to the target organization.</li> <li>Scratch Org Creation: When creating scratch orgs, SFDX uses the <code>sourceApiVersion</code> to ensure the scratch org is created with the correct API version.</li> <li>Package Versioning: The <code>versionName</code> and <code>versionNumber</code> attributes allow you to track and manage different versions of your packages.</li> </ul>"},{"location":"packages/platform/docs/sfdx-project/#updating-the-configuration","title":"Updating the Configuration","text":"<p>You can modify this file directly using a text editor. However, it is recommended to use the SFDX CLI commands to manage the configuration. For example, you can use the <code>sfdx project update</code> command to update the <code>sourceApiVersion</code>.  Always validate the JSON syntax after making changes.</p>"},{"location":"packages/runtime/","title":"GlassOps Runtime","text":"<p>The Bootstrapping Primitive for Secure, Governed Execution.</p> <p>Status: Alpha (Go Implementation) Version: 1.0.0</p> <p>The Runtime is the trusted core of the GlassOps ecosystem. It bootstraps a secure environment, validates identity, enforces policy, and hands off a signed Permit to downstream adapters.</p>"},{"location":"packages/runtime/#architecture","title":"Architecture","text":"<p>The Runtime executes in 3 Strictly Defined Phases:</p> <ol> <li> <p>Phase 1: Policy Enforcement</p> <ul> <li>Loads <code>devops-config.json</code>.</li> <li>Enforces \"Freeze Windows\" (e.g., No deploys on Friday).</li> <li>Validates static analysis results (if enabled).</li> </ul> </li> <li> <p>Phase 2: Identity Resolution</p> <ul> <li>Exchanges GitHub Secrets (<code>JWT_KEY</code>) for a Salesforce session token.</li> <li>Security: Secrets never leave this phase. Downstream adapters receiving the Permit get a verified session ID, not the private key.</li> </ul> </li> <li> <p>Phase 3: Context Handoff (Permit Generation)</p> <ul> <li>Generates the Permit Contract (<code>.glassops/glassops-permit.json</code>).</li> <li>This contract contains the Verified Identity and Policy Evaluation Results.</li> </ul> </li> </ol>"},{"location":"packages/runtime/#contract-artifacts","title":"Contract Artifacts","text":"<p>The Runtime produces ephemeral artifacts in the <code>.glassops/</code> directory (gitignored):</p> <ul> <li><code>glassops-permit.json</code>: The \"ticket\" that authorizes an Adapter to perform work.</li> <li><code>glassops-contract.json</code>: The initial compliance contract (deployment status, audit trail).</li> </ul>"},{"location":"packages/runtime/#usage-github-actions","title":"Usage (GitHub Actions)","text":"<pre><code>- name: GlassOps Runtime\n  uses: glassops-platform/glassops/packages/runtime@v1\n  with:\n      client_id: ${{ secrets.SF_CLIENT_ID }}\n      jwt_key: ${{ secrets.SF_JWT_KEY }}\n      username: ${{ vars.SF_USERNAME }}\n</code></pre>"},{"location":"packages/runtime/#inputs","title":"Inputs","text":"Input Description Required <code>jwt_key</code> PEM-encoded private key Yes <code>client_id</code> Connected App Consumer Key Yes <code>username</code> Salesforce Username Yes <code>instance_url</code> Login URL (default: <code>https://login.salesforce.com</code>) No <code>skip_auth</code> Set to <code>true</code> to skip Salesforce auth (for testing) No"},{"location":"packages/runtime/#outputs","title":"Outputs","text":"Output Description <code>glassops_ready</code> <code>true</code> if runtime suceeded. <code>org_id</code> The authenticated Organization ID. <code>runtime_id</code> Unique UUID for this execution session. <code>is_locked</code> <code>true</code> if a freeze window is active."},{"location":"packages/runtime/#local-development","title":"Local Development","text":"<p>We provide first-class support for local debugging and testing.</p>"},{"location":"packages/runtime/#prerequisites","title":"Prerequisites","text":"<ul> <li>Go 1.21+</li> <li>Salesforce CLI (<code>sf</code>)</li> </ul>"},{"location":"packages/runtime/#helper-scripts-root","title":"Helper Scripts (Root)","text":"<ul> <li>Build: <code>npm run runtime:build</code> (Builds to <code>dist/glassops.exe</code>)</li> <li>Test: <code>npm run runtime:test</code> (Runs Go unit tests)</li> </ul>"},{"location":"packages/runtime/#debugging-in-vs-code","title":"debugging in VS Code","text":"<ol> <li>Create a <code>.env</code> file in the root (see <code>.env.example</code> logic).</li> <li>Key File Support: To avoid multiline env var issues, point <code>INPUT_JWT_KEY_FILE</code> to your local <code>secrets/server.key</code>.</li> <li>Press F5 (Debug GlassOps) to run the runtime with breakpoints.</li> </ol>"},{"location":"packages/runtime/CHANGELOG/","title":"Changelog","text":"<p>All notable changes to GlassOps Runtime will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"packages/runtime/CHANGELOG/#unreleased","title":"[Unreleased]","text":""},{"location":"packages/runtime/CHANGELOG/#added","title":"Added","text":"<ul> <li>Comprehensive documentation in <code>docs/</code> directory</li> <li>Automated release workflow with semantic versioning</li> <li>Enhanced test coverage (98.46% statements, 85.71% branches)</li> <li>Code coverage reporting with configurable thresholds</li> <li>CHANGELOG.md for release tracking</li> </ul>"},{"location":"packages/runtime/CHANGELOG/#fixed","title":"Fixed","text":"<ul> <li>Security vulnerabilities in transitive dependencies</li> <li>Linting errors and unused imports/variables</li> <li>TypeScript ESLint compatibility warnings</li> <li>Test coverage gaps in policy loading error handling</li> </ul>"},{"location":"packages/runtime/CHANGELOG/#changed","title":"Changed","text":"<ul> <li>Improved Jest configuration with coverage collection</li> <li>Enhanced error handling and test cases</li> <li>Better code organization and documentation</li> </ul>"},{"location":"packages/runtime/CHANGELOG/#security","title":"Security","text":"<ul> <li>Updated dependencies to address known vulnerabilities</li> <li>Improved credential handling and cleanup procedures</li> </ul>"},{"location":"packages/runtime/CONTRIBUTING/","title":"Contributing to GlassOps Runtime\u2122","text":"<p>We love your input! We want to make contributing to GlassOps as easy and transparent as possible, whether it's reporting a bug, proposing a new feature, or submitting a fix.</p>"},{"location":"packages/runtime/CONTRIBUTING/#legal-notice-personal-capacity","title":"\ud83d\udee1\ufe0f Legal Notice: Personal Capacity","text":"<p>To ensure the long-term independence and professional integrity of the GlassOps\u2122 platform, all contributions must be made in a personal capacity.</p> <p>By submitting a Pull Request, you represent and warrant that:</p> <ol> <li>Individual Action: You are making this contribution in your personal capacity and not as an employee, agent, or representative of any other entity.</li> <li>Resource Independence: You are not using any equipment, trade secrets, confidential information, or proprietary resources belonging to an employer or third party to develop this contribution.</li> <li>Right to License: You have the full legal right to grant the licenses set forth in the Apache License, Version 2.0.</li> </ol>"},{"location":"packages/runtime/CONTRIBUTING/#community-governance","title":"\ud83c\udfd7\ufe0f Community Governance","text":""},{"location":"packages/runtime/CONTRIBUTING/#the-glassops-protocol","title":"The GlassOps Protocol","text":"<p>GlassOps is a governance-first protocol. We prioritize architectural health and \"One Trigger Per Object\" discipline over raw deployment speed.</p>"},{"location":"packages/runtime/CONTRIBUTING/#adoption-metrics","title":"Adoption Metrics","text":"<p>Before proposing a major change, consider if it aligns with our target maturity levels:</p> Maturity Level Component Who it's for Day 0 Native Adapter Teams wanting safe, transparent execution. Day 30 Scanner Adapter Teams ready to enforce architectural hygiene. Day 90 Hardis Adapter Teams ready for high-velocity automation."},{"location":"packages/runtime/CONTRIBUTING/#how-to-contribute","title":"\ud83d\ude80 How to Contribute","text":""},{"location":"packages/runtime/CONTRIBUTING/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repo and create your branch from <code>main</code>.</li> <li>Clean Room Standard: Ensure your contribution is independent of any proprietary or work-related logic.</li> <li>Test: Verify your changes against the Deployment Contract v1.0 schema.</li> <li>Lint: Ensure the CI build passes and follow the project's TypeScript standards.</li> <li>Issue: Submit your Pull Request!</li> </ol>"},{"location":"packages/runtime/CONTRIBUTING/#report-bugs","title":"Report Bugs","text":"<p>We use GitHub issues to track public bugs. Report a bug by opening a new issue.</p> <p>Great Bug Reports tend to have:</p> <ul> <li>A quick summary and background.</li> <li>Specific steps to reproduce (including sample code).</li> <li>Expected vs. actual outcomes.</li> <li>Notes on troubleshooting steps you\u2019ve already attempted.</li> </ul>"},{"location":"packages/runtime/CONTRIBUTING/#license-trademark","title":"\u2696\ufe0f License &amp; Trademark","text":"<p>By contributing, you agree that your contributions will be licensed under the Apache License, Version 2.0.</p> <p>GlassOps\u2122 is a trademark of Ryan Bumstead. This project does not grant permission to use the trade names, trademarks, or service marks of the Licensor except as required for reasonable and customary use in describing the origin of the Work.</p>"},{"location":"packages/runtime/LICENSE/","title":"LICENSE","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of     this License, each Contributor hereby grants to You a perpetual,     worldwide, non-exclusive, no-charge, royalty-free, irrevocable     copyright license to reproduce, prepare Derivative Works of,     publicly display, publicly perform, sublicense, and distribute the     Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of     this License, each Contributor hereby grants to You a perpetual,     worldwide, non-exclusive, no-charge, royalty-free, irrevocable     (except as stated in this section) patent license to make, have made,     use, offer to sell, sell, import, and otherwise transfer the Work,     where such license applies only to those patent claims licensable     by such Contributor that are necessarily infringed by their     Contribution(s) alone or by combination of their Contribution(s)     with the Work to which such Contribution(s) was submitted. If You     institute patent litigation against any entity (including a     cross-claim or counterclaim in a lawsuit) alleging that the Work     or a Contribution incorporated within the Work constitutes direct     or contributory patent infringement, then any patent licenses     granted to You under this License for that Work shall terminate     as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the     Work or Derivative Works thereof in any medium, with or without     modifications, and in Source or Object form, provided that You     meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,     any Contribution intentionally submitted for inclusion in the Work     by You to the Licensor shall be under the terms and conditions of     this License, without any additional terms or conditions.     Notwithstanding the above, nothing herein shall supersede or modify     the terms of any separate license agreement you may have executed     with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade     names, trademarks, service marks, or product names of the Licensor,     except as required for reasonable and customary use in describing the     origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or     agreed to in writing, Licensor provides the Work (and each     Contributor provides its Contributions) on an \"AS IS\" BASIS,     WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or     implied, including, without limitation, any warranties or conditions     of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A     PARTICULAR PURPOSE. You are solely responsible for determining the     appropriateness of using or redistributing the Work and assume any     risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,     whether in tort (including negligence), contract, or otherwise,     unless required by applicable law (such as deliberate and grossly     negligent acts) or agreed to in writing, shall any Contributor be     liable to You for damages, including any direct, indirect, special,     incidental, or consequential damages of any character arising as a     result of this License or out of the use or inability to use the     Work (including but not limited to damages for loss of goodwill,     work stoppage, computer failure or malfunction, or any and all     other commercial damages or losses), even if such Contributor     has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing     the Work or Derivative Works thereof, You may choose to offer,     and charge a fee for, acceptance of support, warranty, indemnity,     or other liability obligations and/or rights consistent with this     License. However, in accepting such obligations, You may act only     on Your own behalf and on Your sole responsibility, not on behalf     of any other Contributor, and only if You agree to indemnify,     defend, and hold each Contributor harmless for any liability     incurred by, or claims asserted against, such Contributor by reason     of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright 2026 Ryan Bumstead</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"packages/runtime/SECURITY/","title":"Security Policy","text":""},{"location":"packages/runtime/SECURITY/#supported-versions","title":"Supported Versions","text":"Version Supported 1.x :white_check_mark: &lt; 1.0 :x:"},{"location":"packages/runtime/SECURITY/#reporting-a-vulnerability","title":"Reporting a Vulnerability","text":"<p>We take security vulnerabilities seriously. If you discover a security issue, please report it responsibly.</p>"},{"location":"packages/runtime/SECURITY/#how-to-report","title":"How to Report","text":"<ol> <li>Do NOT open a public GitHub issue for security vulnerabilities</li> <li>Email security concerns to the repository maintainer</li> <li>Include a detailed description of the vulnerability</li> <li>Provide steps to reproduce if possible</li> </ol>"},{"location":"packages/runtime/SECURITY/#what-to-expect","title":"What to Expect","text":"<ul> <li>Acknowledgment: We will acknowledge receipt within 48 hours</li> <li>Assessment: We will assess the vulnerability and determine its severity</li> <li>Resolution: Critical vulnerabilities will be addressed as priority</li> <li>Disclosure: We will coordinate disclosure timing with you</li> </ul>"},{"location":"packages/runtime/SECURITY/#scope","title":"Scope","text":"<p>This security policy applies to:</p> <ul> <li>The <code>glassops-runtime</code> GitHub Action</li> <li>Related configuration schemas and contracts</li> <li>CI/CD workflow templates</li> </ul>"},{"location":"packages/runtime/SECURITY/#out-of-scope","title":"Out of Scope","text":"<ul> <li>Vulnerabilities in third-party dependencies (report these upstream)</li> <li>Issues in user-provided configuration files</li> <li>Theoretical vulnerabilities without proof of concept</li> </ul>"},{"location":"packages/runtime/SECURITY/#security-best-practices","title":"Security Best Practices","text":"<p>When using GlassOps Runtime:</p> <ol> <li>Secrets Management: Always use GitHub Secrets for sensitive values (<code>jwt_key</code>, <code>client_id</code>)</li> <li>Least Privilege: Use dedicated External Client Apps with minimal permissions</li> <li>Audit Logs: Store deployment contracts for compliance audit trails</li> <li>Version Pinning: Pin to specific versions in production workflows</li> </ol>"},{"location":"packages/runtime/SECURITY/#acknowledgments","title":"Acknowledgments","text":"<p>We appreciate researchers who practice responsible disclosure.</p>"},{"location":"packages/runtime/TRADEMARK/","title":"GlassOps\u2122 Trademark Policy","text":"<p>GlassOps is a trademark of Ryan Bumstead.</p> <p>This software is licensed under the Apache License 2.0. The Apache License does not grant permission to use the trade names, trademarks, service marks, or product names of the project.</p>"},{"location":"packages/runtime/TRADEMARK/#permitted-uses","title":"Permitted Uses","text":"<ul> <li>Referring to the software as \"GlassOps\" in documentation</li> <li>Using the software internally within your organization</li> <li>Contributing to the project via pull requests</li> </ul>"},{"location":"packages/runtime/TRADEMARK/#restricted-uses","title":"Restricted Uses","text":"<ul> <li>Distributing modified versions under the \"GlassOps\" name</li> <li>Using \"GlassOps\" in commercial product names</li> <li>Claiming endorsement or affiliation without permission</li> </ul>"},{"location":"packages/runtime/TRADEMARK/#commercial-licensing","title":"Commercial Licensing","text":"<p>For commercial use of the GlassOps trademark, contact: [ryan@ryanbumstead.com]</p>"},{"location":"packages/runtime/adr/","title":"GlassOps Runtime - Architecture Decision Records","text":"<p>This directory contains Architecture Decision Records (ADRs) specific to the GlassOps Runtime execution primitive.</p>"},{"location":"packages/runtime/adr/#scope","title":"Scope","text":"<p>ADRs in this directory cover decisions related to:</p> <ul> <li>Runtime phase execution model</li> <li>CLI wrapper patterns</li> <li>Contract generation and atomicity</li> <li>Authentication strategies</li> <li>Error handling and resilience</li> </ul>"},{"location":"packages/runtime/adr/#current-adrs","title":"Current ADRs","text":"Number Title Status Date 001 Six Phase Execution Model Accepted 2024-01-20 002 Caching Strategy in Docker Runtime Accepted 2024-02-01"},{"location":"packages/runtime/adr/#proposed-decisions-to-document","title":"Proposed Decisions to Document","text":"<ol> <li>Runtime Phase Execution Model - The 6-phase execution pattern</li> <li>CLI Wrapper vs Direct Commands - Using sf CLI vs @salesforce packages</li> <li>Contract Atomicity Strategy - Temp file + rename pattern</li> <li>JWT-OAuth Authentication - Strict identity enforcement</li> <li>Cache Strategy - Protocol-linked cache design</li> </ol>"},{"location":"packages/runtime/adr/#creating-a-new-adr","title":"Creating a New ADR","text":"<p>See the Master ADR Index for the template and guidelines.</p> <p>Quick start:</p> <pre><code>cp adr-template.md 001-your-decision-title.md\n# Edit the file\n# Update this README\n# Update ../../../../docs/adr-index.md\n</code></pre> <p>Related Documentation:</p> <ul> <li>Master ADR Index</li> <li>GlassOps ADRs</li> <li>Runtime Package README</li> </ul>"},{"location":"packages/runtime/adr/001-six-phase-execution/","title":"ADR 001: 6-Phase Runtime Execution Model","text":"<p>Status: Accepted Date: 2026-01-24 Context: GlassOps Runtime Architecture</p>"},{"location":"packages/runtime/adr/001-six-phase-execution/#context","title":"Context","text":"<p>Running ad-hoc scripts in CI pipelines creates a \"governance gap.\" We need a deterministic, repeatable way to execute Salesforce deployments that ensures policy is checked before execution and that outcomes are recorded after.</p>"},{"location":"packages/runtime/adr/001-six-phase-execution/#decision","title":"Decision","text":"<p>GlassOps Runtime enforces a strict 6-Phase Execution Model for every operation:</p> <ol> <li>Phase 0: Cache Retrieval - Restore environment from Protocol-Linked Cache.</li> <li>Phase 1: Policy Evaluation - Check Freeze Windows and effective policy rules.</li> <li>Phase 2: Bootstrap - Install exact CLI versions defined in policy.</li> <li>Phase 3: Static Analysis (Optional) - Run scanners and validate ADRs.</li> <li>Phase 4: Identity &amp; Execution - Authenticate (JWT) and execute the Adapter.</li> <li>Phase 5: Contract Validation - Emit and validate the SARIF contract.</li> </ol>"},{"location":"packages/runtime/adr/001-six-phase-execution/#rationale","title":"Rationale","text":"<ol> <li>Fail Fast: Policy (Phase 1) runs before Bootstrap (Phase 2), saving time if a Freeze Window is active.</li> <li>Determinism: Bootstrap (Phase 2) ensures the CLI version is explicitly managed, preventing \"it worked on my machine\" issues.</li> <li>Security: Identity (Phase 4) is JIT-injected only when needed, reducing surface area.</li> <li>Traceability: Every execution is guaranteed to produce a Contract (Phase 5).</li> </ol>"},{"location":"packages/runtime/adr/001-six-phase-execution/#consequences","title":"Consequences","text":"<ul> <li>Positive: Guaranteed consistency across all deployments. No \"hidden scripts.\"</li> <li>Negative: Adds slight overhead (seconds) to small jobs compared to raw CLI.</li> <li>Compliance: This model satisfies SOC 2 \"Change Management\" controls by design.</li> </ul> <p>Author: Ryan Bumstead</p>"},{"location":"packages/runtime/adr/001-six-phase-execution/#alternatives","title":"Alternatives","text":"<ul> <li>None considered.</li> </ul>"},{"location":"packages/runtime/adr/002-docker-caching-strategy/","title":"ADR 002: Caching Strategy in Docker Runtime","text":""},{"location":"packages/runtime/adr/002-docker-caching-strategy/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"packages/runtime/adr/002-docker-caching-strategy/#context","title":"Context","text":"<p>In GitHub Actions pipelines, caching dependencies (like <code>node_modules</code> or <code>~/.local/share/sfdx</code>) is a common pattern to improve performance. The legacy TypeScript runtime (<code>runtime-ts</code>) attempted to use <code>@actions/cache</code> for this purpose.</p> <p>However, the GlassOps Runtime executes as a Docker Container Action. This introduces significant challenges for traditional file-based caching:</p> <ol> <li>Isolation: The runtime executes inside a container, isolated from the runner's file system except for mounted volumes (typically only <code>GITHUB_WORKSPACE</code>).</li> <li>API Access: To access the GitHub Actions Cache API, the container needs the <code>ACTIONS_CACHE_URL</code> and <code>ACTIONS_RUNTIME_TOKEN</code> environment variables, which are not automatically passed to container actions for security reasons.</li> <li>Ineffectiveness: Investigation revealed that the legacy runtime often failed to access the cache API when running in Docker, effectively rendering the cache logic dead code.</li> </ol>"},{"location":"packages/runtime/adr/002-docker-caching-strategy/#decision","title":"Decision","text":"<p>We will NOT implement dynamic file-based caching (e.g., caching plugins or CLI updates) within the Go Runtime at this time.</p> <p>Instead, we will rely on Immutable Docker Images as the primary caching mechanism.</p>"},{"location":"packages/runtime/adr/002-docker-caching-strategy/#rationale","title":"Rationale","text":"<ol> <li>Immutability &amp; Determinism: The <code>Dockerfile</code> already pre-installs the Salesforce CLI and necessary tools. By baking dependencies into the image, we ensure that every run uses the exact same version of tools, eliminating \"it works on my machine\" issues caused by drift in cached plugins.</li> <li>Simplicity: Implementing a custom cache client in Go that talks to the undocumented GitHub Actions Cache API\u2014while managing token passing\u2014adds significant complexity to the codebase for marginal gain.</li> <li>Correctness: If a user needs specific plugins, they should be using a specific version of the GlassOps Runtime image (or a derivative image) that has those plugins installed, rather than relying on runtime installation and caching.</li> </ol>"},{"location":"packages/runtime/adr/002-docker-caching-strategy/#consequences","title":"Consequences","text":"<ul> <li>Performance: Users needing heavy custom plugins that are not in the base image will incur installation time on every run.</li> <li>Mitigation: We will recommend users with heavy customization needs to build their own Docker image <code>FROM glassops/runtime</code> and install plugins there.</li> <li>Cleanliness: The runtime code remains focused on governance and orchestration, not package management.</li> </ul>"},{"location":"packages/runtime/adr/002-docker-caching-strategy/#alternatives","title":"Alternatives","text":"<ul> <li>Use @actions/cache: Attempted in <code>runtime-ts</code> but failed reliably in Docker contexts.</li> <li>Pass Secrets: We could pass <code>ACTIONS_RUNTIME_TOKEN</code> to the container, but this increases the security surface area.</li> <li>Volume Mounting: We could mount a host directory for caching, but this requires user configuration and breaks the \"zero-config\" goal.</li> </ul>"},{"location":"packages/runtime/docs/Dockerfile/","title":"Dockerfile Documentation: glassops Runtime","text":""},{"location":"packages/runtime/docs/Dockerfile/#overview","title":"Overview","text":"<p>This Dockerfile defines the build and runtime environment for the <code>glassops</code> application, a Go-based tool. It employs a multi-stage build to minimize the final image size and improve security. We aim to provide a self-contained environment for running <code>glassops</code> with the Salesforce CLI.</p>"},{"location":"packages/runtime/docs/Dockerfile/#base-images","title":"Base Images","text":"<ul> <li><code>golang:1.25-alpine</code> (Builder Stage): This image is based on Alpine Linux and includes the Go 1.25 toolchain. Alpine is chosen for its small size, reducing the build image footprint.</li> <li><code>alpine:3.19</code> (Runtime Stage):  This image is also based on Alpine Linux, providing a minimal base for the runtime environment. Its small size contributes to a smaller final image.</li> </ul>"},{"location":"packages/runtime/docs/Dockerfile/#stages","title":"Stages","text":"<p>The Dockerfile consists of two stages:</p> <ol> <li>Builder Stage: Responsible for compiling the Go application.</li> <li>Runtime Stage:  Responsible for creating the final image containing only the compiled binary and necessary runtime dependencies.</li> </ol>"},{"location":"packages/runtime/docs/Dockerfile/#key-instructions-and-purpose","title":"Key Instructions and Purpose","text":"<ul> <li><code>FROM &lt;image&gt; AS &lt;name&gt;</code>: Defines the base image for a stage and assigns it a name for referencing in later stages.</li> <li><code>WORKDIR /app</code>: Sets the working directory inside the container. Subsequent commands will be executed from this directory.</li> <li><code>COPY &lt;src&gt; &lt;dest&gt;</code>: Copies files or directories from the host machine to the container's filesystem.</li> <li><code>RUN &lt;command&gt;</code>: Executes a command inside the container during the build process.</li> <li><code>go mod download</code>: Downloads the Go module dependencies defined in <code>go.mod</code> and <code>go.sum</code>. The <code>|| true</code> ensures the build doesn't fail if the download fails (e.g., due to network issues) during initial setup.</li> <li><code>CGO_ENABLED=0 GOOS=linux go build -ldflags=\"-s -w\" -o /glassops ./cmd/glassops</code>: Compiles the Go application.<ul> <li><code>CGO_ENABLED=0</code>: Disables CGO, resulting in a more portable binary.</li> <li><code>GOOS=linux</code>: Sets the target operating system to Linux.</li> <li><code>-ldflags=\"-s -w\"</code>: Strips debug information and symbol table from the binary, reducing its size.</li> <li><code>-o /glassops</code>: Specifies the output path and name of the compiled binary.</li> <li><code>./cmd/glassops</code>: Specifies the main package to build.</li> </ul> </li> <li><code>apk add --no-cache nodejs npm git coreutils</code>: Installs Node.js, npm, git, and coreutils within the runtime stage. <code>--no-cache</code> minimizes image size by not storing the package cache. Coreutils provides the <code>env -S</code> command, required by the Salesforce CLI.</li> <li><code>npm install -g @salesforce/cli</code>: Installs the Salesforce CLI globally using npm.</li> <li><code>COPY --from=builder /glassops /usr/local/bin/glassops</code>: Copies the compiled binary from the builder stage to the runtime stage.</li> <li><code>ENTRYPOINT [\"/usr/local/bin/glassops\"]</code>: Defines the command that will be executed when the container starts.</li> </ul>"},{"location":"packages/runtime/docs/Dockerfile/#security-considerations","title":"Security Considerations","text":"<ul> <li>Minimal Base Images: Using Alpine Linux as the base image reduces the attack surface due to its small size and limited number of installed packages.</li> <li>Stripped Binary: Removing debug information from the binary using <code>-ldflags=\"-s -w\"</code> reduces the amount of potentially sensitive information included in the image.</li> <li>No Root User: The Dockerfile does not explicitly create or switch to a root user. The application will run as the default user within the Alpine image.</li> <li>Package Management: Using <code>apk add --no-cache</code> avoids caching package lists, reducing the risk of outdated or vulnerable packages.</li> <li>Dependency Management: The <code>go.mod</code> and <code>go.sum</code> files ensure reproducible builds and help prevent dependency-related vulnerabilities.</li> </ul>"},{"location":"packages/runtime/docs/Dockerfile/#building-and-running-the-container","title":"Building and Running the Container","text":"<ol> <li> <p>Build the image:</p> <p>You can build the Docker image using the following command from the directory containing the Dockerfile:</p> <pre><code>docker build -t glassops-runtime .\n</code></pre> </li> <li> <p>Run the container:</p> <p>You can run the container using the following command:</p> <pre><code>docker run -it --rm glassops-runtime\n</code></pre> <ul> <li><code>-it</code>: Allocates a pseudo-TTY and keeps STDIN open, allowing you to interact with the container.</li> <li><code>--rm</code>: Automatically removes the container when it exits.</li> <li><code>glassops-runtime</code>: The name of the image to run.</li> </ul> </li> </ol> <p>You may need to configure the Salesforce CLI within the container after it starts, using <code>sf config set ...</code>.</p>"},{"location":"packages/runtime/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/runtime/docs/action/","title":"GlassOps Runtime Action Documentation","text":"<p>This document details the configuration for the GlassOps Runtime action. This action bootstraps a governed Salesforce execution environment, ensuring adherence to the GlassOps Protocol.</p>"},{"location":"packages/runtime/docs/action/#purpose","title":"Purpose","text":"<p>The primary purpose of this action is to set up a secure and controlled environment for interacting with a Salesforce organization. It handles authentication, policy enforcement, and provides outputs for tracking the execution session.</p>"},{"location":"packages/runtime/docs/action/#structure","title":"Structure","text":"<p>The configuration is structured as a YAML file with the following top-level keys:</p> <ul> <li><code>name</code>: A descriptive name for the action.</li> <li><code>description</code>: A detailed explanation of the action's purpose.</li> <li><code>author</code>: The creator of the action.</li> <li><code>branding</code>: Visual elements for the action.</li> <li><code>inputs</code>: Parameters that You provide to customize the action's behavior.</li> <li><code>outputs</code>: Values that the action produces and makes available for subsequent steps.</li> <li><code>runs</code>: Specifies how the action is executed.</li> </ul>"},{"location":"packages/runtime/docs/action/#key-details","title":"Key Details","text":""},{"location":"packages/runtime/docs/action/#name","title":"<code>name</code>","text":"<ul> <li>Type: String</li> <li>Value: <code>'GlassOps Runtime'</code></li> <li>Purpose:  Identifies the action.</li> </ul>"},{"location":"packages/runtime/docs/action/#description","title":"<code>description</code>","text":"<ul> <li>Type: String</li> <li>Value: <code>'Bootstraps a governed Salesforce execution environment adhering to the GlassOps Protocol.'</code></li> <li>Purpose: Provides a human-readable explanation of the action.</li> </ul>"},{"location":"packages/runtime/docs/action/#author","title":"<code>author</code>","text":"<ul> <li>Type: String</li> <li>Value: <code>'Ryan Bumstead'</code></li> <li>Purpose:  Identifies the action's creator.</li> </ul>"},{"location":"packages/runtime/docs/action/#branding","title":"<code>branding</code>","text":"<ul> <li>Type: Object<ul> <li><code>icon</code>: String, Value: <code>'shield'</code>, Purpose:  Icon to represent the action.</li> <li><code>color</code>: String, Value: <code>'blue'</code>, Purpose: Color associated with the action.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/action/#inputs","title":"<code>inputs</code>","text":"<p>This section defines the input parameters for the action.</p> <ul> <li><code>jwt_key</code><ul> <li>Type: String</li> <li>Required: <code>true</code></li> <li>Purpose: The private key used for JSON Web Token (JWT) based authentication.</li> </ul> </li> <li><code>client_id</code><ul> <li>Type: String</li> <li>Required: <code>true</code></li> <li>Purpose: The consumer key for the external client application.</li> </ul> </li> <li><code>username</code><ul> <li>Type: String</li> <li>Required: <code>true</code></li> <li>Purpose: The username of the target Salesforce organization.</li> </ul> </li> <li><code>instance_url</code><ul> <li>Type: String</li> <li>Required: <code>false</code></li> <li>Default: <code>'https://login.salesforce.com'</code></li> <li>Purpose: The Salesforce login URL.  You can specify <code>https://test.salesforce.com</code> for sandbox environments.</li> </ul> </li> <li><code>enforce_policy</code><ul> <li>Type: Boolean</li> <li>Required: <code>false</code></li> <li>Default: <code>'true'</code></li> <li>Purpose:  Determines whether to scan the <code>devops-config.json</code> file for policy violations before allowing CLI access.</li> </ul> </li> <li><code>test_results</code><ul> <li>Type: String</li> <li>Required: <code>false</code></li> <li>Purpose: A JSON string containing test results in the format <code>{\"total\": 100, \"passed\": 95, \"failed\": 5}</code>.</li> </ul> </li> <li><code>coverage_percentage</code><ul> <li>Type: Integer</li> <li>Required: <code>false</code></li> <li>Purpose: The code coverage percentage achieved during testing (a value between 0 and 100).</li> </ul> </li> <li><code>coverage_required</code><ul> <li>Type: Integer</li> <li>Required: <code>false</code></li> <li>Default: <code>'80'</code></li> <li>Purpose: The minimum required code coverage percentage.</li> </ul> </li> <li><code>plugins</code><ul> <li>Type: String</li> <li>Required: <code>false</code></li> <li>Purpose: A comma-separated list of Salesforce CLI plugins to install. Example: <code>'sfdx-hardis,@salesforce/plugin-deploy-retrieve'</code>.</li> </ul> </li> <li><code>skip_auth</code><ul> <li>Type: Boolean</li> <li>Required: <code>false</code></li> <li>Default: <code>'false'</code></li> <li>Purpose:  If set to <code>true</code>, skips Salesforce authentication. This is useful for CI/governance testing scenarios.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/action/#outputs","title":"<code>outputs</code>","text":"<p>This section defines the outputs produced by the action.</p> <ul> <li><code>runtime_id</code><ul> <li>Type: String</li> <li>Purpose: A unique identifier for the execution session.</li> </ul> </li> <li><code>org_id</code><ul> <li>Type: String</li> <li>Purpose: The ID of the authenticated Salesforce organization.</li> </ul> </li> <li><code>is_locked</code><ul> <li>Type: Boolean</li> <li>Purpose: Indicates whether the environment is currently frozen due to policy restrictions.</li> </ul> </li> <li><code>contract_path</code><ul> <li>Type: String</li> <li>Purpose: The file path to the generated deployment contract JSON file.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/action/#runs","title":"<code>runs</code>","text":"<ul> <li><code>using</code>: String, Value: <code>'docker'</code>, Purpose: Specifies that the action is executed within a Docker container.</li> <li><code>image</code>: String, Value: <code>'Dockerfile'</code>, Purpose:  Specifies the Dockerfile used to build the container image. We maintain this Dockerfile within the repository.</li> </ul>"},{"location":"packages/runtime/docs/analyzer-analyzer/","title":"Analyzer analyzer","text":""},{"location":"packages/runtime/docs/analyzer-analyzer/#analyzer-package-documentation","title":"Analyzer Package Documentation","text":"<p>This package provides an interface to the Salesforce Code Analyzer, a tool for static code analysis of Salesforce projects. We aim to integrate this analysis into a broader governance and compliance framework.</p> <p>Package Responsibilities:</p> <p>The <code>analyzer</code> package is responsible for:</p> <ul> <li>Executing the Salesforce Code Analyzer command-line interface (CLI).</li> <li>Parsing the analyzer\u2019s JSON output to extract code violations.</li> <li>Filtering violations based on configurable severity thresholds.</li> <li>Enforcing compatibility by ensuring the correct analyzer version is in use.</li> <li>Integrating with policy configurations to determine when and how to run the analysis.</li> </ul> <p>Key Types:</p> <ul> <li><code>Result</code>: Represents the outcome of a code analysis scan. It contains a slice of <code>Violation</code> objects and the analyzer\u2019s exit code.     <pre><code>type Result struct {\n    Violations []Violation\n    ExitCode   int\n}\n</code></pre></li> <li><code>Violation</code>: Represents a single code violation found during analysis. It includes details such as the rule name, description, severity, file name, and line number.     <pre><code>type Violation struct {\n    Rule        string `json:\"rule\"`\n    Description string `json:\"description\"`\n    Severity    int    `json:\"severity\"`\n    File        string `json:\"file\"`\n    Line        int    `json:\"line\"`\n}\n</code></pre></li> <li><code>Analyzer</code>:  A struct that encapsulates the logic for interacting with the Salesforce Code Analyzer. It provides methods for running scans and parsing results.     <pre><code>type Analyzer struct{}\n</code></pre></li> </ul> <p>Important Functions:</p> <ul> <li><code>New()</code>:  A constructor function that returns a new instance of the <code>Analyzer</code> struct.     <pre><code>func New() *Analyzer {\n    return &amp;Analyzer{}\n}\n</code></pre></li> <li><code>Scan(paths []string, ruleset string) (*Result, error)</code>: Executes the Salesforce Code Analyzer on the specified file paths.  You provide a list of paths to scan and an optional ruleset to apply. The function returns a <code>Result</code> object containing any violations found and the analyzer\u2019s exit code.  It handles potential errors during execution and parsing.     <pre><code>func (a *Analyzer) Scan(paths []string, ruleset string) (*Result, error) {\n    // ... implementation details ...\n}\n</code></pre></li> <li><code>RunIfEnabled(config *policy.Config) error</code>:  Determines whether to run the analyzer based on the provided policy configuration. If the analyzer is enabled in the configuration, it executes a scan on the current directory (<code>.</code>) using the specified ruleset (if any). It filters violations based on the configured severity threshold and returns an error if critical violations are found.     <pre><code>func (a *Analyzer) RunIfEnabled(config *policy.Config) error {\n    // ... implementation details ...\n}\n</code></pre></li> <li><code>EnsureCompatibility() error</code>:  Performs checks to ensure the environment is correctly configured for using the analyzer. Currently, this function serves as a placeholder for future compatibility enforcement, such as verifying the correct version of the Salesforce CLI is installed.     <pre><code>func (a *Analyzer) EnsureCompatibility() error {\n    // ... implementation details ...\n}\n</code></pre></li> <li><code>parseOutput(jsonOutput string, exitCode int) *Result</code>: Parses the JSON output from the Salesforce Code Analyzer and extracts the code violations. It handles cases where the output may contain extraneous characters and gracefully handles parsing errors.     <pre><code>func (a *Analyzer) parseOutput(jsonOutput string, exitCode int) *Result {\n    // ... implementation details ...\n}\n</code></pre></li> </ul> <p>Error Handling:</p> <p>The package employs standard Go error handling practices. Functions return an <code>error</code> value to indicate failure. Errors are often wrapped using <code>fmt.Errorf</code> to provide context.  The <code>gha.Error</code> function is used to log errors for visibility within the broader platform.</p> <p>Concurrency:</p> <p>This package does not currently employ goroutines or channels for concurrent execution. The Salesforce Code Analyzer is executed as a synchronous process.</p> <p>Design Decisions:</p> <ul> <li>We chose to wrap the Salesforce Code Analyzer CLI rather than reimplementing its functionality to leverage its existing capabilities and avoid maintenance overhead.</li> <li>The <code>RunIfEnabled</code> function provides a convenient way to integrate the analyzer into a policy-driven workflow.</li> <li>The <code>parseOutput</code> function is designed to be resilient to variations in the analyzer\u2019s output format.</li> <li>The package is designed to be extensible, allowing for future additions such as support for multiple rulesets and more sophisticated violation filtering.</li> </ul>"},{"location":"packages/runtime/docs/analyzer-analyzer_test/","title":"Analyzer analyzer test","text":""},{"location":"packages/runtime/docs/analyzer-analyzer_test/#analyzer-package-documentation","title":"Analyzer Package Documentation","text":"<p>This document describes the functionality of the <code>analyzer</code> package. The package is responsible for parsing output from external tools, specifically focusing on identifying code quality violations reported in JSON format. It provides a mechanism to convert raw output into a structured representation of violations for further processing.</p> <p>Package Responsibilities:</p> <ul> <li>Parsing output from code analysis tools.</li> <li>Extracting violation details (rule name, message, severity, file, line number).</li> <li>Handling various output scenarios, including valid JSON, invalid JSON, non-JSON output, and cluttered output.</li> <li>Providing a consistent interface for accessing violation data.</li> </ul> <p>Key Types:</p> <ul> <li>Analyzer: This is the primary type in the package. It encapsulates the logic for parsing output and managing violation data.  It is created using the <code>New()</code> function.</li> <li>Violation: This type represents a single code quality violation. It contains the following fields:<ul> <li><code>Rule</code>: The name of the rule that was violated (string).</li> <li><code>Message</code>: A descriptive message explaining the violation (string).</li> <li><code>Severity</code>: An integer representing the severity of the violation.</li> <li><code>Line</code>: The line number where the violation occurred (integer).</li> <li><code>File</code>: The name of the file where the violation occurred (string).</li> </ul> </li> <li>AnalysisResult: This type holds the results of the analysis. It contains:<ul> <li><code>Violations</code>: A slice of <code>Violation</code> structs representing all detected violations.</li> <li><code>ExitCode</code>: The exit code of the analyzed process (integer).</li> </ul> </li> </ul> <p>Important Functions:</p> <ul> <li>New() -&gt; *Analyzer: This function creates and returns a new instance of the <code>Analyzer</code> type. It serves as the constructor for the analyzer.</li> <li>EnsureCompatibility() error: This function performs any necessary compatibility checks. Currently, it does not return an error.</li> <li>parseOutput(output string, exitCode int) AnalysisResult: This is the core function of the package. It takes the output string from an external tool and the tool's exit code as input. It attempts to parse the output as a JSON array of violation objects. If the output is not valid JSON, it returns an <code>AnalysisResult</code> with an empty <code>Violations</code> slice. It handles cases where the output is empty, contains non-JSON content, or is invalid JSON. The function returns an <code>AnalysisResult</code> containing the parsed violations and the provided exit code.</li> </ul> <p>Error Handling:</p> <p>The <code>parseOutput</code> function handles potential errors during JSON parsing gracefully. If the input string is not valid JSON, it does not panic. Instead, it returns an <code>AnalysisResult</code> with an empty <code>Violations</code> slice, indicating that no violations were found.  The <code>EnsureCompatibility</code> function currently does not return an error.</p> <p>Concurrency:</p> <p>This package does not currently employ goroutines or channels, and operates in a single-threaded manner.</p> <p>Design Decisions:</p> <ul> <li>JSON-centric: The package is specifically designed to parse JSON output from code analysis tools. This simplifies the parsing logic and allows for a structured representation of violations.</li> <li>Robust Parsing: The <code>parseOutput</code> function is designed to be robust and handle various input scenarios, including invalid JSON and non-JSON content. This ensures that the package can handle unexpected output from external tools without crashing.</li> <li>Clear Data Structures: The <code>Violation</code> and <code>AnalysisResult</code> types provide a clear and concise representation of the analysis results. This makes it easy for other parts of the system to access and process the violation data.</li> </ul>"},{"location":"packages/runtime/docs/config-jest.config/","title":"Jest Config","text":""},{"location":"packages/runtime/docs/config-jest.config/#jest-configuration-for-runtime-package","title":"Jest Configuration for Runtime Package","text":"<p>Document Version: 1.0 Date: October 26, 2023 Author: Principal Architect</p> <p>1. Introduction</p> <p>This document details the Jest configuration for the <code>runtime</code> package. This configuration defines how automated tests are executed and reported, ensuring code quality and reliability. It is designed for both developers and stakeholders needing to understand the testing framework setup.</p> <p>2. Configuration Overview</p> <p>The <code>jest.config.js</code> file specifies the settings for the Jest testing framework. These settings control test discovery, execution environment, code coverage analysis, and reporting.</p> <p>3. Key Configuration Elements</p> <ul> <li><code>preset: \"ts-jest\"</code>:  Utilizes the <code>ts-jest</code> preset, enabling Jest to directly execute TypeScript code without pre-transpilation. This simplifies the testing process and improves developer experience.</li> <li><code>testEnvironment: \"node\"</code>:  Specifies that tests should be run in a Node.js environment. This is appropriate for server-side runtime code.</li> <li><code>rootDir: \"../\"</code>: Sets the root directory for the project to the parent directory of the <code>packages/runtime/config</code> folder. This ensures that test paths are correctly resolved relative to the project's source code.</li> <li><code>testMatch: [\"&lt;rootDir&gt;/src/**/*.test.ts\"]</code>: Defines the glob pattern used to identify test files.  Tests are located within the <code>src</code> directory and have the <code>.test.ts</code> extension.</li> <li><code>testPathIgnorePatterns</code>:  Specifies patterns for files or directories that should be excluded from test execution.<ul> <li><code>\"&lt;rootDir&gt;/src/integration/\"</code>: Excludes the entire <code>integration</code> directory.</li> <li><code>\".*\\\\.integration\\\\.test\\\\.ts$\"</code>: Excludes any file ending in <code>.integration.test.ts</code>. This allows for separate, potentially slower, integration tests to be run independently.</li> </ul> </li> <li><code>moduleFileExtensions: [\"ts\", \"js\", \"json\", \"node\"]</code>:  Defines the file extensions that Jest should recognize when resolving modules.</li> <li><code>collectCoverage: true</code>: Enables code coverage collection during test execution.</li> <li><code>coverageDirectory: \"coverage\"</code>: Specifies the directory where code coverage reports will be stored.</li> <li><code>coverageReporters</code>:  Configures the types of code coverage reports generated.<ul> <li><code>\"text\"</code>:  Displays a text-based summary of coverage in the console.</li> <li><code>\"lcov\"</code>: Generates an LCOV report, suitable for integration with code coverage tools.</li> <li><code>\"html\"</code>: Creates an HTML report for visual inspection of code coverage.</li> <li><code>\"json-summary\"</code>: Produces a JSON summary of coverage data.</li> </ul> </li> <li><code>coverageThreshold</code>:  Sets minimum acceptable code coverage thresholds.  Tests will fail if coverage falls below these levels.<ul> <li><code>global</code>: Applies to the entire codebase.<ul> <li><code>branches: 80</code>: Requires at least 80% branch coverage.</li> <li><code>functions: 80</code>: Requires at least 80% function coverage.</li> <li><code>lines: 80</code>: Requires at least 80% line coverage.</li> <li><code>statements: 80</code>: Requires at least 80% statement coverage.</li> </ul> </li> </ul> </li> </ul> <p>4. Purpose and Benefits</p> <p>This configuration ensures:</p> <ul> <li>Comprehensive Testing:  All relevant TypeScript test files are automatically discovered and executed.</li> <li>Code Quality:  Coverage thresholds enforce a minimum level of code coverage, promoting thorough testing.</li> <li>Detailed Reporting:  Multiple report formats provide insights into test results and code coverage.</li> <li>Simplified Development: <code>ts-jest</code> simplifies the testing process for TypeScript code.</li> <li>Maintainability: Clear and consistent configuration promotes maintainability and reduces the risk of errors.</li> </ul>"},{"location":"packages/runtime/docs/config-jest.integration.config/","title":"Jest Integration Config","text":""},{"location":"packages/runtime/docs/config-jest.integration.config/#jest-integration-test-configuration","title":"Jest Integration Test Configuration","text":"<p>Document Version: 1.0 Date: October 26, 2023 Author: Principal Architect</p> <p>1. Introduction</p> <p>This document details the configuration for Jest integration tests within the runtime package. These tests verify the interaction between different components of the system, ensuring they function correctly when combined. This configuration is designed to provide comprehensive test coverage and reliable results.</p> <p>2. Core Configuration</p> <ul> <li>Test Runner: Jest is utilized as the test runner.</li> <li>TypeScript Support: <code>ts-jest</code> is employed to enable direct testing of TypeScript code without pre-compilation.</li> <li>Test Environment: Tests are executed within a Node.js environment.</li> <li>Source Code Root: The root directory for source code is set to <code>../src</code>.</li> <li>Test File Pattern: Tests are identified by the filename pattern <code>**/*.integration.test.ts</code>.</li> </ul> <p>3. Test Execution &amp; Performance</p> <ul> <li>Timeout:  A test timeout of 30 seconds (30000 milliseconds) is enforced for each integration test, accommodating potentially longer execution times inherent in integration testing.</li> <li>Module Transformation:  Node modules are generally excluded from the transformation process to improve performance. Specific packages requiring transformation can be explicitly included if necessary.</li> </ul> <p>4. Code Coverage</p> <ul> <li>Coverage Enabled: Code coverage is enabled to measure the extent to which the codebase is exercised by the integration tests.</li> <li>Coverage Directory: Coverage reports are generated and stored in the <code>../coverage/integration</code> directory.</li> <li>Coverage Reporters:  Multiple coverage report formats are generated:<ul> <li>Text:  A human-readable text summary in the console.</li> <li>Lcov:  A format suitable for integration with external coverage analysis tools.</li> <li>HTML:  An interactive HTML report for detailed code coverage visualization.</li> <li>JSON Summary: A concise JSON summary of coverage metrics.</li> </ul> </li> <li>Coverage Scope: Coverage is collected from all TypeScript files (<code>**/*.ts</code>) except:<ul> <li>Test files (<code>**/*.test.ts</code>, <code>**/*.integration.test.ts</code>).</li> <li>Files within <code>node_modules</code>.</li> <li>The main entry point file (<code>index.ts</code>), which is covered by End-to-End (E2E) tests.</li> <li>Integration test helper files (<code>integration/test-helpers.ts</code>), which contain test utilities and are not part of the production code.</li> </ul> </li> </ul> <p>5. Test Setup</p> <ul> <li>Setup File: The <code>jest.integration.setup.js</code> file (located in <code>../config</code>) is executed before each integration test to configure the test environment, mock dependencies, and perform any necessary initialization. This ensures a consistent and isolated testing environment.</li> </ul>"},{"location":"packages/runtime/docs/config-jest.integration.setup/","title":"Jest Integration Setup","text":""},{"location":"packages/runtime/docs/config-jest.integration.setup/#integration-test-environment-configuration","title":"Integration Test Environment Configuration","text":"<p>Document Version: 1.0 Date: October 26, 2023 Author: Principal Architect</p> <p>1. Introduction</p> <p>This document details the configuration applied to the integration test environment for the runtime package.  It outlines the environment variables established and modifications made to the Jest testing framework to facilitate reliable and reproducible integration tests.</p> <p>2. Purpose</p> <p>The primary goal of this configuration is to simulate a typical GitHub Actions environment for integration tests, even when running locally. This ensures tests accurately reflect real-world execution conditions.  Additionally, it adjusts testing parameters to accommodate the longer execution times often associated with integration tests.</p> <p>3. Environment Variable Setup</p> <p>The following environment variables are set to default values if they are not already defined in the execution environment. These variables mimic those provided by the GitHub Actions platform:</p> <ul> <li><code>GITHUB_WORKSPACE</code>:  Set to the current working directory (<code>process.cwd()</code>) if not already defined. Represents the project's workspace.</li> <li><code>GITHUB_ACTOR</code>: Set to \"integration-test\" if not already defined. Represents the user or application triggering the workflow.</li> <li><code>GITHUB_REPOSITORY</code>: Set to \"test/integration\" if not already defined. Represents the repository where the workflow is running.</li> <li><code>GITHUB_RUN_ID</code>: Set to \"12345\" if not already defined.  A unique identifier for the current workflow run.</li> <li><code>GITHUB_SHA</code>: Set to \"abc123def456\" if not already defined.  The commit SHA triggering the workflow.</li> <li><code>GITHUB_EVENT_NAME</code>: Set to \"push\" if not already defined.  The event that triggered the workflow (e.g., push, pull_request).</li> </ul> <p>4. Jest Configuration</p> <ul> <li>Timeout Increase: The default Jest timeout is increased to 30,000 milliseconds (30 seconds) to accommodate the potentially longer execution times of integration tests.  This prevents tests from failing prematurely due to timeout issues.</li> <li>Console Output Control:  A helper is provided to optionally suppress console output during test execution.  Currently, the default console logging functions are preserved.  Commented-out code demonstrates how to replace them with Jest mock functions to silence console output if desired. This is useful for focusing on test results without extraneous logging.</li> </ul> <p>5. Dependencies</p> <ul> <li>Jest testing framework.</li> <li>Node.js runtime environment.</li> </ul> <p>6. Future Considerations</p> <ul> <li>Explore more granular control over environment variable overrides via a configuration file.</li> <li>Implement a mechanism to dynamically adjust the timeout based on test suite size or complexity.</li> </ul>"},{"location":"packages/runtime/docs/contract-contract/","title":"Contract contract","text":""},{"location":"packages/runtime/docs/contract-contract/#deployment-contract-package-documentation","title":"Deployment Contract Package Documentation","text":"<p>This package defines the schema and functionality for a deployment contract, representing the governance output of a deployment process. The contract captures metadata, status, quality metrics, and audit information related to a deployment. It is designed to be generated during runtime and persisted for record-keeping and potential downstream actions.</p> <p>Key Types and Interfaces</p> <ul> <li><code>DeploymentContract</code>: The central structure representing the complete deployment contract. It contains fields for schema version, metadata, status, quality, and audit information.</li> <li><code>Meta</code>:  Holds execution metadata such as the adapter used, the engine type (native, hardis, or custom), timestamp, and the trigger event.</li> <li><code>Quality</code>: Encapsulates code quality metrics, including code coverage and test results.</li> <li><code>Coverage</code>:  Represents code coverage data, tracking actual coverage, required coverage, and whether the requirement is met.</li> <li><code>TestResults</code>: Stores the results of test execution, including the total number of tests, the number passed, and the number failed.</li> <li><code>Audit</code>: Contains audit trail information, including who triggered the deployment, the organization ID, the repository, and the commit hash.</li> <li><code>ValidationError</code>: A custom error type used to signal validation failures within the contract. It includes the field that failed validation and a descriptive message.</li> </ul> <p>Important Functions</p> <ul> <li><code>New()</code>: Creates a new <code>DeploymentContract</code> instance with default values.  Defaults include schema version \"1.0\", a native adapter and engine, the current UTC timestamp, a \"Succeeded\" status, and a coverage requirement of 80%.</li> <li><code>ToJSON()</code>: Serializes a <code>DeploymentContract</code> instance into a JSON byte slice with indentation for readability.</li> <li><code>Validate()</code>: Validates the <code>DeploymentContract</code> to ensure all required fields are present and contain valid values. It checks the status, engine type, and coverage percentages. Returns a <code>ValidationError</code> if validation fails, otherwise returns nil.</li> <li><code>Generate(orgID string)</code>:  Generates a <code>DeploymentContract</code> based on input data (primarily from environment variables and GitHub Actions inputs), writes it to a file named <code>glassops-contract.json</code> within a <code>.glassops</code> directory in the workspace, and returns the file path.  It retrieves test results and coverage data from inputs, defaulting to zero values if inputs are missing or invalid. It also populates audit information using environment variables.</li> </ul> <p>Error Handling</p> <p>The package employs standard Go error handling practices. Functions return an error value when operations fail.  A custom error type, <code>ValidationError</code>, is used for contract validation failures, providing specific information about the invalid field and the reason for the failure.  Errors encountered during JSON marshaling, file system operations, or input parsing are also returned.</p> <p>Concurrency</p> <p>This package does not explicitly use goroutines or channels. It operates in a single-threaded manner.</p> <p>Design Decisions</p> <ul> <li>JSON Serialization: The contract is serialized to JSON for portability and ease of integration with other systems.</li> <li>Input-Driven Generation: The <code>Generate</code> function is designed to be driven by external inputs (environment variables and GitHub Actions inputs), making it flexible and adaptable to different deployment environments.</li> <li>Default Values: Sensible default values are provided in the <code>New</code> function to simplify contract creation and reduce the amount of required configuration.</li> <li>Validation:  The <code>Validate</code> function ensures data integrity and prevents invalid contracts from being persisted.</li> <li>Directory Structure: The contract is written to a <code>.glassops</code> directory within the workspace to keep it separate from other project files. The directory is created if it does not exist.</li> <li>Environment Variable Fallback: The <code>hasEnvOr</code> function provides a mechanism to retrieve environment variables with a fallback value if the variable is not set.</li> </ul>"},{"location":"packages/runtime/docs/contract-contract_test/","title":"Contract contract test","text":""},{"location":"packages/runtime/docs/contract-contract_test/#contract-package-documentation","title":"Contract Package Documentation","text":"<p>This package defines the <code>Contract</code> type and associated methods for representing and validating operational agreements. It serves as a central structure for defining expectations around deployments, quality gates, and auditability. We aim to provide a standardized way to express these contracts, enabling automated verification and enforcement.</p> <p>Key Types and Interfaces</p> <ul> <li> <p><code>Contract</code>: This is the primary type in the package. It encapsulates all information related to a contract, including schema version, metadata, status, quality metrics, and audit details.</p> <ul> <li><code>SchemaVersion</code> (string): Indicates the version of the contract schema. Currently set to \"1.0\".</li> <li><code>Meta</code> (struct): Contains metadata about the contract, including the adapter and engine being used.<ul> <li><code>Adapter</code> (string): Specifies the adapter used for the contract, defaulting to \"native\".</li> <li><code>Engine</code> (string): Specifies the engine used for the contract, defaulting to \"native\".</li> </ul> </li> <li><code>Status</code> (string): Represents the current status of the contract (e.g., \"Succeeded\", \"Failed\", \"Blocked\").</li> <li><code>Quality</code> (struct): Holds quality-related information.<ul> <li><code>Coverage</code> (struct): Details code coverage metrics.<ul> <li><code>Actual</code> (float64): The actual code coverage achieved.</li> <li><code>Required</code> (float64): The minimum required code coverage.</li> <li><code>Met</code> (bool): Indicates whether the actual coverage meets the required coverage.</li> </ul> </li> </ul> </li> <li><code>Audit</code> (struct): Stores audit information related to the contract.<ul> <li><code>TriggeredBy</code> (string): The user or system that triggered the contract.</li> <li><code>OrgID</code> (string): The organization ID associated with the contract.</li> <li><code>Repository</code> (string): The repository associated with the contract.</li> <li><code>Commit</code> (string): The commit associated with the contract.</li> </ul> </li> </ul> </li> </ul> <p>Important Functions</p> <ul> <li><code>New()</code>: This function creates and returns a new <code>Contract</code> instance with default values. This ensures a consistent starting point for contract creation.</li> <li><code>ToJSON()</code>: This function converts the <code>Contract</code> object into a JSON byte array. It is used for serialization and persistence of contract data. It returns an error if the conversion fails. You should check for this error to ensure data integrity.</li> <li><code>Validate()</code>: This function validates the <code>Contract</code> object, checking for valid status, engine, and coverage values. It returns an error if any validation fails, providing feedback on what needs to be corrected.</li> </ul> <p>Error Handling</p> <p>The package employs standard Go error handling practices. Functions return an <code>error</code> value to indicate failure. You should always check the returned error value and handle it appropriately.  Validation errors provide specific details about the validation failure, aiding in debugging and correction.</p> <p>Concurrency</p> <p>This package does not currently employ goroutines or channels. It is designed to operate synchronously.</p> <p>Design Decisions</p> <ul> <li>Default Values: The <code>New()</code> function provides sensible default values for contract fields, simplifying contract creation and reducing boilerplate code.</li> <li>Validation: The <code>Validate()</code> function enforces constraints on contract fields, ensuring data integrity and preventing invalid states.</li> <li>JSON Serialization: The <code>ToJSON()</code> function enables easy serialization of contracts for storage and transmission.</li> <li>Explicit Validation Rules:  Separate validation tests exist for <code>Status</code>, <code>Engine</code>, and <code>Coverage</code> to provide clear and focused validation logic. This improves maintainability and readability.</li> </ul>"},{"location":"packages/runtime/docs/errors-errors/","title":"Errors errors","text":""},{"location":"packages/runtime/docs/errors-errors/#glassops-runtime-error-package-documentation","title":"GlassOps Runtime Error Package Documentation","text":"<p>This package defines a structured error handling system for the GlassOps runtime. The primary goal is to provide consistent error categorization, which supports improved telemetry and integration with automation tools like GitHub Actions.</p> <p>Key Concepts</p> <p>The package introduces a base error type, <code>GlassOpsError</code>, and several specialized error types derived from it. This hierarchy allows for specific error identification while maintaining a common structure for handling and reporting.</p> <p>GlassOpsError Type</p> <p>The <code>GlassOpsError</code> struct is the foundation for all errors within the GlassOps runtime.</p> <pre><code>type GlassOpsError struct {\n    Message string\n    Phase   string\n    Code    string\n    Cause   error\n}\n</code></pre> <ul> <li><code>Message</code>: A human-readable description of the error.</li> <li><code>Phase</code>:  Indicates the stage of the runtime where the error occurred (e.g., \"Policy\", \"Bootstrap\").</li> <li><code>Code</code>: A unique identifier for the error type, intended for programmatic handling and analysis.</li> <li><code>Cause</code>: An optional nested error that provides additional context or the original error that triggered this error. This supports error chaining.</li> </ul> <p>The <code>Error()</code> method satisfies the <code>error</code> interface, providing a formatted string representation of the error, including the code, message, and underlying cause if present. The <code>Unwrap()</code> method allows access to the underlying <code>Cause</code> error, enabling error inspection and handling.</p> <p>Specialized Error Types</p> <p>The package defines several specific error types, each representing a distinct category of failure:</p> <ul> <li><code>PolicyError</code>:  Indicates a violation of a governance policy.</li> <li><code>BootstrapError</code>: Indicates a failure during the CLI bootstrap process.</li> <li><code>IdentityError</code>: Indicates an authentication or identity-related failure.</li> <li><code>ContractError</code>: Indicates a failure during contract generation or validation.</li> <li><code>AnalyzerError</code>: Indicates a failure during code analysis.</li> <li><code>FreezeError</code>: Indicates that a deployment is blocked due to a pre-defined governance freeze window. This type includes additional fields: <code>Day</code>, <code>Start</code>, and <code>End</code> to specify the freeze window details.</li> </ul> <p>Each specialized error type is a struct embedding the <code>GlassOpsError</code> type, adding specific context relevant to that error category.  Each has a corresponding <code>New...Error</code> function to create instances. For example:</p> <pre><code>func NewPolicyError(message string, cause error) *PolicyError {\n    return &amp;PolicyError{\n        GlassOpsError: GlassOpsError{\n            Message: message,\n            Phase:   \"Policy\",\n            Code:    \"POLICY_VIOLATION\",\n            Cause:   cause,\n        },\n    }\n}\n</code></pre> <p>These <code>New...Error</code> functions simplify error creation and ensure consistent error structure.</p> <p>Utility Functions</p> <p>The package provides utility functions for working with <code>GlassOpsError</code> types:</p> <ul> <li><code>IsGlassOpsError(err error) bool</code>:  Determines if a given error is a <code>GlassOpsError</code> or one of its specialized types. This allows you to check if an error belongs to this system.</li> <li><code>GetPhase(err error) string</code>: Extracts the <code>Phase</code> value from a <code>GlassOpsError</code>. Returns \"Unknown\" if the error is not a <code>GlassOpsError</code>.</li> <li><code>GetCode(err error) string</code>: Extracts the <code>Code</code> value from a <code>GlassOpsError</code>. Returns \"UNKNOWN_ERROR\" if the error is not a <code>GlassOpsError</code>.</li> </ul> <p>Error Handling Patterns</p> <p>The package encourages the use of error chaining through the <code>Cause</code> field in the <code>GlassOpsError</code> struct.  When creating a new error, you should include the original error as the <code>Cause</code> whenever possible. This provides a complete history of the error and aids in debugging.</p> <p>Concurrency</p> <p>This package does not explicitly use goroutines or channels. It focuses on defining error types and providing utility functions for handling them.  Error handling itself is not inherently concurrent.</p> <p>Design Decisions</p> <ul> <li>Structured Errors: The use of a structured error type allows for programmatic analysis and reporting of errors.</li> <li>Error Codes:  Unique error codes facilitate automated error handling and correlation with external systems.</li> <li>Error Chaining: The <code>Cause</code> field enables tracing the origin of errors and understanding the sequence of events that led to the failure.</li> <li>Phase Categorization: The <code>Phase</code> field provides a high-level categorization of errors, aiding in identifying problematic areas of the runtime.</li> </ul>"},{"location":"packages/runtime/docs/errors-errors_test/","title":"Errors errors test","text":""},{"location":"packages/runtime/docs/errors-errors_test/#glassops-error-handling-package-documentation","title":"GlassOps Error Handling Package Documentation","text":"<p>This package defines custom error types and functions for managing errors within the GlassOps runtime environment. It provides a structured approach to error representation, allowing for consistent error handling and reporting across different components.</p> <p>Key Concepts</p> <p>The core idea is to create specific error types for different phases of operation (Policy, Bootstrap, Identity, Contract, Analyzer, and a general GlassOps error) and to provide functions to extract relevant information from these errors. This facilitates better error analysis and recovery.</p> <p>Types</p> <ul> <li>GlassOpsError: This is a base type for all GlassOps-specific errors. It includes a <code>Message</code> (string), <code>Phase</code> (string), <code>Code</code> (string), and an optional <code>Cause</code> (error). The <code>Error()</code> method formats the error message as \"[CODE] MESSAGE\". The <code>Unwrap()</code> method allows access to the underlying cause of the error, supporting error chaining.</li> <li>PolicyError: Represents an error occurring during policy evaluation. It inherits from <code>GlassOpsError</code> and sets the <code>Phase</code> to \"Policy\" and the <code>Code</code> to \"POLICY_VIOLATION\".</li> <li>BootstrapError: Represents an error during the bootstrap process. It inherits from <code>GlassOpsError</code>, sets the <code>Phase</code> to \"Bootstrap\", and the <code>Code</code> to \"BOOTSTRAP_FAILED\".</li> <li>IdentityError: Represents an error related to identity and authentication. It inherits from <code>GlassOpsError</code>, sets the <code>Phase</code> to \"Identity\", and the <code>Code</code> to \"AUTHENTICATION_FAILED\".</li> <li>ContractError: Represents an error during contract generation. It inherits from <code>GlassOpsError</code>, sets the <code>Phase</code> to \"Contract\", and the <code>Code</code> to \"CONTRACT_GENERATION_FAILED\".</li> <li>AnalyzerError: Represents an error during analysis. It inherits from <code>GlassOpsError</code>, sets the <code>Phase</code> to \"Analyzer\", and the <code>Code</code> to \"ANALYSIS_FAILED\".</li> <li>FreezeError: Represents an error related to a freeze policy. It inherits from <code>GlassOpsError</code>, sets the <code>Phase</code> to \"Policy\", the <code>Code</code> to \"FROZEN\", and includes a <code>Day</code> field (string) representing the day of the freeze.</li> </ul> <p>Functions</p> <ul> <li>NewPolicyError(message string, cause error) error: Constructs a new <code>PolicyError</code> with the given message and optional cause.</li> <li>NewBootstrapError(message string, cause error) error: Constructs a new <code>BootstrapError</code> with the given message and optional cause.</li> <li>NewIdentityError(message string, cause error) error: Constructs a new <code>IdentityError</code> with the given message and optional cause.</li> <li>NewContractError(message string, cause error) error: Constructs a new <code>ContractError</code> with the given message and optional cause.</li> <li>NewAnalyzerError(message string, cause error) error: Constructs a new <code>AnalyzerError</code> with the given message and optional cause.</li> <li>NewFreezeError(day string, startTime string, endTime string) error: Constructs a new <code>FreezeError</code> with the given day, start time, and end time.</li> <li>IsGlassOpsError(err error) bool: Checks if the given error is a <code>GlassOpsError</code> or one of its subtypes. It returns <code>true</code> if it is, and <code>false</code> otherwise.</li> <li>GetPhase(err error) string: Extracts the <code>Phase</code> from a <code>GlassOpsError</code>. If the error is not a <code>GlassOpsError</code>, it returns \"Unknown\".</li> <li>GetCode(err error) string: Extracts the <code>Code</code> from a <code>GlassOpsError</code>. If the error is not a <code>GlassOpsError</code>, it returns \"UNKNOWN_ERROR\".</li> </ul> <p>Error Handling Patterns</p> <p>The package promotes the use of error wrapping using the <code>errors.New()</code> function and the <code>Cause</code> field in <code>GlassOpsError</code>. This allows for preserving the original error context while adding more specific information at each layer of the application.  You can use <code>errors.Unwrap()</code> to access the root cause of an error.</p> <p>Design Decisions</p> <ul> <li>Specific Error Types: Defining specific error types for each phase allows for more targeted error handling and reporting.</li> <li>Error Codes: Using error codes provides a standardized way to identify and categorize errors.</li> <li>Error Wrapping:  Error wrapping preserves the original error context, aiding in debugging and troubleshooting.</li> <li>Phase Identification: The <code>GetPhase</code> function provides a convenient way to determine the origin of an error within the GlassOps runtime.</li> </ul>"},{"location":"packages/runtime/docs/eslint.config/","title":"ESLint Config","text":""},{"location":"packages/runtime/docs/eslint.config/#eslint-configuration-runtime-package","title":"ESLint Configuration: Runtime Package","text":"<p>Document Version: 1.0 Date: October 26, 2023 Author: Principal Architect</p> <p>1. Introduction</p> <p>This document details the ESLint configuration for the <code>runtime</code> package. ESLint is a static code analysis tool used to enforce coding standards, identify potential errors, and improve code quality. This configuration builds upon a shared root configuration and extends it with rules specific to the runtime environment.</p> <p>2. Configuration Overview</p> <p>The ESLint configuration is defined in <code>packages/runtime/eslint.config.mjs</code>. It is an array of configuration objects, allowing for layered and modular rule sets.  This configuration leverages a base configuration defined in <code>../../config/eslint.config.mjs</code> and extends it with runtime-specific overrides.</p> <p>3. Key Components</p> <ul> <li>Base Configuration: The configuration inherits all rules and settings from the root ESLint configuration located at <code>../../config/eslint.config.mjs</code>. This ensures consistency across the project.</li> <li>Global Ignores: The following directories are excluded from linting:<ul> <li><code>dist/</code>:  Generated distribution files.</li> <li><code>node_modules/</code>:  Installed dependencies.</li> <li><code>coverage/</code>:  Test coverage reports.</li> </ul> </li> <li>TypeScript-Specific Rules:  Rules are applied specifically to TypeScript (<code>.ts</code>) files. These rules modify or disable rules from the base configuration to better suit the runtime package\u2019s needs.<ul> <li><code>@lwc/lwc/no-async-operation</code>: Disabled. Allows asynchronous operations where the base configuration might disallow them.</li> <li><code>no-await-in-loop</code>: Disabled. Permits the use of <code>await</code> within loops.</li> <li><code>@typescript-eslint/no-explicit-any</code>: Set to <code>warn</code>.  Discourages the use of the <code>any</code> type, but flags it as a warning rather than an error.</li> <li><code>@typescript-eslint/no-unused-vars</code>: Set to <code>warn</code> with <code>argsIgnorePattern: \"^_\"</code>.  Flags unused variables as warnings, but ignores variables starting with an underscore (<code>_</code>).</li> </ul> </li> <li>TypeScript Language Options: Configures the TypeScript parser for accurate and reliable analysis.<ul> <li><code>projectService</code>: Enables type checking using <code>tsconfig.json</code> files. <code>allowDefaultProject: ['*.ts', '*.js']</code> allows the parser to find project configurations for both TypeScript and JavaScript files.</li> <li><code>tsconfigRootDir</code>: Specifies the root directory for resolving <code>tsconfig.json</code> files, set to the directory of the current configuration file using <code>import.meta.dirname</code>.</li> </ul> </li> </ul> <p>4. Purpose and Benefits</p> <p>This configuration aims to:</p> <ul> <li>Maintain consistent code style across the project.</li> <li>Identify potential runtime errors early in the development process.</li> <li>Improve code readability and maintainability.</li> <li>Provide flexibility for TypeScript-specific requirements within the runtime package.</li> </ul>"},{"location":"packages/runtime/docs/gha-gha/","title":"Gha gha","text":""},{"location":"packages/runtime/docs/gha-gha/#github-actions-integration-package-documentation","title":"GitHub Actions Integration Package Documentation","text":"<p>This package provides a set of utilities for interacting with the GitHub Actions environment. It aims to replicate functionality found in the <code>@actions/core</code> package commonly used in TypeScript-based GitHub Actions, offering equivalent capabilities within a Go environment.</p> <p>Package Responsibilities:</p> <p>The primary responsibility of this package is to simplify the process of reading inputs, setting outputs, and managing logging within a GitHub Actions workflow. It handles the specific environment variable conventions and output formatting required by GitHub Actions.</p> <p>Key Types and Interfaces:</p> <p>This package does not define any explicit types or interfaces. It operates directly on strings and utilizes environment variables.</p> <p>Important Functions and Their Behavior:</p> <ul> <li> <p><code>GetInput(name string) string</code>: This function retrieves the value of an action input. It searches for the input value in the following order:</p> <ol> <li>Environment variable named <code>INPUT_&lt;NAME&gt;</code> (where <code>&lt;NAME&gt;</code> is the input name in uppercase).</li> <li>Environment variable named <code>GLASSOPS_&lt;NAME&gt;</code> (where <code>&lt;NAME&gt;</code> is the input name in uppercase).</li> <li>If neither environment variable is found, it returns an empty string.</li> </ol> </li> <li> <p><code>GetInputWithDefault(name, defaultValue string) string</code>: This function attempts to retrieve an action input using <code>GetInput()</code>. If <code>GetInput()</code> returns an empty string, it returns the provided <code>defaultValue</code>.</p> </li> <li> <p><code>SetOutput(name, value string)</code>: This function sets an action output parameter. It first checks for the presence of the <code>GITHUB_OUTPUT</code> environment variable.</p> <ol> <li>If <code>GITHUB_OUTPUT</code> is set, it appends a line to the file specified by the variable in the format <code>name=value</code>. This is the preferred method for setting outputs in modern GitHub Actions.</li> <li>If <code>GITHUB_OUTPUT</code> is not set, it falls back to the older <code>::set-output</code> command format, printing to standard output.</li> </ol> </li> <li> <p><code>SetSecret(secret string)</code>: This function masks a sensitive value in the GitHub Actions logs. It uses the <code>::add-mask::</code> command to hide the value.</p> </li> <li> <p><code>SetFailed(message string)</code>: This function marks the GitHub Action as failed and sets an error message. It uses the <code>::error::</code> command to report the error.</p> </li> <li> <p><code>Info(message string)</code>: This function logs an informational message to the GitHub Actions log. It prints the message to standard output.</p> </li> <li> <p><code>Warning(message string)</code>: This function logs a warning message to the GitHub Actions log. It uses the <code>::warning::</code> command to format the warning.</p> </li> <li> <p><code>Error(message string)</code>: This function logs an error message to the GitHub Actions log. It uses the <code>::error::</code> command to format the error.</p> </li> <li> <p><code>StartGroup(name string)</code>: This function starts a new log group in the GitHub Actions log. It uses the <code>::group::</code> command to begin the group.</p> </li> <li> <p><code>EndGroup()</code>: This function ends the current log group in the GitHub Actions log. It prints <code>::endgroup::</code> to standard output.</p> </li> </ul> <p>Error Handling:</p> <p>The package handles errors primarily through the <code>SetFailed</code> function.  Functions like <code>SetOutput</code> include basic error checking (specifically when opening the output file) but do not return errors directly. Instead, they rely on the <code>SetFailed</code> function to signal a failure to the GitHub Actions workflow.</p> <p>Concurrency:</p> <p>This package is not inherently concurrent. The functions are designed to be called sequentially within a single workflow step. There are no goroutines or channels used within the provided code.</p> <p>Design Decisions:</p> <ul> <li>Environment Variable Preference: The <code>GetInput</code> function prioritizes the <code>INPUT_&lt;NAME&gt;</code> environment variable convention, aligning with standard GitHub Actions practices. The <code>GLASSOPS_&lt;NAME&gt;</code> prefix provides a fallback for custom integrations.</li> <li>Output Method Flexibility: The <code>SetOutput</code> function supports both the modern file-based output mechanism (using <code>GITHUB_OUTPUT</code>) and the older <code>::set-output</code> command, ensuring compatibility with a wider range of GitHub Actions environments.</li> <li>Logging Consistency: The package provides a consistent set of logging functions (<code>Info</code>, <code>Warning</code>, <code>Error</code>) that leverage the GitHub Actions command format for structured logging.</li> </ul>"},{"location":"packages/runtime/docs/gha-gha_test/","title":"Gha gha test","text":""},{"location":"packages/runtime/docs/gha-gha_test/#package-gha-documentation","title":"Package gha Documentation","text":"<p>This package provides functions for interacting with the GitHub Actions environment. It allows reading input parameters, setting output variables, and emitting diagnostic messages. The package is designed to facilitate the creation of tools and actions that run within the GitHub Actions workflow.</p> <p>Key Concepts:</p> <p>The package centers around the idea of interacting with the environment variables and standard output streams that GitHub Actions provides to its workflows. It abstracts away the specific formatting required by GitHub Actions for setting outputs, secrets, errors, and warnings.</p> <p>Types and Interfaces:</p> <p>This package does not define any custom types or interfaces. It operates directly on environment variables and standard output.</p> <p>Functions:</p> <ul> <li> <p><code>GetInput(name string) string</code>: This function retrieves the value of an input parameter from the GitHub Actions environment. It first checks for an environment variable prefixed with <code>INPUT_</code>. If not found, it falls back to checking for a variable prefixed with <code>GLASSOPS_</code>.  If neither prefix is found, an empty string is returned. <code>INPUT_</code> prefixed variables take precedence over <code>GLASSOPS_</code> prefixed variables.</p> </li> <li> <p><code>GetInputWithDefault(name string, defaultValue string) string</code>: This function retrieves the value of an input parameter, similar to <code>GetInput</code>. However, if the parameter is not found in the environment, it returns the provided <code>defaultValue</code>.</p> </li> <li> <p><code>SetOutput(name string, value string)</code>: This function sets an output variable in the GitHub Actions environment. It formats the output string according to the GitHub Actions standard (<code>::set-output name=&lt;name&gt;::&lt;value&gt;</code>) and writes it to standard output. If the <code>GITHUB_OUTPUT</code> environment variable is not set, the output is written directly to standard output.</p> </li> <li> <p><code>SetSecret(value string)</code>: This function sets a secret value in the GitHub Actions environment. It formats the output string according to the GitHub Actions standard (<code>::add-mask::&lt;value&gt;</code>) and writes it to standard output, masking the value.</p> </li> <li> <p><code>SetFailed(message string)</code>: This function marks the current step as failed in the GitHub Actions workflow. It formats the output string according to the GitHub Actions standard (<code>::error::&lt;message&gt;</code>) and writes it to standard output.</p> </li> <li> <p><code>Warning(message string)</code>: This function emits a warning message in the GitHub Actions workflow. It formats the output string according to the GitHub Actions standard (<code>::warning::&lt;message&gt;</code>) and writes it to standard output.</p> </li> <li> <p><code>StartGroup(name string)</code>: This function starts a named group in the GitHub Actions log. It formats the output string according to the GitHub Actions standard (<code>::group::&lt;name&gt;</code>) and writes it to standard output.</p> </li> <li> <p><code>EndGroup()</code>: This function ends the current group in the GitHub Actions log. It formats the output string according to the GitHub Actions standard (<code>::endgroup::</code>) and writes it to standard output.</p> </li> </ul> <p>Error Handling:</p> <p>The functions in this package do not return explicit error values. Instead, they rely on the behavior of the GitHub Actions environment.  For example, <code>GetInput</code> returns an empty string if the input is not found. <code>SetFailed</code> signals a workflow failure through standard output.</p> <p>Concurrency:</p> <p>This package does not explicitly use goroutines or channels. The functions are designed to be called sequentially within a single workflow step.</p> <p>Design Decisions:</p> <ul> <li>Environment Variable Prefixes: The package supports two environment variable prefixes (<code>INPUT_</code> and <code>GLASSOPS_</code>) for input parameters. This allows for flexibility and potential compatibility with existing tools. The <code>INPUT_</code> prefix is given priority.</li> <li>Standard Output for Outputs/Diagnostics: The package uses standard output to communicate outputs, secrets, errors, and warnings to the GitHub Actions environment. This is the standard mechanism for these types of interactions.</li> <li>No Explicit Error Returns: The decision to not return explicit errors simplifies the API and aligns with the typical usage pattern in GitHub Actions, where failures are signaled through the workflow status.</li> </ul>"},{"location":"packages/runtime/docs/glassops-main/","title":"Glassops main","text":""},{"location":"packages/runtime/docs/glassops-main/#glassops-runtime-documentation","title":"GlassOps Runtime Documentation","text":"<p>This document describes the GlassOps Runtime, a core component responsible for governing and securing deployments. It orchestrates policy evaluation, identity management, and context generation to ensure compliant and authorized operations.</p> <p>Package Purpose:</p> <p>The <code>main</code> package serves as the entry point for the GlassOps Runtime. It coordinates the execution of several internal packages to provide a secure and governed environment for deployments. The runtime is designed to be invoked as part of a larger automation pipeline, such as a GitHub Action.</p> <p>Key Types and Interfaces:</p> <ul> <li><code>permit.PolicyEvaluation</code>: Represents the outcome of policy checks. It includes a boolean <code>Allowed</code> flag indicating whether the operation is permitted, a list of <code>Evaluated</code> policies, and any <code>Violations</code> encountered.</li> <li><code>permit.Identity</code>:  Encapsulates information about the actor attempting to perform an action. It includes the <code>Subject</code> (user identifier), <code>Provider</code> (authentication source), <code>ProviderID</code>, and a <code>Verified</code> status.</li> <li><code>services.AuthRequest</code>: A structure containing the necessary information for authenticating with Salesforce, including <code>ClientID</code>, <code>JWTKey</code>, <code>Username</code>, and <code>InstanceURL</code>.</li> </ul> <p>Important Functions:</p> <ul> <li><code>main()</code>: The primary entry point of the runtime. It initializes the environment, calls the <code>run()</code> function, and handles any errors that occur during execution.</li> <li><code>run(ctx context.Context) error</code>:  This function contains the core logic of the runtime. It performs the following steps:<ol> <li>Environment Validation: Validates the runtime environment using the <code>validator</code> package.</li> <li>Input Validation: Validates and sanitizes input parameters received from the environment. It can load a JWT key from a file specified by the <code>jwt_key_file</code> input.</li> <li>Resource Limits: Enforces a maximum execution time using a timeout mechanism implemented with the <code>enforceTimeout</code> function.</li> <li>Policy Evaluation: Loads and evaluates governance policies using the <code>policy</code> package.  It checks for active freeze windows if policy enforcement is enabled.</li> <li>Identity Resolution: Authenticates with Salesforce using the <code>services</code> package, obtaining the organization ID. Authentication can be skipped for testing purposes.</li> <li>Permit Generation: Generates a GlassOps Permit containing the runtime ID, actor identity, policy evaluation results, and instance URL using the <code>permit</code> package.</li> <li>Contract Generation: Generates a deployment contract using the <code>contract</code> package.</li> <li>Output: Sets output variables for use in subsequent workflow steps, including the runtime ID, organization ID, contract path, and a flag indicating readiness.</li> </ol> </li> <li><code>generateUUID()</code>: Generates a Universally Unique Identifier (UUID) used as a runtime identifier.</li> <li><code>enforceTimeout(limit time.Duration)</code>:  Implements a timeout mechanism. It sleeps for the specified duration and then terminates the runtime if the limit is exceeded.</li> </ul> <p>Error Handling:</p> <p>The runtime employs a consistent error handling pattern. Functions return an <code>error</code> value, which is checked by the caller. If an error occurs, the function immediately returns, and the error is propagated up the call stack.  The <code>fmt.Errorf</code> function is used to wrap errors, providing additional context.  Critical errors result in the runtime exiting with a non-zero status code, and failures are reported to the GitHub Actions workflow using <code>gha.SetFailed</code>.</p> <p>Concurrency:</p> <p>The runtime uses a single goroutine for its main execution flow. However, the <code>enforceTimeout</code> function is launched as a separate goroutine to monitor execution time without blocking the main process.</p> <p>Notable Design Decisions:</p> <ul> <li>Modular Design: The runtime is composed of several internal packages, each responsible for a specific aspect of the governance process. This promotes code reusability and maintainability.</li> <li>Configuration-Driven: The runtime's behavior is largely driven by configuration loaded from policy files. This allows for flexible and customizable governance rules.</li> <li>GitHub Actions Integration: The runtime is designed to be easily integrated with GitHub Actions, using the <code>gha</code> package to interact with the workflow environment.</li> <li>Telemetry: The runtime includes optional OpenTelemetry integration for monitoring and tracing.</li> <li>Skip Authentication: The ability to skip authentication is provided for testing and development purposes, but should not be used in production environments.</li> </ul>"},{"location":"packages/runtime/docs/integration-analyzer.integration.test/","title":"Integration Analyzer","text":""},{"location":"packages/runtime/docs/integration-analyzer.integration.test/#analyzer-integration-test-documentation","title":"Analyzer Integration Test Documentation","text":"<p>Purpose: This document details the integration tests for the Code Analyzer service. These tests verify the correct operation of the analyzer, ensuring it interacts properly with the <code>sf code-analyzer</code> command-line tool and processes its output. This work satisfies requirement BR-003.</p> <p>Overview:</p> <p>The Analyzer service is designed to integrate with the <code>sf code-analyzer</code> tool to identify code quality issues. It executes the analyzer against specified targets and rulesets, parses the results, and provides a structured representation of any violations found.  I prioritize the use of <code>sf code-analyzer</code> over <code>sf scanner</code>.</p> <p>Functionality Tested:</p> <p>The integration tests cover the following key areas:</p> <ul> <li>Command Construction: Verification that the correct <code>sf code-analyzer</code> command is constructed with the appropriate arguments (target directories and rulesets).</li> <li>Output Parsing:  Confirmation that the service correctly parses the JSON output from <code>sf code-analyzer</code>, extracting violation details such as rule name, message, severity, and location.</li> <li>Error Handling:  Ensuring the service handles failures during command execution gracefully, propagating errors to the calling code.</li> </ul> <p>Test Details:</p> <ol> <li> <p>Valid Command Construction:</p> <ul> <li>Input: A target directory (\"src\") and a ruleset (\"Complexity\").</li> <li>Behavior: The test mocks the execution of <code>sf code-analyzer</code> to simulate a successful run with no violations. It then asserts that <code>sf code-analyzer</code> was called with the expected command and arguments.</li> <li>Outcome: Confirms the service builds the correct command line invocation.</li> </ul> </li> <li> <p>Violation Parsing:</p> <ul> <li>Input: A target directory (\"src\") and mocked JSON output representing a code violation (specifically, an \"any\" type usage in <code>src/bad.ts</code>).</li> <li>Behavior: The test mocks <code>sf code-analyzer</code> to return the sample JSON output. It then calls the analyzer and asserts that the resulting violation list contains the expected violation details (rule name \"no-any\").</li> <li>Outcome: Validates the service can correctly interpret the analyzer\u2019s output and extract relevant information.</li> </ul> </li> <li> <p>Command Failure Handling:</p> <ul> <li>Input: A target directory (\"src\").</li> <li>Behavior: The test mocks <code>sf code-analyzer</code> to throw an error (simulating a command not found). It then asserts that calling the analyzer results in the same error being thrown.</li> <li>Outcome:  Verifies the service handles errors during command execution and provides informative error messages.</li> </ul> </li> </ol> <p>Dependencies:</p> <ul> <li><code>@actions/exec</code>:  Used for executing the <code>sf code-analyzer</code> command. This is mocked during testing.</li> </ul> <p>Configuration:</p> <p>You can configure the target directories and rulesets passed to the analyzer through its <code>scan</code> method. For example: <code>await analyzer.scan([\"src\", \"test\"], \"Security\")</code>.</p> <p>Output:</p> <p>The <code>scan</code> method returns a promise that resolves to an object containing a <code>violations</code> array. Each element in the array represents a code violation and includes properties such as <code>rule</code>, <code>message</code>, <code>severity</code>, and <code>line</code>.  If an error occurs during execution, the promise will reject with an error object.</p>"},{"location":"packages/runtime/docs/integration-cli-platform.integration.test/","title":"Integration CLI Platform","text":""},{"location":"packages/runtime/docs/integration-cli-platform.integration.test/#cli-platform-integration-test-documentation","title":"CLI Platform Integration Test Documentation","text":"<p>This document details integration tests designed to verify the correct operation of the CLI across different operating systems \u2013 Windows, macOS, and Linux. These tests ensure platform-specific behaviors, particularly around command execution and plugin installation, function as expected.</p> <p>Purpose</p> <p>The primary goal of these tests is to confirm that the CLI operates consistently and reliably regardless of the underlying platform. This includes verifying the correct shell commands are used for each operating system and that plugin installation processes handle platform-specific requirements.</p> <p>Scope</p> <p>The tests cover the following key areas:</p> <ul> <li>Plugin Installation: Validates that plugins are installed correctly on each platform, utilizing the appropriate command prefixes (e.g., <code>echo y|</code> for Windows, <code>echo y |</code> for Unix-based systems). Error handling during plugin installation is also tested.</li> <li>CLI Installation: Confirms that the CLI is installed when not already present and skipped if it exists.  Tests also verify error handling during the CLI installation process.</li> <li>Cross-Platform Command Execution: Ensures commands are executed using the correct shell (cmd on Windows, sh on Unix-like systems) for consistent behavior.</li> </ul> <p>Key Components</p> <ul> <li>RuntimeEnvironment: This class encapsulates the logic for interacting with the CLI, including installation and plugin management.</li> <li>ProtocolConfig:  This configuration object defines runtime settings, including plugin whitelists and CLI/Node versions.</li> <li>Mocking: The tests extensively use mocking of external GitHub Actions modules (<code>@actions/exec</code>, <code>@actions/io</code>) to isolate the CLI functionality and control the execution environment.</li> </ul> <p>Test Methodology</p> <p>The tests operate by:</p> <ol> <li>Temporarily modifying the <code>process.platform</code> property to simulate different operating systems.</li> <li>Creating an instance of the <code>RuntimeEnvironment</code> class.</li> <li>Calling methods on the <code>RuntimeEnvironment</code> instance to perform CLI operations (e.g., <code>installPlugins</code>, <code>install</code>).</li> <li>Asserting that the expected shell commands were called with the correct arguments using mocked functions.</li> <li>Restoring the original <code>process.platform</code> value after each test to avoid impacting other tests.</li> </ol> <p>Configuration</p> <p>You can configure the tests by modifying the <code>ProtocolConfig</code> object. Specifically, the <code>governance.plugin_whitelist</code> property controls which plugins are allowed to be installed.  The <code>runtime.cli_version</code> and <code>runtime.node_version</code> properties define the desired CLI and Node.js versions.</p> <p>Error Handling</p> <p>The tests include scenarios to verify that errors during plugin installation and CLI installation are handled gracefully and propagate appropriately.  Expectations are set to confirm that specific error messages are thrown when failures occur.</p>"},{"location":"packages/runtime/docs/integration-cli.integration.test/","title":"Integration CLI","text":""},{"location":"packages/runtime/docs/integration-cli.integration.test/#runtime-environment-cli-integration-tests-documentation","title":"Runtime Environment CLI Integration Tests Documentation","text":"<p>This document details the integration tests for the Runtime Environment Command Line Interface (CLI). These tests ensure the Runtime Environment functions correctly with module loading, specifically dynamic imports, while simulating external input/output operations.</p> <p>Purpose</p> <p>The primary goal of these tests is to validate the installation and management of the Salesforce CLI and its plugins within the runtime environment. This includes verifying correct installation procedures, adherence to plugin whitelists, and graceful handling of potential errors.</p> <p>Key Components</p> <ul> <li>RuntimeEnvironment: The core class responsible for managing the CLI lifecycle, including installation and plugin management.</li> <li>ProtocolConfig:  A configuration object that defines runtime settings, including CLI version, Node.js version, and plugin governance policies (e.g., whitelists).</li> <li>Mocking: External dependencies (GitHub Actions modules for execution, I/O, and logging) are mocked to isolate the Runtime Environment and ensure predictable test results.</li> </ul> <p>Functionality Tested</p> <p>1. CLI Installation</p> <ul> <li>Existing CLI Detection: The system correctly identifies when the Salesforce CLI is already installed and skips the installation process.</li> <li>CLI Installation: When the CLI is not present, the system installs it using npm.</li> <li>Installation Failure Handling: The system gracefully handles errors during the CLI installation process.</li> </ul> <p>2. Plugin Installation with Whitelist</p> <ul> <li>No Whitelist Configuration: When no plugin whitelist is defined, plugins are installed without validation, accompanied by a warning message.</li> <li>Whitelisted Plugin Installation: Plugins listed in the whitelist are installed with specified version constraints (e.g., <code>^6.0.0</code>).</li> <li>Scoped Package Installation: Installation of scoped packages (e.g., <code>@salesforce/plugin-deploy-retrieve</code>) with version constraints is validated.</li> <li>Non-Whitelisted Plugin Rejection:  Plugins not present in the whitelist are rejected, preventing their installation.</li> <li>Multiple Plugin Installation: The system can install multiple whitelisted plugins simultaneously.</li> <li>No Plugin Specified: The system handles the case where no plugins are specified for installation.</li> <li>Plugin Verification: After installation, the system verifies the plugin is installed correctly by querying the CLI.</li> <li>Plugin Verification Failure: The system handles failures during plugin verification.</li> <li>Plugin Installation Error Handling: The system gracefully handles errors during plugin installation.</li> </ul> <p>3. End-to-End Plugin Flow</p> <ul> <li>Complete Workflow Validation:  Tests the entire plugin installation workflow, from validation to installation and verification, ensuring all steps function correctly.</li> </ul> <p>Configuration</p> <p>The <code>ProtocolConfig</code> object is central to controlling the runtime environment. Key settings include:</p> <ul> <li><code>governance.enabled</code>: Enables or disables plugin governance features.</li> <li><code>governance.plugin_whitelist</code>: A list of allowed plugins, potentially including version constraints.</li> <li><code>runtime.cli_version</code>: Specifies the desired Salesforce CLI version.</li> <li><code>runtime.node_version</code>: Specifies the required Node.js version.</li> </ul> <p>Platform Considerations</p> <p>The tests account for differences between operating systems (Windows and others) when constructing shell commands. Specifically, the tests adjust the shell executable and command flags accordingly.</p>"},{"location":"packages/runtime/docs/integration-contract.integration.test/","title":"Integration Contract","text":""},{"location":"packages/runtime/docs/integration-contract.integration.test/#deployment-contract-integration-test-documentation","title":"Deployment Contract Integration Test Documentation","text":"<p>This document details the integration tests for the Deployment Contract schema, verifying its functionality with diverse inputs and boundary conditions. These tests ensure the contract accurately represents deployment metadata and enforces data integrity.</p> <p>Overview</p> <p>The core component under test is the <code>DeploymentContractSchema</code>, which defines the structure and validation rules for deployment contracts. A deployment contract encapsulates information about a deployment, including its status, quality metrics, and audit details.  I validate that the schema correctly parses valid contracts, applies default values where appropriate, and rejects invalid data.</p> <p>Key Areas of Testing</p> <p>The integration tests are organized into two primary sections:</p> <ol> <li> <p>Schema Validation: This suite confirms the schema\u2019s ability to validate contract data against defined rules. Tests cover:</p> <ul> <li>Complete Contract Validation: Verifies successful parsing of a fully populated contract.</li> <li>Default Schema Version: Confirms the schema automatically assigns a default version when one is not provided.</li> <li>Engine Type Support: Validates compatibility with supported engine types (\"native\", \"hardis\", \"custom\").</li> <li>Status Value Support:  Ensures the schema accepts valid status values (\"Succeeded\", \"Failed\", \"Blocked\").</li> <li>Invalid Input Rejection:  Tests the schema\u2019s ability to reject contracts with invalid engine types, out-of-range coverage values (outside 0-100), negative test counts, and improperly formatted timestamps.</li> </ul> </li> <li> <p>Coverage Calculation Integration: This section focuses on the accurate determination of coverage status (met/not met) based on actual and required coverage percentages.  It tests various scenarios to ensure the <code>met</code> field is correctly calculated.</p> </li> </ol> <p>Data Structures</p> <p>The tests primarily interact with the <code>DeploymentContract</code> data structure, which is defined and validated by the <code>DeploymentContractSchema</code>. This structure includes the following key fields:</p> <ul> <li><code>schemaVersion</code>:  The version of the contract schema.</li> <li><code>meta</code>: Metadata about the deployment, including the adapter, engine, timestamp, and trigger.</li> <li><code>status</code>: The deployment status (e.g., \"Succeeded\", \"Failed\").</li> <li><code>quality</code>: Quality metrics, including code coverage and test results.</li> <li><code>audit</code>: Audit information, such as the triggering user, organization ID, repository, and commit hash.</li> </ul> <p>Usage &amp; Configuration</p> <p>You do not need to configure anything to run these tests. They are designed to be executed as part of the standard testing process.  The tests are self-contained and do not rely on external dependencies beyond the core libraries.</p> <p>Expected Behavior</p> <p>Successful execution of these tests confirms the reliability and correctness of the <code>DeploymentContractSchema</code>.  Any test failures indicate a potential issue with the schema definition or validation logic, requiring investigation and correction.</p>"},{"location":"packages/runtime/docs/integration-contract_test/","title":"Integration contract test","text":""},{"location":"packages/runtime/docs/integration-contract_test/#integration-test-documentation-contract-validation","title":"Integration Test Documentation: Contract Validation","text":"<p>This document details the integration tests for the contract package, focusing on validation and serialization functionality. The purpose of these tests is to ensure the contract object behaves as expected and enforces defined constraints.</p> <p>Package Responsibility:</p> <p>The <code>integration</code> package contains tests that verify the interaction between the components and the <code>contract</code> package. These tests are designed to confirm that the contract object can be created, validated, and serialized correctly.</p> <p>Key Types and Structures:</p> <p>The primary type involved is the <code>contract.Contract</code> structure (defined in the <code>github.com/glassops-platform/glassops/packages/runtime/internal/contract</code> package). This structure represents the core agreement or specification for a runtime operation.  Key fields within the <code>Contract</code> structure include:</p> <ul> <li><code>SchemaVersion</code>: A string indicating the version of the contract schema.</li> <li><code>Status</code>: A string representing the current status of the contract (e.g., \"Succeeded\", \"Failed\").</li> <li><code>Meta</code>: A nested structure containing metadata about the contract, including the execution <code>Engine</code> and a <code>Timestamp</code>.</li> <li><code>Quality</code>: A nested structure containing quality metrics, such as code <code>Coverage</code> and test <code>Results</code>.</li> <li><code>Audit</code>: A nested structure containing audit information, such as the user who <code>TriggeredBy</code> the contract, the <code>OrgID</code>, <code>Repository</code>, and <code>Commit</code>.</li> </ul> <p>Important Functions and Behavior:</p> <p>The tests focus on the following behaviors:</p> <ul> <li>Contract Creation with Defaults:  The <code>contract.New()</code> function is tested to ensure it creates a contract object with sensible default values for key fields like <code>SchemaVersion</code>, <code>Status</code>, and <code>Meta.Engine</code>.</li> <li>Status Validation: The <code>Validate()</code> method of the <code>Contract</code> structure is tested to verify that only valid status values are accepted.  Valid statuses include \"Succeeded\", \"Failed\", and \"Blocked\".  Empty strings and invalid statuses trigger an error.</li> <li>Engine Type Validation: The <code>Validate()</code> method is also tested to ensure that only supported engine types are accepted. Valid engines include \"native\", \"hardis\", and \"custom\". Empty strings and invalid engine types result in an error.</li> <li>Coverage Bounds Validation: The <code>Validate()</code> method checks that <code>Coverage.Actual</code> and <code>Coverage.Required</code> values are within acceptable bounds (non-negative and not exceeding 100). Values outside these bounds cause validation to fail.</li> <li>JSON Serialization: The <code>ToJSON()</code> method is tested to confirm that a contract object can be serialized into a valid JSON representation. The test verifies that the resulting JSON data is not empty.</li> <li>Coverage Met Calculation: The tests verify that the <code>Coverage.Met</code> field is correctly calculated based on whether <code>Coverage.Actual</code> is greater than or equal to <code>Coverage.Required</code>.</li> <li>Test Data Integration: Tests leverage predefined test data structures (<code>TestData</code>) to populate contract fields and validate the overall contract state.</li> </ul> <p>Error Handling:</p> <p>The <code>Validate()</code> method is central to error handling. It returns an error when:</p> <ul> <li>The <code>Status</code> field contains an invalid value.</li> <li>The <code>Meta.Engine</code> field contains an invalid value.</li> <li><code>Coverage.Actual</code> or <code>Coverage.Required</code> are outside the valid range (0-100).</li> </ul> <p>The tests assert that errors are returned when expected and that no errors are returned when validation should succeed.</p> <p>Concurrency:</p> <p>These integration tests do not explicitly test concurrent behavior. They focus on the functional correctness of the contract object and its validation logic in a single-threaded environment.</p> <p>Design Decisions:</p> <ul> <li>Explicit Validation: The <code>Validate()</code> method provides a clear and centralized point for enforcing contract constraints.</li> <li>Default Values: Providing default values through <code>contract.New()</code> simplifies contract creation and ensures a consistent starting point.</li> <li>Test-Driven Approach: The tests are structured to cover various scenarios, including valid and invalid inputs, to ensure robust validation logic.</li> </ul>"},{"location":"packages/runtime/docs/integration-helpers/","title":"Integration helpers","text":""},{"location":"packages/runtime/docs/integration-helpers/#integration-test-helpers-documentation","title":"Integration Test Helpers Documentation","text":"<p>This package provides a collection of helper functions and data structures to simplify the creation and management of test environments for integration tests. It focuses on providing a consistent and isolated environment for reliable test execution.</p>"},{"location":"packages/runtime/docs/integration-helpers/#package-responsibilities","title":"Package Responsibilities","text":"<p>The primary responsibilities of this package are:</p> <ul> <li>Creating temporary workspaces for tests.</li> <li>Managing test configuration files.</li> <li>Setting and restoring environment variables required by tests.</li> <li>Providing pre-defined test data for common scenarios.</li> <li>Cleaning up test artifacts after execution.</li> </ul>"},{"location":"packages/runtime/docs/integration-helpers/#key-types-and-interfaces","title":"Key Types and Interfaces","text":"<ul> <li> <p>TestEnvironment: This struct encapsulates the state of a test environment. It holds the path to the workspace directory, the path to the configuration file, and a map of original environment variables that were overridden during test setup.     <pre><code>type TestEnvironment struct {\n    WorkspacePath string\n    ConfigPath    string\n    OriginalEnv   map[string]string\n}\n</code></pre></p> </li> <li> <p>FreezeWindowData:  A struct containing pre-defined freeze window configurations for testing purposes.     <pre><code>type FreezeWindowData struct {\n    Weekend  []map[string]string\n    Weekday  []map[string]string\n    Multiple []map[string]string\n}\n</code></pre></p> </li> <li> <p>PluginConfigData: A struct containing pre-defined plugin configuration lists for testing.     <pre><code>type PluginConfigData struct {\n    Whitelist   []string\n    NoWhitelist []string\n    Versioned   []string\n    Scoped      []string\n}\n</code></pre></p> </li> <li> <p>TestResultsData: A struct containing pre-defined test result sets for testing.     <pre><code>type TestResultsData struct {\n    Valid     TestResults\n    Empty     TestResults\n    AllPassed TestResults\n    AllFailed TestResults\n}\n</code></pre></p> </li> <li> <p>TestResults: A struct representing the outcome of a test run, including total, passed, and failed counts.     <pre><code>type TestResults struct {\n    Total  int\n    Passed int\n    Failed int\n}\n</code></pre></p> </li> <li> <p>CoverageTestData: A struct containing pre-defined code coverage data for testing.     <pre><code>type CoverageTestData struct {\n    Good       Coverage\n    Borderline Coverage\n    Failing    Coverage\n    Perfect    Coverage\n}\n</code></pre></p> </li> <li> <p>Coverage: A struct representing code coverage information, with actual and required coverage percentages.     <pre><code>type Coverage struct {\n    Actual   float64\n    Required float64\n}\n</code></pre></p> </li> </ul>"},{"location":"packages/runtime/docs/integration-helpers/#important-functions","title":"Important Functions","text":"<ul> <li>SetupTestWorkspace(config map[string]interface{}) (*TestEnvironment, error): This function creates a temporary workspace directory, creates a <code>config</code> subdirectory within it, and writes a JSON configuration file (<code>devops-config.json</code>) to the <code>config</code> directory.  If a <code>config</code> is not provided, it uses a <code>DefaultConfig</code>. It returns a pointer to a <code>TestEnvironment</code> struct containing information about the created workspace and configuration file, or an error if creation fails.</li> <li>SetEnvironment(vars map[string]string): This method, associated with the <code>TestEnvironment</code> struct, sets environment variables required for tests. It merges provided overrides (<code>vars</code>) with a set of default environment variables, saving the original values in the <code>TestEnvironment</code>\u2019s <code>OriginalEnv</code> map before setting them.</li> <li>Cleanup(): This method, associated with the <code>TestEnvironment</code> struct, restores the original environment variables saved during setup and removes the temporary workspace directory. If an environment variable was not previously set, it is unset.</li> <li>WriteConfig(config map[string]interface{}) error: This method, associated with the <code>TestEnvironment</code> struct, updates the configuration file within the test workspace with the provided <code>config</code> data.</li> <li>TestData: This is a struct containing various pre-defined data sets for testing different scenarios. It includes data for freeze windows, plugin configurations, test results, and code coverage.</li> </ul>"},{"location":"packages/runtime/docs/integration-helpers/#error-handling","title":"Error Handling","text":"<p>The functions in this package generally return an <code>error</code> value to indicate failure.  Common error scenarios include:</p> <ul> <li>Failure to create temporary directories.</li> <li>Failure to write configuration files.</li> <li>Errors during JSON marshaling.</li> </ul> <p>In case of an error, the <code>SetupTestWorkspace</code> function attempts to clean up any created workspace before returning the error.</p>"},{"location":"packages/runtime/docs/integration-helpers/#concurrency","title":"Concurrency","text":"<p>This package does not currently employ goroutines or channels. It operates synchronously.</p>"},{"location":"packages/runtime/docs/integration-helpers/#design-decisions","title":"Design Decisions","text":"<ul> <li>Temporary Workspace: Using a temporary workspace ensures that tests do not interfere with each other or with the host system.</li> <li>Configuration Management:  Providing a mechanism to manage test configuration allows for flexible and repeatable tests.</li> <li>Environment Variable Management:  Setting and restoring environment variables ensures that tests have the correct context and do not pollute the host environment.</li> <li>Pre-defined Test Data:  Including pre-defined test data simplifies test creation and reduces duplication.</li> <li>Default Configuration: The <code>DefaultConfig</code> provides a sensible baseline for tests, reducing the need to specify configuration for every test case.</li> </ul>"},{"location":"packages/runtime/docs/integration-identity.integration.test/","title":"Integration Identity","text":""},{"location":"packages/runtime/docs/integration-identity.integration.test/#identity-resolver-integration-test-documentation","title":"Identity Resolver Integration Test Documentation","text":"<p>This document details the integration tests for the Identity Resolver component. These tests ensure proper functionality when interacting with Salesforce authentication processes via the Salesforce CLI.</p> <p>Purpose</p> <p>The Identity Resolver facilitates authentication with Salesforce using JWT (JSON Web Token) authentication flows. These tests verify the resolver\u2019s ability to successfully authenticate, handle failures, and manage temporary key files.</p> <p>Scope</p> <p>The tests cover the following scenarios:</p> <ul> <li>Successful authentication with valid credentials, including optional instance URL specification.</li> <li>Handling authentication failures due to CLI command errors or invalid JSON responses.</li> <li>Proper cleanup of temporary JWT key files, both on success and failure.</li> <li>Authentication against different Salesforce environments (Production, Sandbox, Custom Domains).</li> <li>Silent execution of CLI commands and stdout capture.</li> </ul> <p>Functionality</p> <p>The <code>IdentityResolver</code> class interacts with the Salesforce CLI (<code>sf</code>) to perform authentication.  It accepts the following inputs:</p> <ul> <li><code>clientId</code>: The client ID for the Salesforce connected app.</li> <li><code>jwtKey</code>: The private key associated with the client ID.</li> <li><code>username</code>: The Salesforce username.</li> <li><code>instanceUrl</code> (Optional): The Salesforce instance URL (e.g., <code>https://login.salesforce.com</code> or a sandbox URL). If not provided, the resolver attempts authentication without it.</li> </ul> <p>Upon successful authentication, the resolver returns the Salesforce Organization ID.</p> <p>Test Methodology</p> <p>These tests employ mocking to simulate the Salesforce CLI execution environment. Specifically, the <code>@actions/exec</code> module is mocked to control the behavior of the <code>sf</code> command.  This allows for testing various success and failure scenarios without requiring a live Salesforce environment.  The tests verify:</p> <ul> <li>The correct <code>sf</code> command and arguments are invoked.</li> <li>The expected output is processed correctly.</li> <li>Error conditions are handled gracefully.</li> <li>Temporary files are created and deleted as expected.</li> </ul> <p>Error Handling</p> <p>The Identity Resolver is designed to handle the following error conditions:</p> <ul> <li>CLI Command Failure: If the <code>sf</code> command fails to execute, the resolver throws an error message: \"\u274c Authentication Failed. Check Client ID and JWT Key.\"</li> <li>Invalid JSON Response: If the <code>sf</code> command returns an invalid JSON response, the resolver throws an error message: \"\u274c Authentication Failed. Check Client ID and JWT Key.\"</li> </ul> <p>Temporary File Management</p> <p>The resolver creates temporary files to store the JWT key during the authentication process. These files are automatically cleaned up after authentication, regardless of success or failure. The files are named with a prefix of \"glassops-jwt-\".</p> <p>Configuration</p> <p>You can configure the authentication process by providing the necessary credentials (clientId, jwtKey, username, instanceUrl) to the <code>authenticate</code> method. The <code>instanceUrl</code> parameter is optional.</p> <p>Dependencies</p> <ul> <li>Salesforce CLI (<code>sf</code>) \u2013 Mocked in the test environment.</li> <li>Node.js file system (<code>fs</code>) and operating system (<code>os</code>) modules.</li> </ul>"},{"location":"packages/runtime/docs/integration-identity_test/","title":"Integration identity test","text":""},{"location":"packages/runtime/docs/integration-identity_test/#identity-integration-test-documentation","title":"Identity Integration Test Documentation","text":"<p>This document details the purpose and functionality of the <code>integration</code> package, specifically focusing on the <code>identity_test.go</code> file. This package contains integration tests for the identity service, verifying its ability to parse and validate Salesforce authentication URLs.</p> <p>Package Responsibilities:</p> <p>The <code>integration</code> package focuses on testing the interaction between different components of the system, ensuring they work correctly together. In this case, it tests the <code>services.Identity</code> service\u2019s ability to handle Salesforce authentication URLs. These tests are designed to confirm the service behaves as expected in a realistic environment.</p> <p>Key Types and Interfaces:</p> <ul> <li><code>services.Identity</code>: This type, defined in the <code>internal/services</code> package, represents the identity service. It provides methods for parsing and validating Salesforce authentication URLs. We interact with this service through its methods during testing.</li> <li><code>TestWorkspace</code>: This is a custom type (defined elsewhere, not shown in this file) used to manage a test environment. It allows us to set up and clean up resources needed for the tests, including environment variables.</li> </ul> <p>Important Functions:</p> <ul> <li><code>TestIdentityIntegration(t *testing.T)</code>: This is the main test function. It orchestrates several sub-tests to verify different aspects of the identity service. It skips execution if the test is run in short mode.</li> <li><code>SetupTestWorkspace(nil)</code>: This function (defined elsewhere) sets up a temporary test environment. It returns a <code>TestWorkspace</code> object that can be used to manage the environment.</li> <li><code>env.Cleanup()</code>: This function (method of <code>TestWorkspace</code>) cleans up the test environment after the tests have completed, releasing any resources that were allocated.</li> <li><code>env.SetEnvironment(map[string]string)</code>: This function (method of <code>TestWorkspace</code>) sets environment variables for the test process.</li> <li><code>identity.ParseAuthURL(authURL string)</code>: This method of the <code>services.Identity</code> type attempts to parse a Salesforce authentication URL and extract the organization ID. It returns the organization ID and an error if parsing fails.</li> <li><code>os.Getenv(\"INPUT_SFDX_AUTH_URL\")</code>: This standard Go function retrieves the value of the environment variable named \"INPUT_SFDX_AUTH_URL\".</li> </ul> <p>Test Cases and Behavior:</p> <p>The <code>TestIdentityIntegration</code> function includes the following test cases:</p> <ol> <li>Parses valid SFDX auth URL: This test verifies that the <code>ParseAuthURL</code> method handles a valid, albeit simplified, authentication URL. It expects an error if the URL doesn't contain an organization ID (as it's a mock URL).</li> <li>Validates auth URL format: This test uses a table of test cases to verify that the <code>ParseAuthURL</code> method correctly validates the format of authentication URLs. It tests valid URLs (including sandbox and custom domain URLs) and invalid URLs (empty string and incorrect format). It asserts that the method returns an error for invalid URLs and no error for valid URLs.</li> <li>Handles environment auth URL: This test verifies that the service can read the authentication URL from the <code>INPUT_SFDX_AUTH_URL</code> environment variable. It sets the environment variable, then reads it back to confirm that the value is correct.</li> </ol> <p>Error Handling:</p> <p>The tests extensively check for expected errors. The <code>ParseAuthURL</code> method returns an error when it encounters an invalid URL or fails to parse the URL correctly. The tests assert that errors are returned in these cases and that no errors are returned when the URL is valid.  The tests use <code>t.Fatalf</code> to immediately stop execution if a critical setup error occurs, and <code>t.Error</code> or <code>t.Errorf</code> to report failures within individual test cases.</p> <p>Concurrency:</p> <p>This code does not exhibit any explicit concurrency patterns (goroutines, channels). The tests are executed sequentially within the <code>testing</code> framework.</p> <p>Design Decisions:</p> <ul> <li>Integration Tests: The use of integration tests ensures that the identity service works correctly with other components of the system, such as the test workspace environment setup.</li> <li>Table-Driven Tests: The \"validates auth URL format\" test case uses a table-driven approach, which makes it easy to add new test cases and maintain the tests.</li> <li>Environment Variable Handling: The test for environment variable handling verifies that the service can correctly retrieve the authentication URL from the environment, which is a common way to configure the service in a production environment.</li> </ul>"},{"location":"packages/runtime/docs/integration-policy.integration.test/","title":"Integration Policy","text":""},{"location":"packages/runtime/docs/integration-policy.integration.test/#policy-integration-test-documentation","title":"Policy Integration Test Documentation","text":"<p>This document details the integration tests for the ProtocolPolicy class, verifying its functionality with file system operations and configuration loading. These tests ensure the policy enforcement mechanisms operate as expected.</p> <p>Scope:</p> <p>The tests cover the following core areas:</p> <ul> <li>Configuration Loading:  Loading and merging policy configurations from JSON files, handling missing files, and validating JSON and schema integrity.</li> <li>Plugin Whitelist Validation: Validating installed plugins against a configured whitelist, extracting version constraints, and handling cases with and without whitelists.</li> <li>Freeze Window Validation:  Determining whether a deployment should be blocked based on configured freeze windows (time-based restrictions).</li> </ul> <p>Test Environment:</p> <p>The tests create a temporary workspace directory (<code>test-workspace</code>) to isolate the tests from the existing environment.  The <code>GITHUB_WORKSPACE</code> environment variable is temporarily modified to point to this directory during each test.  This directory is cleaned up after each test suite and after all tests complete.</p> <p>Configuration:</p> <p>The tests read a configuration file named <code>devops-config.json</code> from the test workspace. This file defines governance and runtime settings, including:</p> <ul> <li><code>governance.enabled</code>:  A boolean indicating whether governance policies are active.</li> <li><code>governance.freeze_windows</code>: An array of objects defining time windows during which deployments are blocked. Each object includes a <code>day</code> (e.g., \"Saturday\"), <code>start</code> time (e.g., \"00:00\"), and <code>end</code> time (e.g., \"23:59\").</li> <li><code>governance.plugin_whitelist</code>: An array of strings representing allowed plugins and their version constraints (e.g., \"sfdx-hardis@^4.0.0\").</li> <li><code>runtime.cli_version</code>: The expected CLI version.</li> <li><code>runtime.node_version</code>: The expected Node.js version.</li> </ul> <p>Key Functionality Verified:</p> <ul> <li>Policy Loading: The <code>ProtocolPolicy</code> class correctly loads and merges configuration data from a JSON file.  It provides default values when the configuration file is missing. Errors are thrown for invalid JSON or schema.</li> <li>Plugin Validation: The <code>validatePluginWhitelist</code> method checks if a given plugin is present in the configured whitelist. The <code>getPluginVersionConstraint</code> method retrieves the version constraint for a plugin, if specified.  If no whitelist is configured, all plugins are considered valid.</li> <li>Freeze Window Enforcement: The <code>checkFreeze</code> method determines if the current time falls within a configured freeze window. If so, it throws an error, blocking the deployment.</li> </ul> <p>Error Handling:</p> <p>The tests verify that appropriate errors are thrown in the following scenarios:</p> <ul> <li>Invalid JSON format in the configuration file.</li> <li>Configuration schema validation failures.</li> <li>Attempting a deployment during a configured freeze window.</li> </ul> <p>Dependencies:</p> <ul> <li>Node.js</li> <li><code>fs</code> module (file system operations)</li> <li><code>path</code> module (path manipulation)</li> <li>Jest testing framework</li> <li><code>@actions/core</code> (mocked for testing purposes)</li> </ul>"},{"location":"packages/runtime/docs/integration-policy_test/","title":"Integration policy test","text":""},{"location":"packages/runtime/docs/integration-policy_test/#policy-integration-test-documentation","title":"Policy Integration Test Documentation","text":"<p>This document describes the integration tests for the policy engine. These tests verify the correct behavior of the policy loading, validation, and application processes.</p> <p>Package Purpose:</p> <p>The <code>integration</code> package contains tests that exercise the policy engine with realistic configurations and scenarios. These tests ensure that the policy engine interacts correctly with its configuration and provides expected results.</p> <p>Key Types and Interfaces:</p> <ul> <li><code>policy.Engine</code>: This type (defined in the <code>policy</code> package) represents the core policy engine. It is responsible for loading, validating, and applying policies.  We interact with it through its methods to test the configuration process.</li> <li><code>map[string]interface{}</code>: This is used extensively to represent the configuration data. It allows for flexible configuration structures.</li> </ul> <p>Important Functions and Behavior:</p> <ul> <li><code>TestPolicyIntegration</code>: This is the main test function, containing several sub-tests (using <code>t.Run</code>). It sets up a test workspace, loads configurations, and asserts expected behavior.</li> <li><code>SetupTestWorkspace(testConfig map[string]interface{})</code>: This function creates a temporary workspace for testing. It takes a configuration map as input and sets up the environment accordingly. It also handles cleanup after the test.</li> <li><code>engine.Load()</code>: This method of the <code>policy.Engine</code> loads the configuration from the test workspace and populates the internal policy state. It returns a configuration object and an error if loading fails.</li> <li><code>engine.ValidatePluginWhitelist(config, pluginName string) bool</code>: This method checks if a given plugin name is present in the configured whitelist. It returns <code>true</code> if the plugin is allowed, and <code>false</code> otherwise.</li> <li><code>engine.GetPluginVersionConstraint(config, pluginName string) string</code>: This method retrieves the version constraint for a given plugin from the configuration.</li> </ul> <p>Test Cases:</p> <ol> <li> <p>Loads default config when file has empty values: This test verifies that when the configuration file contains empty values, the policy engine applies default values. Specifically, it checks that <code>Governance.Enabled</code> is <code>false</code> when the <code>governance</code> section of the configuration is empty.</p> </li> <li> <p>Loads valid governance config: This test validates that the policy engine correctly loads a valid configuration with governance enabled, freeze windows defined, and a plugin whitelist. It asserts that the loaded configuration matches the expected values.</p> </li> <li> <p>Validates plugin whitelist: This test checks the functionality of the plugin whitelist validation. It verifies that whitelisted plugins are allowed, non-whitelisted plugins are blocked, and scoped plugins are handled correctly.</p> </li> <li> <p>Extracts version constraints: This test confirms that the policy engine can correctly extract version constraints for plugins from the configuration. It checks that the correct constraints are returned for both regular and scoped plugins.</p> </li> <li> <p>Rejects invalid config: This test ensures that the policy engine handles invalid configuration data gracefully. It writes an invalid configuration (specifically, an invalid day in a freeze window) and verifies that the <code>Load()</code> method returns an error.</p> </li> </ol> <p>Error Handling:</p> <p>The tests extensively check for errors returned by the <code>SetupTestWorkspace</code> and <code>engine.Load()</code> functions.  If an error is encountered, the test immediately fails using <code>t.Fatalf</code> or <code>t.Error</code>. This ensures that any issues during configuration loading or validation are detected and reported.</p> <p>Concurrency:</p> <p>This test suite does not currently employ goroutines or channels, as the tests are focused on synchronous configuration loading and validation.</p>"},{"location":"packages/runtime/docs/integration-test-helpers/","title":"Integration Test Helpers","text":""},{"location":"packages/runtime/docs/integration-test-helpers/#integration-test-helpers","title":"Integration Test Helpers","text":"<p>This document details a collection of utilities designed to support integration testing. These helpers streamline the process of setting up test environments, managing mock dependencies, and generating test data. They are intended for use by developers and testers working on the project.</p> <p>Core Functionality</p> <p>The provided tools address the following key areas:</p> <ul> <li>Test Workspace Management:  Creation and cleanup of a dedicated test directory (<code>TEST_WORKSPACE</code>) and associated configuration file (<code>devops-config.json</code>).  The default configuration includes governance enabled and specific runtime settings for CLI and Node versions.</li> <li>Environment Mocking: Generation of mock environment variables (<code>GITHUB_WORKSPACE</code>, <code>GITHUB_ACTOR</code>, etc.) to simulate a GitHub Actions environment.  These can be customized with overrides.</li> <li>Input Mocking: Creation of mock GitHub Action inputs, including Salesforce-specific credentials and configuration options.  Customization via overrides is supported.</li> <li>Key Management:  Creation of temporary JWT key files for testing authentication scenarios.</li> <li>CLI Mocking:  Simulation of Salesforce CLI execution, allowing for control over success/failure scenarios and response data.  This includes handling JSON output and simulating standard output streams.</li> <li>Cache Mocking:  Control over cache restoration behavior during tests.</li> <li>Command Availability Mocking:  Mocking the <code>which</code> command to simulate the presence or absence of specific commands (e.g., <code>sf</code>).</li> <li>Test Data:  Predefined test data sets for JWT keys (valid and invalid), test results (various scenarios), coverage data, freeze windows, plugin configurations, Salesforce environments, and repository formats.</li> <li>Assertions:  Helper functions for verifying expected outcomes, such as successful execution, error logging, warning logging, and CLI command execution.  File existence checks are also included.</li> <li>Scenario Building: A <code>TestScenarioBuilder</code> class provides a fluent interface for constructing complex test scenarios by combining environment variables, inputs, configuration, cache state, and command availability.</li> </ul> <p>Key Components</p> <ul> <li><code>TEST_WORKSPACE</code>:  A constant defining the path to the test workspace directory.</li> <li><code>DEFAULT_CONFIG</code>:  An object containing default configuration settings for the test environment.</li> <li><code>setupTestWorkspace()</code>:  Creates the test workspace directory and configuration file.</li> <li><code>cleanupTestWorkspace()</code>:  Removes the test workspace directory and its contents.</li> <li><code>createMockEnvironment()</code>:  Generates a set of mock environment variables.</li> <li><code>createMockInputs()</code>:  Generates a set of mock GitHub Action inputs.</li> <li><code>createTempJwtKey()</code>:  Creates a temporary file containing a JWT key.</li> <li><code>mockSuccessfulCliExecution()</code>:  Mocks successful Salesforce CLI execution.</li> <li><code>mockFailedCliExecution()</code>:  Mocks failed Salesforce CLI execution.</li> <li><code>mockCacheOperations()</code>:  Mocks cache restoration behavior.</li> <li><code>mockWhichOperations()</code>:  Mocks the <code>which</code> command.</li> <li><code>TestData</code>:  An object containing pre-defined test data.</li> <li><code>Assertions</code>:  An object containing assertion helper functions.</li> <li><code>TestScenarioBuilder</code>: A class for building complex test scenarios.</li> </ul> <p>Usage</p> <p>You can use these helpers within your integration tests to create controlled and repeatable test environments. For example, you can use <code>setupTestWorkspace()</code> to prepare a test directory, <code>createMockEnvironment()</code> to simulate a GitHub Actions environment, and <code>mockSuccessfulCliExecution()</code> to control the behavior of the Salesforce CLI. The <code>TestScenarioBuilder</code> allows you to combine these elements into a cohesive test setup.</p>"},{"location":"packages/runtime/docs/package/","title":"<code>@glassops/runtime</code> Package Documentation","text":"<p>This document details the structure and purpose of the <code>@glassops/runtime</code> package, a core component for Salesforce DevOps execution.</p>"},{"location":"packages/runtime/docs/package/#overview","title":"Overview","text":"<p>The <code>@glassops/runtime</code> package serves as the execution primitive for a governance-first Salesforce DevOps pipeline. It provides the core logic and tooling for orchestrating and governing deployments and other DevOps processes within a Salesforce environment.  It is designed to be used within CI/CD systems, particularly GitHub Actions.</p>"},{"location":"packages/runtime/docs/package/#schema-breakdown","title":"Schema Breakdown","text":"<p>The <code>package.json</code> file defines the metadata and dependencies for this Node.js package.  Here's a breakdown of the key fields:</p>"},{"location":"packages/runtime/docs/package/#core-metadata","title":"Core Metadata","text":"<ul> <li><code>name</code>: <code>@glassops/runtime</code> -  The unique identifier for the package within the npm registry and the project.</li> <li><code>version</code>: <code>1.0.0</code> - The current version of the package, following semantic versioning.</li> <li><code>description</code>: <code>The governance-first execution primitive for Salesforce DevOps.</code> - A brief description of the package's purpose.</li> <li><code>main</code>: <code>dist/index.js</code> - Specifies the entry point for the package when it's required in a Node.js environment.  This points to the compiled JavaScript file.</li> <li><code>repository</code>:  Defines the location of the source code repository.<ul> <li><code>type</code>: <code>git</code> - Indicates the repository type is Git.</li> <li><code>url</code>: <code>git+https://github.com/glassops-platform/glassops-runtime.git</code> - The URL of the Git repository.</li> </ul> </li> <li><code>keywords</code>: <code>[\"salesforce\", \"devops\", \"governance\", \"github-actions\"]</code> -  Keywords used for searching and categorizing the package.</li> <li><code>author</code>: <code>Ryan Bumstead</code> - The author of the package.</li> <li><code>license</code>: <code>Apache-2.0</code> - The license under which the package is distributed.</li> </ul>"},{"location":"packages/runtime/docs/package/#development-build-configuration","title":"Development &amp; Build Configuration","text":"<ul> <li><code>engines</code>:  Specifies the Node.js version requirement.<ul> <li><code>node</code>: <code>&gt;=20</code> -  Requires Node.js version 20 or higher.</li> </ul> </li> <li><code>scripts</code>: Defines a set of scripts for automating common development tasks.<ul> <li><code>build</code>: <code>ncc build src/index.ts -o dist --source-map --license LICENSE</code> - Compiles the TypeScript source code (<code>src/index.ts</code>) into JavaScript and outputs it to the <code>dist</code> directory.  Uses <code>ncc</code> (Next.js Compiler) for bundling and includes source maps and the license file.</li> <li><code>format</code>: <code>prettier --write \\\"src/**/*.ts\\\" \\\"config/**/*.js\\\"</code> - Formats TypeScript and JavaScript files in the <code>src</code> and <code>config</code> directories using Prettier.</li> <li><code>format:check</code>: <code>prettier --check \\\"src/**/*.ts\\\" \\\"config/**/*.js\\\"</code> - Checks if TypeScript and JavaScript files are formatted correctly using Prettier, without making changes.</li> <li><code>lint</code>: <code>eslint src/**/*.ts</code> -  Lints TypeScript files in the <code>src</code> directory using ESLint.</li> <li><code>test</code>: <code>jest --config config/jest.config.js</code> - Runs unit tests using Jest with the configuration file <code>config/jest.config.js</code>.</li> <li><code>test:integration</code>: <code>jest --config config/jest.integration.config.js</code> - Runs integration tests using Jest with the configuration file <code>config/jest.integration.config.js</code>.</li> <li><code>test:all</code>: <code>npm run test &amp;&amp; npm run test:integration</code> - Runs both unit and integration tests.</li> <li><code>all</code>: <code>npm run format &amp;&amp; npm run lint &amp;&amp; npm run test &amp;&amp; npm run build</code> - Executes all development tasks: formatting, linting, testing, and building.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/package/#dependencies","title":"Dependencies","text":"<ul> <li> <p><code>dependencies</code>: Lists the packages required for the runtime execution of the package.</p> <ul> <li><code>@actions/cache</code>: Used for caching dependencies and other artifacts in GitHub Actions.</li> <li><code>@actions/core</code>: Provides core functionality for interacting with GitHub Actions.</li> <li><code>@actions/exec</code>: Allows executing shell commands within GitHub Actions.</li> <li><code>@actions/io</code>: Provides utilities for file system operations within GitHub Actions.</li> <li><code>zod</code>: A TypeScript-first schema declaration and validation library.</li> </ul> </li> <li> <p><code>devDependencies</code>: Lists the packages required for development and testing, but not for runtime execution.  These include:</p> <ul> <li><code>@eslint/js</code>: Core ESLint JavaScript parser.</li> <li><code>@types/jest</code>: TypeScript definitions for Jest.</li> <li><code>@types/node</code>: TypeScript definitions for Node.js.</li> <li><code>@typescript-eslint/eslint-plugin</code>: ESLint plugin for TypeScript.</li> <li><code>@typescript-eslint/parser</code>: ESLint parser for TypeScript.</li> <li><code>@vercel/ncc</code>:  A compiler used for bundling Node.js projects.</li> <li><code>eslint</code>:  A linting tool for JavaScript and TypeScript.</li> <li><code>globals</code>: Provides global definitions for testing environments.</li> <li><code>jest</code>: A JavaScript testing framework.</li> <li><code>prettier</code>: A code formatter.</li> <li><code>ts-jest</code>: A Jest transformer for TypeScript.</li> <li><code>typescript</code>: The TypeScript compiler.</li> <li><code>typescript-eslint</code>: ESLint plugin for TypeScript.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/package/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Salesforce Deployment Automation: Automating the deployment of Salesforce metadata changes.</li> <li>Governance Enforcement: Implementing and enforcing governance policies during deployments.</li> <li>CI/CD Pipelines: Integrating with CI/CD systems (like GitHub Actions) to automate Salesforce DevOps processes.</li> <li>Data Management: Automating data loading and manipulation tasks in Salesforce.</li> <li>Testing Automation: Running automated tests against Salesforce environments.</li> </ul>"},{"location":"packages/runtime/docs/permit-permit/","title":"Permit permit","text":""},{"location":"packages/runtime/docs/permit-permit/#permit-package-documentation","title":"Permit Package Documentation","text":"<p>This package is responsible for creating and persisting a permit artifact to disk. This artifact represents a governance decision point within a workflow, capturing information about the actor requesting access, the policies evaluated, and the context in which the request was made. It serves as a handoff contract for downstream processes.</p> <p>Key Types:</p> <ul> <li> <p>Identity: Represents the entity requesting access. It contains the following fields:</p> <ul> <li><code>Subject</code>: A human-readable identifier for the actor.</li> <li><code>Provider</code>: The authentication provider used (e.g., GitHub, Google).</li> <li><code>ProviderID</code>: The unique identifier assigned by the provider.</li> <li><code>Verified</code>: A boolean indicating whether the identity has been verified.</li> </ul> </li> <li> <p>PolicyEvaluation:  Holds the results of policy checks.</p> <ul> <li><code>Allowed</code>: A boolean indicating whether the request is permitted based on policy.</li> <li><code>Evaluated</code>: A string slice listing the policies that were evaluated.</li> <li><code>Violations</code>: A string slice containing details of any policies that were violated. This field is omitted if no violations occurred.</li> </ul> </li> <li> <p>Permit: The central data structure representing the governance decision.</p> <ul> <li><code>Version</code>: The version of the permit schema. Currently \"1.0\".</li> <li><code>PermitID</code>: A unique identifier for this permit instance.</li> <li><code>Timestamp</code>: The time the permit was generated, in RFC3339 format.</li> <li><code>Actor</code>: The <code>Identity</code> of the actor making the request.</li> <li><code>Policies</code>: The <code>PolicyEvaluation</code> result.</li> <li><code>Context</code>: A map of strings providing contextual information about the environment.</li> <li><code>Inputs</code>: A map of strings containing input parameters relevant to the permit.</li> </ul> </li> </ul> <p>Important Functions:</p> <ul> <li> <p>Generate(permitID string, actor Identity, evaluation PolicyEvaluation, instanceURL string) (string, error):     This function creates a <code>Permit</code> instance, serializes it to JSON, and writes it to a file named <code>glassops-permit.json</code> within a <code>.glassops</code> directory in the workspace.</p> <ul> <li><code>permitID</code>: A string providing a unique identifier for the permit.</li> <li><code>actor</code>: The <code>Identity</code> of the actor requesting access.</li> <li><code>evaluation</code>: The <code>PolicyEvaluation</code> result.</li> <li><code>instanceURL</code>: A string representing the URL of the instance.</li> </ul> <p>The function first determines the workspace directory, defaulting to the current directory if the <code>GITHUB_WORKSPACE</code> environment variable is not set. It then populates the <code>Permit</code> struct with relevant data, including environment variables for repository, commit SHA, and workspace. Input parameters <code>username</code> and <code>client_id</code> are retrieved using the <code>gha.GetInput</code> function.  It creates the <code>.glassops</code> directory if it doesn't exist. Finally, it marshals the <code>Permit</code> to JSON with indentation for readability and writes the JSON to the specified file. The function returns the path to the created permit file and an error if any step fails.</p> </li> </ul> <p>Error Handling:</p> <p>The <code>Generate</code> function employs standard Go error handling practices. Errors encountered during directory creation, JSON marshaling, or file writing are wrapped with context using <code>fmt.Errorf</code> to provide more informative error messages. These errors are then returned to the caller.</p> <p>Concurrency:</p> <p>This package does not currently employ any explicit concurrency mechanisms like goroutines or channels. The operations performed are primarily I/O bound and are executed sequentially within the <code>Generate</code> function.</p> <p>Design Decisions:</p> <ul> <li>JSON Format: The permit is serialized to JSON for portability and ease of consumption by other systems.</li> <li>File-Based Persistence:  The permit is written to a file to provide a durable record of the governance decision. The location is within a hidden <code>.glassops</code> directory to avoid accidental modification.</li> <li>Environment Variable Integration: The function leverages environment variables (e.g., <code>GITHUB_WORKSPACE</code>, <code>GITHUB_REPOSITORY</code>, <code>GITHUB_SHA</code>) to gather contextual information about the execution environment.</li> <li>Input Retrieval: The package depends on the <code>gha</code> package to retrieve input parameters, indicating an intended integration with GitHub Actions.</li> </ul>"},{"location":"packages/runtime/docs/permit-permit_test/","title":"Permit permit test","text":""},{"location":"packages/runtime/docs/permit-permit_test/#permit-package-documentation","title":"Permit Package Documentation","text":"<p>This package is responsible for generating permit files. These files represent authorization decisions made at runtime, containing information about the actor requesting access, the policies evaluated, and relevant contextual inputs. The permits are designed to be used by downstream systems to enforce access control.</p> <p>Key Types:</p> <ul> <li><code>Identity</code>: Represents the authenticated user or service account. It includes:<ul> <li><code>Subject</code>: A human-readable identifier for the actor (e.g., username, service account name).</li> <li><code>Provider</code>: The authentication provider (e.g., \"github\").</li> <li><code>ProviderID</code>: A unique identifier assigned by the provider.</li> <li><code>Verified</code>: A boolean indicating if the identity has been verified.</li> </ul> </li> <li><code>PolicyEvaluation</code>: Represents the result of evaluating policies against an actor. It includes:<ul> <li><code>Allowed</code>: A boolean indicating whether access is granted.</li> <li><code>Evaluated</code>: A slice of strings representing the names of the policies that were evaluated.</li> </ul> </li> <li><code>Permit</code>: Represents the generated permit file. It contains:<ul> <li><code>PermitID</code>: A unique identifier for the permit, often corresponding to the runtime identifier.</li> <li><code>Actor</code>: The <code>Identity</code> of the actor the permit applies to.</li> <li><code>Policies</code>: The <code>PolicyEvaluation</code> result.</li> <li><code>Inputs</code>: A map of string keys to string values, holding contextual information relevant to the permit (e.g., instance URL).</li> </ul> </li> </ul> <p>Important Functions:</p> <ul> <li><code>Generate(runtimeID string, actor Identity, evaluation PolicyEvaluation, instanceURL string) (string, error)</code>: This function generates a permit file.<ul> <li>It takes the runtime identifier, actor information, policy evaluation result, and instance URL as input.</li> <li>It creates a <code>Permit</code> object populated with the provided data.</li> <li>It serializes the <code>Permit</code> object to JSON.</li> <li>It writes the JSON data to a file. The filename is derived from the <code>runtimeID</code>.</li> <li>It returns the path to the generated permit file and an error if any occurred during the process.</li> </ul> </li> </ul> <p>Error Handling:</p> <p>The <code>Generate</code> function returns an error value. Common errors include:</p> <ul> <li>Errors during JSON serialization.</li> <li>Errors during file creation or writing.</li> </ul> <p>The test suite verifies that errors are handled correctly and that the expected files are created with the correct content.</p> <p>Design Decisions:</p> <ul> <li>JSON Format: Permits are serialized to JSON for easy parsing and consumption by other systems.</li> <li>File-Based Output: Permits are written to files, providing a persistent record of authorization decisions. The file path is based on the <code>runtimeID</code> to ensure uniqueness.</li> <li>Environment Variables: The test suite uses environment variables (<code>GITHUB_WORKSPACE</code>, <code>GITHUB_ACTOR</code>, <code>GITHUB_REPOSITORY</code>, <code>GITHUB_SHA</code>) to simulate a typical runtime environment, such as a CI/CD pipeline. This allows for realistic testing of the permit generation process.</li> <li>Testability: The package is designed to be easily testable, with a comprehensive test suite that verifies the core functionality.</li> </ul>"},{"location":"packages/runtime/docs/policy-policy/","title":"Policy policy","text":""},{"location":"packages/runtime/docs/policy-policy/#governance-policy-engine-documentation","title":"Governance Policy Engine Documentation","text":"<p>This document describes the governance policy engine, responsible for managing and enforcing organizational policies related to deployments and runtime environments.</p> <p>Package Purpose:</p> <p>The <code>policy</code> package provides the functionality to load, validate, and apply governance rules. It controls aspects like deployment freeze windows, plugin whitelisting, and runtime environment constraints. This package aims to provide a centralized and configurable system for maintaining operational safety and compliance.</p> <p>Key Types and Interfaces:</p> <ul> <li><code>Config</code>: The top-level structure representing the entire governance configuration. It contains <code>GovernanceConfig</code> and <code>RuntimeConfig</code>.</li> <li><code>GovernanceConfig</code>: Holds settings related to governance rules, including enabling/disabling governance, defining freeze windows, and managing a plugin whitelist.</li> <li><code>RuntimeConfig</code>: Stores runtime environment settings such as CLI and Node.js versions.</li> <li><code>FreezeWindow</code>: Defines a specific time window (day and time range) during which deployments are prohibited.</li> <li><code>AnalyzerConfig</code>: Configures static analysis settings, including enabling/disabling the analyzer, setting a severity threshold, and specifying rulesets.</li> <li><code>Engine</code>: The core type that manages policy loading and enforcement. It encapsulates the configuration path.</li> </ul> <p>Important Functions:</p> <ul> <li><code>New()</code>: Creates a new <code>Engine</code> instance. It determines the configuration file path, prioritizing the <code>GLASSOPS_CONFIG_PATH</code> environment variable, falling back to a default location (<code>config/devops-config.json</code>). If the <code>GITHUB_WORKSPACE</code> environment variable is set, the path is resolved relative to that workspace.</li> <li><code>Load()</code>: Reads the governance configuration from the configured file path. If the file does not exist, it returns a default configuration with governance disabled and sets default runtime versions. It handles JSON unmarshaling errors and validates the configuration data, including freeze window times and days. Default values are applied if certain runtime settings are missing.</li> <li><code>CheckFreeze()</code>: Validates whether the current time falls within any defined freeze windows. If a match is found, it returns an error indicating that deployments are blocked.</li> <li><code>ValidatePluginWhitelist()</code>: Checks if a given plugin name is present in the configured whitelist. If the whitelist is empty, all plugins are allowed.</li> <li><code>GetPluginVersionConstraint()</code>: Retrieves the version constraint associated with a whitelisted plugin. Returns an empty string if the plugin is not whitelisted or no version constraint is specified.</li> <li><code>extractPluginName()</code>: Helper function to extract the plugin name from a string that may include a version.</li> <li><code>extractVersionConstraint()</code>: Helper function to extract the version constraint from a string that may include a plugin name.</li> </ul> <p>Error Handling:</p> <p>The package employs standard Go error handling practices. Functions return an error value alongside their primary return value. Errors are often wrapped using <code>fmt.Errorf</code> to provide context and preserve the original error. Specific error conditions, such as file not found or invalid JSON, are handled gracefully, often with informative error messages.</p> <p>Concurrency:</p> <p>This package is not inherently concurrent. The <code>Load()</code> function performs file I/O, which could be made concurrent with goroutines if performance becomes a concern, but the current implementation is single-threaded.</p> <p>Design Decisions:</p> <ul> <li>Configuration File Path: The package supports both absolute and relative configuration file paths. The use of environment variables (<code>GLASSOPS_CONFIG_PATH</code>, <code>GITHUB_WORKSPACE</code>) allows for flexibility in different deployment environments.</li> <li>Default Configuration: A default configuration is provided when the configuration file is missing, ensuring that the system can operate even without explicit configuration. Governance is disabled by default in this scenario.</li> <li>Whitelist Behavior: An empty plugin whitelist allows all plugins, providing a simple way to disable whitelisting.</li> <li>Time Validation: Freeze window times are validated to ensure they are in the correct format (HH:MM).</li> <li>Plugin Name Extraction: The <code>extractPluginName</code> and <code>extractVersionConstraint</code> functions provide a robust way to parse plugin names and version constraints from strings, accommodating both scoped and unscoped packages.</li> </ul>"},{"location":"packages/runtime/docs/policy-policy_test/","title":"Policy policy test","text":""},{"location":"packages/runtime/docs/policy-policy_test/#policy-package-documentation","title":"Policy Package Documentation","text":"<p>This package defines the policy engine responsible for governing runtime behavior. It handles configuration loading, freeze window enforcement, and plugin whitelisting. The primary goal is to provide a mechanism for controlling when and how operations can be performed, and which tools are permitted.</p> <p>Key Types and Interfaces</p> <ul> <li>Config: This structure holds the entire configuration loaded from a JSON file or environment variables. It contains two main fields:<ul> <li><code>Governance</code>:  A <code>GovernanceConfig</code> struct that manages governance-related settings.</li> <li><code>Runtime</code>: A struct managing runtime-specific settings like CLI and Node versions.</li> </ul> </li> <li>GovernanceConfig:  This structure encapsulates governance settings, including:<ul> <li><code>Enabled</code>: A boolean indicating whether governance is active.</li> <li><code>FreezeWindows</code>: A slice of <code>FreezeWindow</code> structs defining periods when operations are prohibited.</li> <li><code>PluginWhitelist</code>: A slice of strings representing allowed plugin names.</li> </ul> </li> <li>FreezeWindow: This structure defines a specific freeze period with:<ul> <li><code>Day</code>: The day of the week the freeze window applies to (e.g., \"Friday\").</li> <li><code>Start</code>: The start time of the freeze window in HH:MM format (e.g., \"17:00\").</li> <li><code>End</code>: The end time of the freeze window in HH:MM format (e.g., \"23:59\").</li> </ul> </li> <li>Engine: This type represents the policy engine itself. It provides methods for loading the configuration, checking for freeze windows, and validating plugins.</li> </ul> <p>Important Functions</p> <ul> <li>New(): Engine: This function creates and returns a new instance of the <code>Engine</code>.</li> <li>Load(): (*Config, error): This function loads the configuration. It first checks for the <code>GLASSOPS_CONFIG_PATH</code> environment variable. If set, it attempts to read the configuration from the specified file. If the environment variable is not set, it attempts to load a default configuration.  It returns a pointer to the <code>Config</code> struct and an error if loading fails.</li> <li>CheckFreeze(*Config): error: This function checks if the current time falls within a defined freeze window. It iterates through the <code>FreezeWindows</code> in the configuration and returns an error if a match is found. If no freeze windows are defined or the current time is outside of any window, it returns nil.</li> <li>ValidatePluginWhitelist(*Config, string): bool: This function checks if a given plugin name is present in the <code>PluginWhitelist</code>. It returns <code>true</code> if the plugin is whitelisted or if the whitelist is empty (allowing all plugins), and <code>false</code> otherwise.</li> <li>GetPluginVersionConstraint(*Config, string): string: This function retrieves the version constraint for a given plugin from the <code>PluginWhitelist</code>. It parses the plugin name and version (if present) and returns the version constraint string. If the plugin is not found in the whitelist or no version is specified, it returns an empty string.</li> <li>extractPluginName(string): string: This helper function extracts the plugin name from a string that may include a version constraint (e.g., \"sfdx-hardis@^4.0.0\").</li> <li>extractVersionConstraint(string): string: This helper function extracts the version constraint from a string that may include a plugin name (e.g., \"sfdx-hardis@^4.0.0\").</li> </ul> <p>Error Handling</p> <p>The package uses standard Go error handling patterns. Functions return an error value as the second return parameter.  The caller is responsible for checking the error value and handling it appropriately.  Errors typically indicate file I/O problems during configuration loading or issues with the configuration data itself.</p> <p>Concurrency</p> <p>This package does not explicitly use goroutines or channels. It is designed to be used in a single-threaded manner.</p> <p>Design Decisions</p> <ul> <li>Configuration Loading: The package supports loading configuration from a JSON file specified by the <code>GLASSOPS_CONFIG_PATH</code> environment variable. This allows for flexible configuration management.  Default values are applied if the configuration file is empty or missing.</li> <li>Plugin Whitelisting: The plugin whitelisting mechanism allows for controlling which plugins are permitted to run. The version constraint parsing provides a way to enforce specific plugin versions.</li> <li>Freeze Windows: The freeze window functionality provides a way to prevent operations during specific times, such as during critical maintenance periods.</li> </ul>"},{"location":"packages/runtime/docs/protocol-contract/","title":"Protocol Contract","text":""},{"location":"packages/runtime/docs/protocol-contract/#deployment-contract-specification","title":"Deployment Contract Specification","text":"<p>This document details the structure and content of the Deployment Contract, a standardized format for representing deployment metadata. It provides a consistent way to communicate the outcome and quality of deployments across different systems and environments.</p> <p>Purpose</p> <p>The Deployment Contract serves as a single source of truth for deployment information. It enables automated validation, reporting, and auditing of deployments.</p> <p>Schema Overview</p> <p>The contract is defined using a schema that ensures data integrity and consistency. The schema consists of the following key sections:</p> <p>1. Schema Version</p> <ul> <li><code>schemaVersion</code>: (String, default: \"1.0\") \u2013 Indicates the version of the contract schema used. This allows for future evolution of the contract format while maintaining backward compatibility.</li> </ul> <p>2. Metadata</p> <ul> <li><code>adapter</code>: (String) \u2013 Identifies the adapter used for the deployment.</li> <li><code>engine</code>: (Enum: \"native\", \"hardis\", \"custom\") \u2013 Specifies the execution engine used during deployment.</li> <li><code>timestamp</code>: (DateTime String) \u2013 Records the date and time of the deployment.</li> <li><code>trigger</code>: (String) \u2013 Describes the event or process that initiated the deployment.</li> </ul> <p>3. Status</p> <ul> <li><code>status</code>: (Enum: \"Succeeded\", \"Failed\", \"Blocked\") \u2013 Represents the overall outcome of the deployment.</li> </ul> <p>4. Quality</p> <p>This section provides metrics related to the quality of the deployed code.</p> <ul> <li><code>coverage</code>:<ul> <li><code>actual</code>: (Number, 0-100) \u2013 The actual code coverage achieved during testing.</li> <li><code>required</code>: (Number, 0-100) \u2013 The minimum code coverage required for the deployment.</li> <li><code>met</code>: (Boolean) \u2013 Indicates whether the actual coverage meets the required coverage.</li> </ul> </li> <li><code>tests</code>:<ul> <li><code>total</code>: (Number, &gt;=0) \u2013 The total number of tests executed.</li> <li><code>passed</code>: (Number, &gt;=0) \u2013 The number of tests that passed.</li> <li><code>failed</code>: (Number, &gt;=0) \u2013 The number of tests that failed.</li> </ul> </li> </ul> <p>5. Audit Information</p> <ul> <li><code>triggeredBy</code>: (String) \u2013 Identifies the user or system that initiated the deployment.</li> <li><code>orgId</code>: (String) \u2013 The organization associated with the deployment.</li> <li><code>repository</code>: (String) \u2013 The repository containing the deployed code.</li> <li><code>commit</code>: (String) \u2013 The specific commit hash deployed.</li> </ul> <p>Data Type</p> <p>The <code>DeploymentContract</code> type is derived directly from the <code>DeploymentContractSchema</code>, ensuring type safety and consistency. </p> <p>Usage</p> <p>I designed this contract to be used in automated deployment pipelines. You can validate deployment data against this schema to ensure it conforms to the expected format. I provide tools to generate and parse contracts programmatically. </p> <p>Future Considerations</p> <p>We plan to extend this contract with additional metadata, such as performance metrics and security scan results, to provide a more comprehensive view of deployment quality.</p>"},{"location":"packages/runtime/docs/protocol-contract.test/","title":"Protocol Contract Test","text":""},{"location":"packages/runtime/docs/protocol-contract.test/#deployment-contract-schema-documentation","title":"Deployment Contract Schema Documentation","text":"<p>This document describes the <code>DeploymentContractSchema</code>, which defines the structure and validation rules for deployment contracts. These contracts represent the outcome of a deployment process and contain metadata, status information, quality metrics, and audit details.</p> <p>Purpose</p> <p>The schema ensures that deployment contracts adhere to a consistent format, enabling reliable processing and analysis of deployment results. It validates the data to maintain data integrity and prevent errors.</p> <p>Schema Structure</p> <p>A valid deployment contract must conform to the following structure:</p> <ul> <li><code>schemaVersion</code> (string, optional):  The version of the schema used. If not provided, it defaults to \"1.0\".</li> <li><code>meta</code> (object): Contains metadata about the deployment.<ul> <li><code>adapter</code> (string): The adapter used for the deployment.</li> <li><code>engine</code> (string): The engine used for the deployment.  Acceptable values are limited to \"native\".</li> <li><code>timestamp</code> (string): The timestamp of the deployment event in ISO 8601 format (e.g., \"2024-01-21T18:00:00.000Z\").</li> <li><code>trigger</code> (string): The event that triggered the deployment (e.g., \"push\").</li> </ul> </li> <li><code>status</code> (string): The overall status of the deployment. Acceptable values are limited to \"Succeeded\".</li> <li><code>quality</code> (object): Contains quality metrics for the deployment.<ul> <li><code>coverage</code> (object): Code coverage information.<ul> <li><code>actual</code> (number): The actual code coverage percentage. Must be between 0 and 100.</li> <li><code>required</code> (number): The required code coverage percentage.</li> <li><code>met</code> (boolean): Indicates whether the required coverage was met.</li> </ul> </li> <li><code>tests</code> (object): Test execution results.<ul> <li><code>total</code> (number): The total number of tests executed. Must be a non-negative integer.</li> <li><code>passed</code> (number): The number of tests that passed.</li> <li><code>failed</code> (number): The number of tests that failed.</li> </ul> </li> </ul> </li> <li><code>audit</code> (object): Contains audit information about the deployment.<ul> <li><code>triggeredBy</code> (string): The user or system that triggered the deployment.</li> <li><code>orgId</code> (string): The organization ID associated with the deployment.</li> <li><code>repository</code> (string): The repository where the code was deployed from (e.g., \"org/repo\").</li> <li><code>commit</code> (string): The commit hash associated with the deployment.</li> </ul> </li> </ul> <p>Validation Rules</p> <p>I enforce the following validation rules:</p> <ul> <li>The <code>engine</code> field must be set to \"native\".</li> <li>The <code>status</code> field must be set to \"Succeeded\".</li> <li>The <code>timestamp</code> field must be a valid ISO 8601 formatted string.</li> <li>Test counts (<code>total</code>, <code>passed</code>, <code>failed</code>) must be non-negative integers.</li> <li>Code coverage percentages (<code>actual</code>, <code>required</code>) must be between 0 and 100.</li> </ul> <p>Usage</p> <p>You can parse a deployment contract using <code>DeploymentContractSchema.parse(contractData)</code>. This method will validate the <code>contractData</code> against the schema and return the parsed contract if it is valid. If the contract is invalid, an error will be thrown.</p>"},{"location":"packages/runtime/docs/protocol-policy/","title":"Protocol Policy","text":""},{"location":"packages/runtime/docs/protocol-policy/#protocol-policy-document","title":"Protocol Policy Document","text":"<p>1. Introduction</p> <p>This document details the Protocol Policy, a component responsible for governing runtime behavior and enforcing operational constraints. It manages configurations related to governance, including deployment freezes and plugin whitelisting, as well as runtime settings like CLI and Node.js versions.</p> <p>2. Configuration</p> <p>The policy is driven by a configuration file (<code>devops-config.json</code>) located in the root of the GitHub workspace (or the current directory if not running within a workspace).  If this file is absent, a default, less restrictive policy is applied. The configuration is validated against a defined schema.</p> <p>2.1. Governance Settings</p> <ul> <li>Enabled: A boolean flag to globally enable or disable governance features. Defaults to <code>true</code>.</li> <li>Freeze Windows: Defines specific time windows during which deployments are blocked. Each window includes a <code>day</code> (Monday-Sunday), <code>start</code> time (HH:MM), and <code>end</code> time (HH:MM).  Times are evaluated using UTC.</li> <li>Plugin Whitelist: A list of allowed Salesforce CLI plugins. Entries can optionally include version constraints (e.g., <code>sfdx-hardis@^4.0.0</code>). If no whitelist is provided, all plugins are permitted.</li> <li>Analyzer: Configures the Salesforce code analyzer.<ul> <li>Enabled: Enables or disables the analyzer. Defaults to <code>false</code>.</li> <li>Severity Threshold: Sets the minimum severity level for analyzer findings (1-3). Defaults to <code>1</code>.</li> <li>Rulesets: An optional array of rulesets to apply.</li> <li>Opinionated:  Determines whether the <code>sf code-analyzer</code> is preferred over <code>sf scanner</code>. Defaults to <code>true</code>.</li> </ul> </li> </ul> <p>2.2. Runtime Settings</p> <ul> <li>CLI Version: Specifies the desired Salesforce CLI version. Defaults to <code>latest</code>.</li> <li>Node Version: Specifies the desired Node.js version. Defaults to <code>20</code>.</li> </ul> <p>3. Core Functionality</p> <ul> <li>Configuration Loading: The <code>ProtocolPolicy</code> class loads the configuration from <code>devops-config.json</code>, validating it against the defined schema.  Errors during loading result in an exception.</li> <li>Deployment Freeze Check: The <code>checkFreeze</code> method evaluates the current time against configured freeze windows. If the current time falls within a freeze window, a descriptive error is thrown, blocking the deployment.</li> <li>Plugin Validation:<ul> <li><code>validatePluginWhitelist</code>: Checks if a given plugin is allowed based on the configured whitelist. If no whitelist is defined, all plugins are allowed.</li> <li><code>getPluginVersionConstraint</code>: Retrieves the version constraint for a given plugin from the whitelist, if specified.</li> </ul> </li> <li>Plugin Name and Version Extraction:  Internal methods (<code>extractPluginName</code>, <code>extractVersionConstraint</code>) parse whitelist entries to determine the plugin name and associated version constraint. These methods handle both scoped packages (e.g., <code>@scope/package@version</code>) and regular packages (e.g., <code>package@version</code>).</li> </ul> <p>4. Usage</p> <p>You can instantiate the <code>ProtocolPolicy</code> class to access its functionality.  </p> <pre><code>const policy = new ProtocolPolicy();\nconst config = await policy.load();\npolicy.checkFreeze(config); // Check for deployment freezes\nconst isPluginAllowed = policy.validatePluginWhitelist(config, \"sfdx-cli\"); // Validate a plugin\nconst versionConstraint = policy.getPluginVersionConstraint(config, \"sfdx-cli\"); // Get version constraint\n</code></pre> <p>5. Error Handling</p> <p>The <code>ProtocolPolicy</code> includes error handling for invalid configuration files and deployment freeze violations.  Informative error messages are provided to aid in troubleshooting.  A warning is logged if the configuration file is not found, and a default policy is applied.</p>"},{"location":"packages/runtime/docs/protocol-policy.test/","title":"Protocol Policy Test","text":""},{"location":"packages/runtime/docs/protocol-policy.test/#protocol-policy-document","title":"Protocol Policy Document","text":"<p>This document details the Protocol Policy component, responsible for enforcing governance and security constraints during runtime operations. It outlines the policy\u2019s functionality, including freeze window checks and plugin whitelisting.</p> <p>Overview</p> <p>The Protocol Policy component provides a mechanism to control when and how operations can be performed. It reads configuration from a <code>devops-config.json</code> file (if present) to determine governance settings. If the configuration file is missing, a default, permissive policy is applied.  The policy enforces rules related to deployment timing (freeze windows) and permitted plugins.</p> <p>Key Features</p> <ul> <li>Freeze Window Enforcement: Prevents deployments during specified time windows, such as weekends or specific maintenance periods. The policy checks the current time against configured freeze windows and throws an error if a deployment is attempted during a frozen period.</li> <li>Plugin Whitelisting:  Ensures that only approved plugins are used.  The policy validates plugins against a whitelist defined in the configuration.</li> <li>Configuration Loading: Loads governance settings from a <code>devops-config.json</code> file. Handles missing or invalid configuration files gracefully, falling back to a default policy or throwing an error.</li> <li>Version Constraints: Supports version constraints for whitelisted plugins, allowing for specific versions or ranges of versions to be approved.</li> </ul> <p>Functionality Details</p> <ol> <li> <p><code>checkFreeze(config)</code>:</p> <ul> <li>Takes a configuration object as input.</li> <li>Determines if the current time falls within a defined freeze window.</li> <li>Throws an error if the current time is within a freeze window, halting execution.</li> <li>Does nothing if no freeze windows are defined in the configuration.</li> </ul> </li> <li> <p><code>validatePluginWhitelist(config, pluginName)</code>:</p> <ul> <li>Takes a configuration object and a plugin name as input.</li> <li>Checks if the specified plugin is present in the configured whitelist.</li> <li>Returns <code>true</code> if the plugin is whitelisted or if no whitelist is configured.</li> <li>Returns <code>false</code> if the plugin is not in the whitelist.</li> </ul> </li> <li> <p><code>getPluginVersionConstraint(config, pluginName)</code>:</p> <ul> <li>Takes a configuration object and a plugin name as input.</li> <li>Retrieves the version constraint for the specified plugin from the whitelist, if one exists.</li> <li>Returns the version constraint string (e.g., \"^6.0.0\") if found.</li> <li>Returns <code>null</code> if the plugin is not in the whitelist or if no version constraint is specified.</li> </ul> </li> <li> <p><code>load()</code>:</p> <ul> <li>Attempts to load governance settings from a <code>devops-config.json</code> file.</li> <li>If the file is missing, loads a default, permissive policy and issues a warning.</li> <li>If the file exists, parses the JSON content and validates it against a predefined schema.</li> <li>Throws an error if the JSON is invalid or if the configuration schema is invalid.</li> <li>Handles potential errors during file reading and parsing.</li> </ul> </li> </ol> <p>Configuration</p> <p>The policy is configured through a <code>devops-config.json</code> file. The following settings are supported:</p> <ul> <li><code>governance.enabled</code>: A boolean indicating whether governance policies are enabled.</li> <li><code>governance.freeze_windows</code>: An array of objects defining freeze windows. Each object includes:<ul> <li><code>day</code>: The day of the week (e.g., \"Friday\").</li> <li><code>start</code>: The start time of the freeze window (e.g., \"09:00\").</li> <li><code>end</code>: The end time of the freeze window (e.g., \"17:00\").</li> </ul> </li> <li><code>governance.plugin_whitelist</code>: An array of strings representing whitelisted plugins, optionally including version constraints (e.g., \"sfdx-hardis@^6.0.0\").</li> <li><code>runtime.cli_version</code>: The CLI version.</li> <li><code>runtime.node_version</code>: The Node.js version.</li> </ul> <p>Error Handling</p> <p>The policy handles errors related to configuration loading and validation.  Invalid JSON or schema errors result in an exception being thrown, preventing execution.  Freeze window violations also result in an exception.  Missing configuration files result in a warning and the application of a default policy.</p>"},{"location":"packages/runtime/docs/services-analyzer/","title":"Services Analyzer","text":""},{"location":"packages/runtime/docs/services-analyzer/#analyzer-service-documentation","title":"Analyzer Service Documentation","text":"<p>This document details the functionality of the Analyzer service, responsible for executing the Salesforce Code Analyzer and processing its results.</p> <p>Overview</p> <p>The Analyzer service provides a standardized way to scan Salesforce projects for code quality issues. It leverages the Salesforce CLI (<code>sf</code>) to run the <code>code-analyzer</code> command and interprets the output to identify violations against defined rules.  I am designed to be adaptable to different rulesets and project structures.</p> <p>Key Components</p> <ul> <li>Analyzer Class: The core component that orchestrates the analysis process.</li> <li>AnalyzerResult Interface: Defines the structure of the analysis results, including a list of violations and the analyzer's exit code.</li> <li>Violation Interface:  Describes a single code violation, including the rule triggered, a descriptive message, severity level, the file name, and the line number.</li> </ul> <p>Functionality</p> <ol> <li> <p><code>scan(paths: string[], ruleset?: string): Promise&lt;AnalyzerResult&gt;</code></p> <p>This asynchronous function initiates the code analysis process.</p> <ul> <li><code>paths</code>:  An array of strings representing the directories or files to be scanned.  For example: <code>[\"src\", \"test\"]</code>.</li> <li><code>ruleset</code>: (Optional) A string specifying the ruleset to enforce during the analysis. If not provided, a default ruleset is used.</li> <li>Return Value: A <code>Promise</code> that resolves to an <code>AnalyzerResult</code> object containing the identified violations and the analyzer's exit code.</li> </ul> <p>The <code>scan</code> function performs the following steps:</p> <ul> <li>Calls <code>ensureCompatibility()</code> to verify the environment.</li> <li>Constructs the command-line arguments for the <code>sf code-analyzer run</code> command.</li> <li>Executes the command using <code>@actions/exec</code>.</li> <li>Captures the standard output and standard error streams.</li> <li>Parses the JSON output from the analyzer.</li> <li>Returns an <code>AnalyzerResult</code> object.</li> </ul> </li> <li> <p><code>ensureCompatibility(): Promise&lt;void&gt;</code></p> <p>This asynchronous function enforces a policy that requires the use of <code>sf code-analyzer</code>.  It currently serves as a placeholder to ensure that users migrate from older scanning tools.  In future versions, this function may include checks to verify the presence of the <code>sf code-analyzer</code> command.</p> </li> <li> <p><code>parseOutput(jsonOutput: string, exitCode: number): AnalyzerResult</code></p> <p>This private function parses the JSON output from the <code>sf code-analyzer</code> command.</p> <ul> <li><code>jsonOutput</code>: The raw JSON string received from the analyzer.</li> <li><code>exitCode</code>: The exit code returned by the analyzer.</li> <li>Return Value: An <code>AnalyzerResult</code> object.</li> </ul> <p>The <code>parseOutput</code> function performs the following steps:</p> <ul> <li>Extracts the JSON array from the output string.</li> <li>Parses the JSON string into a JavaScript object.</li> <li>Transforms the raw analyzer output into a list of <code>Violation</code> objects.</li> <li>Handles potential parsing errors by logging a warning and returning an empty list of violations.</li> </ul> </li> </ol> <p>Error Handling</p> <p>The <code>scan</code> function includes error handling to catch exceptions during analyzer execution.  Errors are logged using <code>@actions/core</code>, and the error is re-thrown to allow calling functions to handle the failure.  Parsing errors in <code>parseOutput</code> are logged as warnings, and an empty result is returned to prevent the process from halting.</p> <p>Configuration</p> <p>You can configure the analysis by:</p> <ul> <li>Specifying the <code>paths</code> to scan.</li> <li>Providing a custom <code>ruleset</code> to enforce specific code quality rules.</li> </ul>"},{"location":"packages/runtime/docs/services-analyzer.test/","title":"Services Analyzer Test","text":""},{"location":"packages/runtime/docs/services-analyzer.test/#analyzer-service-documentation","title":"Analyzer Service Documentation","text":"<p>This document details the functionality of the Analyzer service, responsible for executing external analysis tools and processing their output.</p> <p>Overview</p> <p>The Analyzer service executes a command-line tool (\"sf\") to scan source code for potential issues. It captures the tool\u2019s output, parses it as JSON, and transforms the findings into a standardized violation format.  The service is designed to handle potential errors during execution and output processing, providing informative feedback through logging.</p> <p>Functionality</p> <p>The primary function, <code>scan</code>, accepts an array of source code paths to analyze and an optional ruleset identifier.  </p> <ul> <li>Execution: It executes the \"sf\" command with the provided source paths and ruleset.</li> <li>Output Handling: It captures both standard output (stdout) and standard error (stderr) from the executed command.  Stderr is logged for debugging purposes.</li> <li>JSON Parsing: It attempts to parse the stdout as a JSON array of violation objects.  The service includes error handling for malformed JSON.</li> <li>Violation Transformation:  Parsed violations are transformed into an internal format containing the rule name, description, severity, file path, and line number.</li> <li>Error Handling:  The service gracefully handles command execution failures and JSON parsing errors, logging appropriate error or warning messages.</li> <li>Return Value: The <code>scan</code> function returns an object containing an array of violations and the exit code of the executed command.</li> </ul> <p>Configuration</p> <p>You can specify a ruleset for the analysis by providing a string as the second argument to the <code>scan</code> function. If no ruleset is provided, a default ruleset is used.</p> <p>Error and Logging</p> <p>The service uses the following mechanisms for reporting issues:</p> <ul> <li>Error Logging:  Critical errors, such as command execution failures, are logged using <code>core.error</code>.</li> <li>Warning Logging:  Issues like JSON parsing failures are logged using <code>core.warning</code>.</li> <li>Standard Error Capture:  The stderr output from the executed command is captured and logged to aid in debugging.</li> </ul> <p>Data Structures</p> <ul> <li>Violation Object (Internal Format):<ul> <li><code>rule</code>: The name of the violated rule.</li> <li><code>description</code>: A description of the violation.</li> <li><code>severity</code>: An integer representing the severity of the violation.</li> <li><code>file</code>: The path to the file containing the violation.</li> <li><code>line</code>: The line number where the violation occurred.</li> </ul> </li> </ul> <p>Dependencies</p> <ul> <li><code>@actions/exec</code>: Used for executing the external command.</li> <li><code>@actions/core</code>: Used for logging errors and warnings.</li> </ul>"},{"location":"packages/runtime/docs/services-cli/","title":"Services CLI","text":""},{"location":"packages/runtime/docs/services-cli/#runtime-environment-service-documentation","title":"Runtime Environment Service Documentation","text":"<p>This document describes the <code>RuntimeEnvironment</code> service, a component responsible for managing the execution environment. It handles interactions with the operating system to execute commands, primarily focused on scenarios requiring automated confirmation.</p> <p>Package Responsibilities:</p> <p>The <code>services</code> package provides implementations for runtime services. This specific module, <code>cli.go</code>, focuses on executing commands with automatic confirmation, previously used for CLI installation and plugin management.  However, the installation and plugin management functionality has been removed as part of a larger architectural change to decouple runtime dependencies. The service now primarily supports executing commands that require non-interactive confirmation.</p> <p>Key Types:</p> <ul> <li><code>RuntimeEnvironment</code>: This struct represents the runtime environment.<ul> <li><code>platform</code>: A string indicating the operating system (obtained from the <code>GOOS</code> environment variable). This is used to determine the appropriate command shell for executing commands.</li> </ul> </li> </ul> <p>Functions:</p> <ul> <li> <p><code>NewRuntimeEnvironment()</code>: This function creates and returns a pointer to a new <code>RuntimeEnvironment</code> struct. It initializes the <code>platform</code> field by reading the value of the <code>GOOS</code> environment variable.     <pre><code>func NewRuntimeEnvironment() *RuntimeEnvironment {\n    return &amp;RuntimeEnvironment{\n        platform: os.Getenv(\"GOOS\"),\n    }\n}\n</code></pre></p> </li> <li> <p><code>execWithAutoConfirm(command string, args []string) error</code>: This function executes a given command with its arguments, automatically providing a \"yes\" response to any prompts. This is achieved by piping \"y\" to the command's standard input.</p> <ul> <li>It takes the command name and a slice of arguments as input.</li> <li>It constructs the full command string, quoting each argument to handle spaces and special characters.</li> <li>It determines the appropriate shell based on the <code>platform</code> field.  On Windows, it uses <code>cmd /c \"echo y|...\"</code>. On other systems, it uses <code>sh -c \"echo y | ...\"</code>.</li> <li>It executes the command using <code>exec.Command</code> and returns any error encountered during execution. <pre><code>func (r *RuntimeEnvironment) execWithAutoConfirm(command string, args []string) error {\n    quotedArgs := make([]string, len(args))\n    for i, arg := range args {\n        quotedArgs[i] = fmt.Sprintf(`\"%s\"`, arg)\n    }\n    fullCommand := fmt.Sprintf(\"%s %s\", command, strings.Join(quotedArgs, \" \"))\n\n    var cmd *exec.Cmd\n    if r.platform == \"windows\" {\n        cmd = exec.Command(\"cmd\", \"/c\", fmt.Sprintf(\"echo y|%s\", fullCommand))\n    } else {\n        cmd = exec.Command(\"sh\", \"-c\", fmt.Sprintf(\"echo y | %s\", fullCommand))\n    }\n\n    return cmd.Run()\n}\n</code></pre></li> </ul> </li> </ul> <p>Error Handling:</p> <p>The <code>execWithAutoConfirm</code> function returns an <code>error</code> value. You should check this value after calling the function to determine if the command executed successfully.  Any error returned by the <code>cmd.Run()</code> function is propagated to the caller.</p> <p>Design Decisions:</p> <ul> <li>Platform-Specific Execution: The service uses conditional logic based on the <code>GOOS</code> environment variable to execute commands using the appropriate shell for the operating system. This ensures compatibility across different platforms.</li> <li>Automated Confirmation: The <code>execWithAutoConfirm</code> function provides a mechanism for automatically confirming prompts during command execution. This is useful for automating tasks that would otherwise require manual intervention.</li> <li>Removed Functionality: The <code>Install</code> and <code>InstallPlugins</code> methods were removed to simplify the runtime and shift dependency management to the execution environment. We now expect the environment to have all necessary dependencies pre-installed. This change improves portability and reduces the complexity of the runtime.</li> </ul>"},{"location":"packages/runtime/docs/services-cli.test/","title":"Services CLI Test","text":""},{"location":"packages/runtime/docs/services-cli.test/#runtime-environment-documentation","title":"Runtime Environment Documentation","text":"<p>This document details the functionality of the Runtime Environment service, responsible for managing the Salesforce CLI (sf CLI) and its plugins. It outlines installation, verification, and governance features.</p> <p>Overview</p> <p>The Runtime Environment provides methods to ensure the necessary sf CLI and plugins are present and correctly configured for operation. It handles installation, version checks, and plugin whitelisting to maintain a secure and predictable environment.</p> <p>Functionality</p> <p>1. Installation ( <code>runtime.install()</code> )</p> <p>This function manages the installation of the sf CLI.</p> <ul> <li>Detection: First, it checks if the sf CLI is already available in the system\u2019s PATH. If found, installation is skipped.</li> <li>Installation Process: If the sf CLI is not found, it installs the latest version (or a specified version) using npm.  After installation, it verifies the installation by running <code>sf version</code>.</li> <li>Error Handling:  The function throws an error if either the npm installation or the sf CLI version check fails, indicating potential issues with the npm registry or the CLI itself.</li> <li>Logging:  Installation attempts and skips are logged for transparency.  A start and end group is used to delineate the installation process.</li> </ul> <p>Parameters:</p> <ul> <li><code>version</code> (optional):  A string specifying the desired sf CLI version (e.g., \"2.50.0\"). If omitted, the latest version is installed.</li> </ul> <p>2. Plugin Management ( <code>runtime.installPlugins()</code> )</p> <p>This function manages the installation of Salesforce CLI plugins.</p> <ul> <li>Plugin Whitelisting:  It enforces a plugin whitelist defined in the <code>ProtocolConfig</code>. Only plugins present in the whitelist are installed. If no whitelist is configured, a warning is issued, and all plugins are permitted.</li> <li>Installation Process: For each whitelisted plugin, it executes the <code>sf plugins install</code> command.</li> <li>Verification: After installation, it verifies the installation by querying installed plugins using <code>sf plugins --json</code>.</li> <li>Error Handling:  The function throws errors in the following scenarios:<ul> <li>Attempting to install a plugin not on the whitelist.</li> <li>Failure during plugin installation.</li> <li>Unexpected output format from the <code>sf plugins --json</code> command.</li> <li>Plugin verification failing (plugin not found after installation).</li> </ul> </li> <li>Logging:  Plugin validation, installation attempts, and any errors are logged.</li> <li>Platform Considerations: Uses the appropriate shell (<code>sh</code> on Linux/macOS, <code>cmd</code> on Windows) and command flags for plugin installation.</li> </ul> <p>Parameters:</p> <ul> <li><code>config</code>: A <code>ProtocolConfig</code> object containing governance settings, including the plugin whitelist.</li> <li><code>plugins</code>: An array of strings, where each string is the name of a plugin to install.</li> </ul> <p>Configuration ( <code>ProtocolConfig</code> )</p> <p>The <code>ProtocolConfig</code> object governs the behavior of the Runtime Environment. Relevant properties include:</p> <ul> <li><code>governance.enabled</code>: A boolean indicating whether governance features (like plugin whitelisting) are enabled.</li> <li><code>governance.plugin_whitelist</code>: An array of strings representing the allowed plugins.  Can be undefined to allow all plugins.</li> <li><code>runtime.cli_version</code>: The desired CLI version.</li> <li><code>runtime.node_version</code>: The required Node.js version.</li> </ul> <p>Dependencies</p> <ul> <li><code>@actions/exec</code>: Used for executing shell commands.</li> <li><code>@actions/io</code>: Used for checking if a command is available in the system\u2019s PATH.</li> <li><code>@actions/core</code>: Used for logging and managing action groups.</li> </ul>"},{"location":"packages/runtime/docs/services-cli_test/","title":"Services cli test","text":""},{"location":"packages/runtime/docs/services-cli_test/#runtime-services-package-documentation","title":"Runtime Services Package Documentation","text":"<p>This document describes the <code>services</code> package, which provides components for managing the runtime environment. The primary responsibility of this package is to encapsulate information about the operating system and provide functions for executing commands with automatic confirmation where appropriate.</p> <p>Key Types</p> <ul> <li><code>RuntimeEnvironment</code>: This struct represents the runtime environment. It currently holds a single field:<ul> <li><code>platform</code>: A string representing the operating system platform (e.g., \"linux\", \"windows\"). This value is determined by reading the <code>GOOS</code> environment variable. If <code>GOOS</code> is not set, the platform will be an empty string.</li> </ul> </li> </ul> <p>Functions</p> <ul> <li><code>NewRuntimeEnvironment()</code>: This function creates and returns a new <code>RuntimeEnvironment</code> instance. The platform is initialized based on the <code>GOOS</code> environment variable. It returns <code>nil</code> if initialization fails, though current implementation does not have failure conditions.</li> <li><code>execWithAutoConfirm(command string, args []string) error</code>: This function executes a command with arguments. It is designed to handle automatic confirmation prompts, though the provided tests do not fully exercise this functionality. The function currently logs any errors encountered during execution but does not halt execution. It returns an error if the command execution fails.</li> </ul> <p>Error Handling</p> <p>The package employs a standard Go error handling pattern. Functions return an <code>error</code> value to indicate failure. The tests log errors encountered during command execution, but the functions themselves do not panic.</p> <p>Concurrency</p> <p>This package does not currently employ goroutines or channels.</p> <p>Design Decisions</p> <ul> <li>Platform Detection: The package relies on the <code>GOOS</code> environment variable to determine the operating system platform. This allows for flexibility and testing in different environments. If <code>GOOS</code> is not set, the platform field remains empty.</li> <li>Testability: The tests use <code>defer</code> statements to restore the original value of the <code>GOOS</code> environment variable, ensuring that tests do not interfere with each other or the environment.</li> <li>Command Execution: The <code>execWithAutoConfirm</code> function is designed to abstract the complexities of command execution and automatic confirmation. The tests focus on verifying the command construction rather than the actual execution, as the availability of specific commands (like <code>sf</code>) is not guaranteed in the test environment.</li> <li>Platform Specific Tests: The tests for <code>execWithAutoConfirm</code> are skipped based on the current operating system to ensure that only relevant tests are executed. You will see <code>t.Skip</code> calls in the test code.</li> </ul>"},{"location":"packages/runtime/docs/services-health/","title":"Services health","text":""},{"location":"packages/runtime/docs/services-health/#health-service-documentation","title":"Health Service Documentation","text":"<p>This document describes the <code>health</code> service package, responsible for verifying the operational status of dependent command-line tools, specifically the Salesforce CLI (sf). It provides a mechanism to determine if the CLI is installed, accessible, and functioning correctly.</p> <p>Package Responsibilities:</p> <p>The primary responsibility of this package is to perform a health check on the Salesforce CLI. This involves executing a CLI command and parsing its output to determine the CLI\u2019s health and version. This information is then returned in a structured format.</p> <p>Key Types:</p> <ul> <li><code>HealthCheckResult</code>: This struct encapsulates the outcome of the health check.<ul> <li><code>Healthy</code>: A boolean indicating whether the Salesforce CLI is considered healthy (i.e., accessible and responding).</li> <li><code>Version</code>: A string representing the version of the Salesforce CLI.  If the version cannot be determined, it defaults to \"unknown\".</li> <li><code>Error</code>: A string containing an error message if the health check failed.  This field is empty if the check was successful.</li> </ul> </li> </ul> <p>Important Functions:</p> <ul> <li><code>HealthCheck()</code>: This function performs the health check.<ol> <li>It executes the command <code>sf version --json</code> using <code>exec.Command</code>.</li> <li>It captures the standard output and any errors from the command.</li> <li>If an error occurs during command execution (e.g., the <code>sf</code> command is not found), it constructs a <code>HealthCheckResult</code> with <code>Healthy</code> set to <code>false</code> and the error message populated. It attempts to extract the error message from the standard error stream of the command if available.</li> <li>If the command executes successfully, it attempts to parse the JSON output using <code>json.Unmarshal</code>.</li> <li>If JSON parsing fails, it returns a <code>HealthCheckResult</code> with <code>Healthy</code> set to <code>false</code> and an appropriate error message.</li> <li>If parsing is successful, it extracts the CLI version from the JSON response. The function handles variations in the JSON structure, checking both <code>result.CLIVersion</code> and <code>result.Result.CLIVersion</code>.</li> <li>Finally, it returns a <code>HealthCheckResult</code> with <code>Healthy</code> set to <code>true</code>, the extracted version, and an empty error string.</li> </ol> </li> </ul> <p>Error Handling:</p> <p>The <code>HealthCheck</code> function employs robust error handling. It checks for errors during command execution and JSON parsing. When an error occurs, it constructs a <code>HealthCheckResult</code> with the <code>Healthy</code> flag set to <code>false</code> and a descriptive error message. The function specifically handles <code>exec.ExitError</code> to capture standard error output from the CLI command, providing more informative error messages to the user.</p> <p>Concurrency:</p> <p>This package does not currently employ goroutines or channels. The <code>HealthCheck</code> function is synchronous and executes sequentially.</p> <p>Design Decisions:</p> <ul> <li>JSON Parsing: The function relies on the Salesforce CLI providing version information in JSON format. This allows for structured parsing and avoids fragile string manipulation.</li> <li>Error Message Extraction: The function attempts to extract error messages from the standard error stream of the CLI command, providing more context to the user when the CLI fails.</li> <li>Version Fallback: The function includes fallback logic to handle potential variations in the JSON response structure, ensuring that the version is extracted correctly whenever possible.</li> <li>Simple Result Structure: The <code>HealthCheckResult</code> struct provides a clear and concise representation of the health check outcome.</li> </ul> <p>Usage:</p> <p>You can call the <code>HealthCheck</code> function to determine the health of the Salesforce CLI. You should inspect the <code>Healthy</code> field of the returned <code>HealthCheckResult</code> to determine if the CLI is functioning correctly. If <code>Healthy</code> is <code>false</code>, you should examine the <code>Error</code> field for details about the failure.</p>"},{"location":"packages/runtime/docs/services-health_test/","title":"Services health test","text":""},{"location":"packages/runtime/docs/services-health_test/#health-service-documentation","title":"Health Service Documentation","text":"<p>This document describes the <code>services</code> package, specifically focusing on the health check functionality. This package provides a mechanism to determine the operational status of the application and report its version.</p> <p>Package Responsibilities:</p> <p>The primary responsibility of this package is to provide a simple health check endpoint. This allows monitoring systems and other services to verify the application is running correctly. It also provides a way to report the application\u2019s current version.</p> <p>Key Types:</p> <ul> <li><code>HealthCheckResult</code>: This structure represents the outcome of a health check. It contains the following fields:<ul> <li><code>Healthy</code>: A boolean value indicating whether the application is healthy (<code>true</code>) or not (<code>false</code>).</li> <li><code>Version</code>: A string representing the application's version. This field is populated when the application is healthy.</li> <li><code>Error</code>: A string containing an error message. This field is populated when the application is unhealthy, providing details about the failure.</li> </ul> </li> </ul> <p>Important Functions:</p> <p>Currently, the package contains only test code. The core health check logic is not present in this file, but the <code>HealthCheckResult</code> type and its expected behavior are defined through the tests.</p> <p>The <code>TestHealthCheckResult</code> function validates the correct construction and content of the <code>HealthCheckResult</code> type. It tests two scenarios:</p> <ol> <li>Healthy Scenario: Creates a <code>HealthCheckResult</code> with <code>Healthy</code> set to <code>true</code> and <code>Version</code> set to \"2.0.0\". The test asserts that these values are correctly set.</li> <li>Unhealthy Scenario: Creates a <code>HealthCheckResult</code> with <code>Healthy</code> set to <code>false</code> and <code>Error</code> set to \"sf not found\". The test asserts that these values are correctly set.</li> </ol> <p>Error Handling:</p> <p>The <code>HealthCheckResult</code> type handles errors by including an <code>Error</code> field. When a health check fails, this field is populated with a descriptive error message. This allows consumers of the health check to understand the reason for the failure.</p> <p>Concurrency:</p> <p>This specific file does not demonstrate any concurrency patterns. However, in a production implementation, the health check function itself might employ goroutines to perform checks against various dependencies concurrently.</p> <p>Design Decisions:</p> <p>We chose a simple struct to represent the health check result. This approach provides a clear and concise way to communicate the application's status and any associated errors. The use of a boolean <code>Healthy</code> field, combined with an optional <code>Error</code> message, offers a flexible and informative health check mechanism. You can extend this structure to include additional information about the application's health, such as resource usage or dependency status.</p>"},{"location":"packages/runtime/docs/services-identity/","title":"Services Identity","text":""},{"location":"packages/runtime/docs/services-identity/#identity-service-documentation","title":"Identity Service Documentation","text":"<p>This document describes the Identity Service, responsible for handling authentication with Salesforce. It provides functionality for authenticating using both JWT (JSON Web Token) and SFDX (Salesforce DX) authentication URLs.</p>"},{"location":"packages/runtime/docs/services-identity/#package-responsibilities","title":"Package Responsibilities","text":"<p>The <code>services</code> package contains the core logic for interacting with Salesforce identity management. Specifically, this module focuses on:</p> <ul> <li>Authenticating with Salesforce using a JWT key.</li> <li>Parsing and validating Salesforce SFDX authentication URLs.</li> <li>Authenticating with Salesforce using an SFDX authentication URL.</li> <li>Retrieving the Salesforce Organization ID after successful authentication.</li> </ul>"},{"location":"packages/runtime/docs/services-identity/#key-types-and-interfaces","title":"Key Types and Interfaces","text":"<ul> <li> <p><code>AuthRequest</code>: This structure encapsulates the parameters required for JWT-based authentication. It contains the following fields:</p> <ul> <li><code>ClientID</code>: The Salesforce Connected App Client ID.</li> <li><code>JWTKey</code>: The private key used to generate the JWT.</li> <li><code>Username</code>: The Salesforce username.</li> <li><code>InstanceURL</code>: The Salesforce instance URL (optional).</li> </ul> </li> <li> <p><code>IdentityResolver</code>: This type provides methods for JWT authentication. It interacts directly with the Salesforce CLI (<code>sf</code>) to perform the authentication process.</p> </li> <li> <p><code>Identity</code>: This type provides methods for authenticating using SFDX auth URLs and parsing those URLs. It also interacts with the Salesforce CLI.</p> </li> </ul>"},{"location":"packages/runtime/docs/services-identity/#important-functions","title":"Important Functions","text":"<p><code>NewIdentityResolver()</code>: This function creates and returns a new instance of the <code>IdentityResolver</code> type. You can use this to obtain an instance ready for JWT authentication.</p> <p><code>Authenticate(req AuthRequest)</code>: (Method of <code>IdentityResolver</code>) This function performs JWT-based authentication with Salesforce. It takes an <code>AuthRequest</code> as input and returns the Salesforce Organization ID upon successful authentication, along with any potential error. The process involves:</p> <ol> <li>Sanitizing the JWT key to handle escaped newline characters.</li> <li>Writing the JWT key to a temporary file with restricted permissions (0600).</li> <li>Executing the <code>sf org login jwt</code> command with the provided parameters.</li> <li>Retrying the command up to three times for transient Salesforce API failures, with exponential backoff.</li> <li>Parsing the JSON response from the Salesforce CLI to extract the Organization ID.</li> <li>Securely deleting the temporary JWT key file by overwriting it with zeros before removing it.</li> </ol> <p><code>NewIdentity()</code>: This function creates and returns a new instance of the <code>Identity</code> type. You can use this to obtain an instance ready for SFDX URL authentication.</p> <p><code>ParseAuthURL(authURL string)</code>: (Method of <code>Identity</code>) This function parses and validates a Salesforce SFDX authentication URL. It checks the URL format and validates the instance URL against a regular expression to ensure it is a valid Salesforce domain. It returns the instance URL if the validation is successful.</p> <p><code>AuthenticateWithURL(authURL string)</code>: (Method of <code>Identity</code>) This function authenticates with Salesforce using an SFDX authentication URL. It first validates the URL using <code>ParseAuthURL</code>. Then, it writes the URL to a temporary file, executes the <code>sf org login sfdx-url</code> command, parses the JSON response to extract the Organization ID, and securely deletes the temporary file.</p>"},{"location":"packages/runtime/docs/services-identity/#error-handling","title":"Error Handling","text":"<p>The service employs robust error handling:</p> <ul> <li>Functions return both a result and an error value.</li> <li>Errors are wrapped using <code>fmt.Errorf</code> to provide context and preserve the original error.</li> <li>Transient errors (Salesforce API failures) are handled with retries and exponential backoff.</li> <li>Detailed error messages from the Salesforce CLI are logged for debugging purposes.</li> <li>Temporary files are securely cleaned up even in the event of errors.</li> </ul>"},{"location":"packages/runtime/docs/services-identity/#concurrency","title":"Concurrency","text":"<p>This service does not explicitly use goroutines or channels. However, the <code>exec.Command</code> function used to interact with the Salesforce CLI may execute in a separate process.</p>"},{"location":"packages/runtime/docs/services-identity/#design-decisions","title":"Design Decisions","text":"<ul> <li>Temporary Files: The use of temporary files for storing the JWT key and SFDX auth URL is a security measure to avoid exposing sensitive information in memory or process listings.</li> <li>Secure File Deletion: Overwriting temporary files with zeros before deletion ensures that the data is unrecoverable.</li> <li>Salesforce CLI Dependency: The service relies on the Salesforce CLI (<code>sf</code>) being installed and configured on the system.</li> <li>Retry Mechanism: The retry mechanism for JWT authentication improves resilience to transient Salesforce API failures.</li> <li>Error Wrapping: Wrapping errors provides valuable context for debugging and troubleshooting.</li> </ul>"},{"location":"packages/runtime/docs/services-identity.test/","title":"Services Identity Test","text":""},{"location":"packages/runtime/docs/services-identity.test/#identityresolver-service-documentation","title":"IdentityResolver Service Documentation","text":"<p>This document details the functionality of the <code>IdentityResolver</code> service, responsible for authenticating with Salesforce and retrieving organization (org) information.</p> <p>Overview</p> <p>The <code>IdentityResolver</code> service manages the authentication process against a Salesforce instance. It leverages the Salesforce CLI (<code>sf</code>) to perform the authentication and obtain the org ID and access token.  The service handles secure storage of the JWT key used for authentication and ensures cleanup of this key file, even in the event of authentication failures.</p> <p>Functionality</p> <p>The primary function of this service is the <code>authenticate</code> method. This method accepts authentication request parameters and returns the Salesforce org ID upon successful authentication.</p> <p>Authentication Request Parameters:</p> <ul> <li><code>clientId</code>: A unique identifier for the client application.</li> <li><code>jwtKey</code>: The JSON Web Token (JWT) private key used for authentication. This key is written to a file with restricted permissions (mode 0o600) for security.</li> <li><code>username</code>: The Salesforce username associated with the authentication.</li> <li><code>instanceUrl</code> (Optional): The Salesforce instance URL. If provided, it is included in the authentication command.  If not provided, the service will proceed without it.</li> </ul> <p>Workflow:</p> <ol> <li>JWT Key Storage: Upon receiving an authentication request, the service securely writes the provided <code>jwtKey</code> to a file.</li> <li>Salesforce CLI Execution: The service executes the <code>sf</code> command with appropriate arguments, including the username and optionally the instance URL.</li> <li>Response Parsing: The service parses the JSON response from the <code>sf</code> command, extracting the org ID and access token.</li> <li>Org ID Return:  If authentication is successful, the service returns the extracted org ID.</li> <li>JWT Key Cleanup: Regardless of success or failure, the service attempts to delete the JWT key file to maintain security.  Deletion is skipped if the file does not exist.</li> <li>Error Handling: If the <code>sf</code> command fails, the service throws an \"Authentication Failed\" error.</li> </ol> <p>Dependencies:</p> <ul> <li><code>@actions/exec</code>: Used for executing the Salesforce CLI (<code>sf</code>) command.</li> <li><code>fs</code>: Used for file system operations (writing and deleting the JWT key file).</li> </ul> <p>Testing Considerations:</p> <p>The provided tests verify the following:</p> <ul> <li>Successful authentication and org ID retrieval.</li> <li>Correct inclusion of the instance URL in the <code>sf</code> command when provided.</li> <li>Exclusion of the instance URL when not provided.</li> <li>Error handling for authentication failures.</li> <li>Proper cleanup of the JWT key file in both success and failure scenarios.</li> <li>Prevention of deletion attempts on non-existent key files.</li> </ul> <p>Configuration:</p> <p>You can configure the Salesforce CLI path if it is not in your system's PATH environment variable.  The service relies on the <code>sf</code> command being accessible in the execution environment.</p>"},{"location":"packages/runtime/docs/services-identity_test/","title":"Services identity test","text":""},{"location":"packages/runtime/docs/services-identity_test/#identity-services-package-documentation","title":"Identity Services Package Documentation","text":"<p>This document describes the <code>services</code> package, specifically focusing on identity-related functionality. This package provides components for managing authentication requests and securely handling sensitive data like JWT keys. It is designed to be a foundational element for secure access to external systems.</p> <p>Package Responsibilities:</p> <p>The primary responsibility of this package is to define data structures and associated tests related to authentication and secure key management. It focuses on preparing authentication requests and ensuring the secure handling of JWT keys, including secure deletion practices.</p> <p>Key Types:</p> <ul> <li><code>AuthRequest</code>: This structure represents an authentication request. It contains the following fields:<ul> <li><code>ClientID</code>: A string identifying the client application.</li> <li><code>JWTKey</code>: A string representing the JSON Web Token key.</li> <li><code>Username</code>: A string representing the user's identifier (e.g., email address).</li> <li><code>InstanceURL</code>: A string representing the URL of the instance being accessed. This field is optional and defaults to an empty string if not provided.</li> </ul> </li> </ul> <p>Important Functions:</p> <ul> <li><code>NewIdentityResolver()</code>: This function creates and returns a new instance of the Identity Resolver. The tests confirm it returns a non-nil value, indicating successful initialization.</li> <li><code>os.WriteFile()</code>: Used extensively in testing to write data to temporary files. This function is part of the standard library and is used for creating and populating JWT key files.</li> <li><code>os.Stat()</code>: Used to retrieve file information, such as size and permissions. This is used to verify file creation and permissions during testing.</li> <li><code>os.ReadFile()</code>: Used to read the contents of a file. This is used to verify the content of JWT key files during testing.</li> <li><code>os.Remove()</code>: Used to delete files. This is used in the secure cleanup tests to verify file deletion.</li> </ul> <p>Error Handling:</p> <p>The package employs standard Go error handling practices. Functions return an <code>error</code> value to indicate failure. Tests extensively check for these errors using <code>t.Fatalf()</code> and <code>t.Error()</code>, ensuring that errors are properly detected and handled.  Specific error messages are included in the test failures to aid in debugging.</p> <p>Security Considerations &amp; Design Decisions:</p> <ul> <li>Secure Key Handling: The <code>TestSecureCleanup</code> function demonstrates a secure deletion pattern. Before deleting a file containing sensitive data (like a JWT key), the file's contents are overwritten with zeros. This mitigates the risk of data recovery from residual storage.</li> <li>File Permissions: When creating JWT key files, the code sets file permissions to <code>0600</code> (read/write for the owner only). This restricts access to the key, enhancing security.</li> <li>Temporary Files: The tests use <code>t.TempDir()</code> to create temporary directories for storing test files. This ensures that test files do not interfere with other files on the system and are automatically cleaned up after the tests complete.</li> <li>Default <code>InstanceURL</code>: The <code>AuthRequest</code> type initializes the <code>InstanceURL</code> field to an empty string by default. This allows for flexibility in scenarios where an instance URL is not immediately available or required.</li> </ul> <p>Testing Strategy:</p> <p>The package is thoroughly tested using Go's built-in testing framework. The tests cover the following aspects:</p> <ul> <li>Initialization of the Identity Resolver.</li> <li>Correct population of the <code>AuthRequest</code> structure.</li> <li>Creation and verification of JWT key files, including content and permissions.</li> <li>Secure deletion of sensitive data using the overwrite-with-zeros pattern.</li> <li>Verification of file deletion.</li> </ul> <p>These tests ensure the reliability and security of the identity-related functionality provided by the package.</p>"},{"location":"packages/runtime/docs/services-retry/","title":"Services retry","text":""},{"location":"packages/runtime/docs/services-retry/#retry-service-documentation","title":"Retry Service Documentation","text":"<p>This document describes the <code>retry</code> service, a component designed to provide resilient execution of functions that may fail transiently. We aim to simplify the implementation of retry logic within applications.</p> <p>Package Responsibilities</p> <p>The <code>services</code> package provides a mechanism for automatically retrying function calls with configurable backoff and retry conditions. It handles the complexities of exponential backoff and allows developers to define custom logic for determining whether a retry is appropriate.</p> <p>Key Types</p> <ul> <li><code>RetryOptions</code>: This struct configures the retry behavior.<ul> <li><code>MaxRetries int</code>:  Specifies the maximum number of times the function will be retried.</li> <li><code>BackoffMs int</code>: Defines the initial backoff duration in milliseconds. The actual delay increases exponentially with each retry attempt.</li> <li><code>ShouldRetry func(error) bool</code>: A function that determines whether a retry should be attempted based on the error returned by the function being executed. If nil, all errors will trigger a retry.</li> </ul> </li> </ul> <p>Functions</p> <ul> <li> <p><code>DefaultRetryOptions() RetryOptions</code>: This function returns a <code>RetryOptions</code> struct initialized with sensible default values. The defaults are: <code>MaxRetries</code> set to 3, <code>BackoffMs</code> set to 1000 milliseconds, and <code>ShouldRetry</code> set to a function that always returns true (meaning retry on any error).</p> </li> <li> <p><code>ExecuteWithRetry[T any](fn func() (T, error), opts *RetryOptions) (T, error)</code>: This is the core function of the service. It executes the provided function <code>fn</code> with retry logic.</p> <ul> <li><code>fn func() (T, error)</code>: The function to be executed. It should return a value of type <code>T</code> and an error.</li> <li><code>opts *RetryOptions</code>: A pointer to a <code>RetryOptions</code> struct that configures the retry behavior. If <code>opts</code> is nil, the function uses the default options returned by <code>DefaultRetryOptions()</code>.</li> <li>Returns: The result of the function <code>fn</code> if it succeeds, and a nil error. If the function fails after all retries, it returns the zero value of type <code>T</code> and the last error encountered.</li> </ul> </li> </ul> <p>Error Handling</p> <p>The <code>ExecuteWithRetry</code> function handles errors returned by the provided function <code>fn</code>. It stores the last error encountered and returns it if all retry attempts fail. The <code>ShouldRetry</code> function allows you to customize which errors should trigger a retry. If <code>ShouldRetry</code> is nil, all errors will result in a retry attempt.</p> <p>Concurrency</p> <p>This service does not directly employ goroutines or channels. The <code>time.Sleep</code> function introduces pauses between retries, but these pauses occur within a single goroutine.</p> <p>Design Decisions</p> <ul> <li>Exponential Backoff: We chose exponential backoff to avoid overwhelming the target service with repeated requests immediately after a failure. This strategy provides increasing delays between retries, giving the service time to recover.</li> <li>Configurable Retry Logic: The <code>ShouldRetry</code> function provides flexibility in determining when a retry is appropriate. This allows you to handle specific error conditions differently.</li> <li>Zero Value on Failure: Returning the zero value of type <code>T</code> on failure provides a clear indication that the function did not succeed. You should check the returned error to determine the cause of the failure.</li> <li>Options Pattern: The use of a <code>RetryOptions</code> struct and a default options function promotes configurability and allows for easy extension of the retry behavior in the future.</li> </ul> <p>Usage Example</p> <p>You can use this service as follows:</p> <p>```go result, err := ExecuteWithRetry(func() (string, error) {     // Your function that might fail     return \"Success\", nil // Or return an error }, &amp;RetryOptions{MaxRetries: 5, BackoffMs: 500})</p> <p>if err != nil {     // Handle the error } else {     // Process the result }</p>"},{"location":"packages/runtime/docs/services-retry_test/","title":"Services retry test","text":""},{"location":"packages/runtime/docs/services-retry_test/#retry-service-documentation","title":"Retry Service Documentation","text":"<p>This package provides a service for executing operations with automatic retries, handling transient failures and implementing configurable backoff strategies. It is designed to improve the resilience of operations that may occasionally fail due to temporary issues.</p> <p>Key Types:</p> <ul> <li> <p><code>RetryOptions</code>: This type encapsulates the configuration for the retry mechanism.</p> <ul> <li><code>MaxRetries</code>: An integer defining the maximum number of retry attempts.</li> <li><code>BackoffMs</code>: An integer specifying the initial delay in milliseconds between retries. The delay increases exponentially with each subsequent attempt.</li> <li><code>ShouldRetry</code>: A function that takes an error as input and returns a boolean indicating whether the operation should be retried for that specific error. If this is nil, all errors are retried.</li> </ul> </li> <li> <p><code>testError</code>: A custom error type used in the tests to simulate different error scenarios. It implements the <code>error</code> interface.</p> </li> </ul> <p>Functions:</p> <ul> <li> <p><code>DefaultRetryOptions()</code>: This function returns a <code>RetryOptions</code> struct with default values. The defaults are: <code>MaxRetries</code> set to 3, <code>BackoffMs</code> set to 1000 milliseconds, and <code>ShouldRetry</code> set to nil (meaning all errors will be retried).</p> </li> <li> <p><code>ExecuteWithRetry(operation func() (string, error), options *RetryOptions)</code>: This is the core function of the package. It accepts an operation (a function that returns a string and an error) and optional <code>RetryOptions</code>.</p> <ul> <li>It executes the provided <code>operation</code>.</li> <li>If the operation returns an error, it checks if the error should be retried based on the <code>ShouldRetry</code> function in the <code>options</code>.</li> <li>If the error should be retried, it waits for the specified <code>BackoffMs</code> duration (increasing exponentially with each attempt) and retries the operation up to <code>MaxRetries</code> times.</li> <li>If the operation eventually succeeds, it returns the result and a nil error.</li> <li>If the operation fails after exhausting all retry attempts, it returns an error.</li> </ul> </li> </ul> <p>Error Handling:</p> <p>The <code>ExecuteWithRetry</code> function handles errors returned by the provided operation. The <code>ShouldRetry</code> function within the <code>RetryOptions</code> allows for fine-grained control over which errors trigger a retry. If <code>ShouldRetry</code> is nil, all errors are considered retryable. The package does not perform any specific error type checking beyond what is defined by the <code>ShouldRetry</code> function.</p> <p>Concurrency:</p> <p>This package does not explicitly employ goroutines or channels. The retries are performed sequentially within the <code>ExecuteWithRetry</code> function. The <code>time.Sleep</code> function is used to introduce delays between retries, but this does not involve concurrent execution.</p> <p>Design Decisions:</p> <ul> <li>Configuration via Options: The use of <code>RetryOptions</code> allows for flexible configuration of the retry behavior without requiring changes to the core <code>ExecuteWithRetry</code> function.</li> <li>Functional Approach: The <code>operation</code> is passed as a function, promoting a functional programming style and making the retry service reusable with different operations.</li> <li>Exponential Backoff: The backoff strategy increases the delay between retries, reducing the load on the failing service and potentially allowing it to recover.</li> <li><code>ShouldRetry</code> Function: This function provides a powerful mechanism for controlling which errors are retried, preventing infinite loops for non-transient failures.</li> </ul> <p>Usage:</p> <p>You can use this package to wrap operations that may be prone to transient failures. For example:</p> <p>```go result, err := ExecuteWithRetry(func() (string, error) {     // Your operation here     return \"data\", nil // or return \"\", error }, &amp;RetryOptions{     MaxRetries: 5,     BackoffMs: 500,     ShouldRetry: func(err error) bool {         // Check if the error is retryable         return true     }, })</p> <p>if err != nil {     // Handle the error } else {     // Process the result }</p>"},{"location":"packages/runtime/docs/src-index/","title":"Source Index","text":""},{"location":"packages/runtime/docs/src-index/#glassops-runtime-architecture-overview","title":"GlassOps Runtime \u2013 Architecture Overview","text":"<p>This document details the architecture and functionality of the GlassOps Runtime, a tool designed to provide a governed and secure execution environment for Salesforce development operations. It outlines the core components, operational flow, and key considerations for its use.</p> <p>1. Introduction</p> <p>The GlassOps Runtime establishes a framework for automating Salesforce deployments and changes while enforcing organizational governance policies. It focuses on security, compliance, and operational integrity throughout the entire process.</p> <p>2. Core Components</p> <ul> <li>Policy Engine: Responsible for evaluating and enforcing pre-defined governance rules. This includes freeze windows, code quality standards, and access controls.</li> <li>Runtime Environment: Manages the Salesforce CLI (SFDX) installation and plugin dependencies, ensuring a consistent and reliable execution environment.</li> <li>Identity Resolver: Handles authentication with Salesforce organizations, securely managing credentials and establishing trust.</li> <li>Analyzer: Performs static code analysis to identify potential vulnerabilities and ensure adherence to coding best practices.</li> <li>Deployment Contract: A structured document that captures the state of the deployment, including quality metrics, audit information, and compliance status.</li> <li>Error Handling: A custom error hierarchy (GlassOpsError, PolicyError, BootstrapError, IdentityError, ContractError) provides specific categorization for improved debugging and issue resolution.</li> </ul> <p>3. Operational Flow</p> <p>The runtime operates through a series of phases:</p> <ol> <li>Environment Validation: Checks for the presence of required environment variables (e.g., <code>GITHUB_WORKSPACE</code>, <code>GITHUB_ACTOR</code>, <code>GITHUB_REPOSITORY</code>) and input parameters (e.g., <code>client_id</code>, <code>jwt_key</code>, <code>username</code>).</li> <li>Policy Evaluation: Loads and evaluates governance policies, potentially halting execution if violations are detected. Static code analysis is performed if enabled.</li> <li>Bootstrap: Installs or updates the Salesforce CLI and any required plugins. Caching mechanisms are used to optimize performance.</li> <li>Identity Resolution: Authenticates with the target Salesforce organization using provided credentials. Authentication can be skipped for testing purposes.</li> <li>Contract Generation: Creates a Deployment Contract containing metadata about the deployment, quality metrics (code coverage, test results), and audit information.</li> <li>Output: Sets output variables for downstream processes, including the generated contract path and the Salesforce organization ID.</li> </ol> <p>4. Key Features &amp; Considerations</p> <ul> <li>Security: Emphasizes secure credential management, input validation, and compliance checks.</li> <li>Governance: Enforces organizational policies through the Policy Engine, preventing unauthorized or risky deployments.</li> <li>Caching: Improves performance by caching dependencies and reducing redundant downloads.</li> <li>Extensibility: Designed to be extensible through plugins and configurable policies.</li> <li>Error Handling: Provides detailed error messages and categorization for easier troubleshooting.</li> <li>Rate Limiting: Includes a placeholder for future implementation of rate limiting and concurrency controls.</li> <li>Timeout Mechanism: Implements a safety timeout to prevent indefinite execution.</li> <li>Forked Repository Handling: Provides a warning when running in forked repositories, recommending additional security validations.</li> </ul> <p>5. Configuration</p> <p>You can configure the runtime using input parameters:</p> <ul> <li><code>client_id</code>: Salesforce Connected App Client ID.</li> <li><code>jwt_key</code>: Salesforce JWT Key.</li> <li><code>username</code>: Salesforce Username.</li> <li><code>instance_url</code>: Salesforce instance URL (defaults to <code>https://login.salesforce.com</code>).</li> <li><code>enforce_policy</code>: Enables or disables policy enforcement (defaults to enabled).</li> <li><code>plugins</code>: Comma-separated list of Salesforce CLI plugins to install.</li> <li><code>test_results</code>: JSON string containing test results data.</li> <li><code>coverage_percentage</code>: Code coverage percentage.</li> <li><code>coverage_required</code>: Required code coverage percentage.</li> <li><code>skip_auth</code>: Skips Salesforce authentication (for testing only).</li> </ul> <p>6. Outputs</p> <p>The runtime provides the following outputs:</p> <ul> <li><code>runtime_id</code>: A unique identifier for the execution session.</li> <li><code>org_id</code>: The Salesforce organization ID.</li> <li><code>contract_path</code>: The path to the generated Deployment Contract.</li> <li><code>is_locked</code>: Indicates whether a policy freeze window is active.</li> <li><code>glassops_ready</code>: Indicates successful runtime initialization.</li> </ul>"},{"location":"packages/runtime/docs/telemetry-telemetry/","title":"Telemetry telemetry","text":""},{"location":"packages/runtime/docs/telemetry-telemetry/#glassops-runtime-telemetry-package-documentation","title":"glassops Runtime Telemetry Package Documentation","text":"<p>This package provides integration with OpenTelemetry for distributed tracing within the glassops runtime environment. It allows for the monitoring and analysis of application performance and behavior.</p> <p>Package Responsibilities:</p> <p>The primary responsibility of this package is to initialize, manage, and provide access to an OpenTelemetry tracer. It handles the configuration of the tracer based on environment variables, the creation of spans to track operations, and the reporting of trace data to a configured backend.</p> <p>Key Types and Interfaces:</p> <ul> <li><code>trace.Tracer</code>:  The core OpenTelemetry interface for creating and managing traces and spans.  We use this to start new tracing spans.</li> <li><code>trace.Span</code>: Represents a single operation within a trace.  Spans are used to measure the duration and attributes of specific code sections.</li> <li><code>sdktrace.TracerProvider</code>:  Manages the lifecycle of tracers and exporters.  It is responsible for configuring and shutting down the tracing pipeline.</li> <li><code>attribute.KeyValue</code>: Represents a key-value pair used to add metadata to spans and events.</li> </ul> <p>Important Functions:</p> <ul> <li><code>Init(ctx context.Context, serviceName, serviceVersion string) error</code>:   This function initializes the OpenTelemetry SDK. It checks for the <code>OTEL_EXPORTER_OTLP_ENDPOINT</code> environment variable. If this variable is set, it configures an OpenTelemetry exporter to send trace data to the specified endpoint. It also sets service name and version attributes. If the environment variable is not set, telemetry is disabled, and the function returns nil. It also parses optional headers from the <code>OTEL_EXPORTER_OTLP_HEADERS</code> environment variable.</li> <li><code>Shutdown(ctx context.Context) error</code>:   This function gracefully shuts down the OpenTelemetry tracer provider, releasing resources and flushing any pending trace data. It returns an error if shutdown fails; otherwise, it returns nil.</li> <li><code>WithSpan[T any](ctx context.Context, name string, fn func(context.Context, trace.Span) (T, error), attrs ...attribute.KeyValue) (T, error)</code>:   This is a utility function for executing a function within a traced span. It starts a new span with the given name and attributes, executes the provided function with the span context, and ensures the span is ended (regardless of success or failure). If the function returns an error, the span's status is set to <code>Error</code>; otherwise, it's set to <code>Ok</code>.  You pass a function <code>fn</code> that accepts a <code>context.Context</code> and a <code>trace.Span</code> as arguments.</li> <li><code>GetCurrentSpan(ctx context.Context) trace.Span</code>:   This function retrieves the currently active span from the provided context. It returns nil if no span is active in the context.</li> <li><code>AddSpanEvent(ctx context.Context, name string, attrs ...attribute.KeyValue)</code>:   This function adds an event to the current span.  It retrieves the current span from the context and adds an event with the given name and attributes. If no span is present in the context, the function does nothing.</li> </ul> <p>Error Handling:</p> <p>The package employs standard Go error handling practices. Functions return an <code>error</code> value to indicate failure. Errors are typically wrapped and propagated to provide context. Within <code>WithSpan</code>, errors from the executed function are recorded on the span using <code>span.RecordError</code> and the span status is set accordingly.</p> <p>Concurrency:</p> <p>The OpenTelemetry SDK itself is designed to be concurrency-safe. This package leverages that inherent safety.  The <code>WithSpan</code> function is safe to be called concurrently from multiple goroutines.</p> <p>Design Decisions:</p> <ul> <li>Conditional Initialization: Telemetry is only initialized if the <code>OTEL_EXPORTER_OTLP_ENDPOINT</code> environment variable is set. This allows for easy disabling of tracing in environments where it is not desired or necessary.</li> <li>Environment Variable Configuration: The package relies on environment variables for configuration, making it easy to adapt to different deployment environments without code changes.</li> <li>Context Propagation:  The package utilizes Go's context mechanism to propagate trace context across function calls and goroutines.</li> <li>Generic <code>WithSpan</code> Function: The <code>WithSpan</code> function is implemented using generics to provide type safety and flexibility.</li> </ul>"},{"location":"packages/runtime/docs/telemetry-telemetry_test/","title":"Telemetry telemetry test","text":""},{"location":"packages/runtime/docs/telemetry-telemetry_test/#telemetry-package-documentation","title":"Telemetry Package Documentation","text":"<p>This package provides functionality for integrating OpenTelemetry tracing into applications. It handles initialization, shutdown, and basic operations for interacting with spans and events. The primary goal is to offer a simple and resilient telemetry solution, even in environments where a full tracing backend is not configured.</p> <p>Key Responsibilities:</p> <ul> <li>Initialization of the OpenTelemetry tracer.</li> <li>Graceful shutdown of the OpenTelemetry tracer.</li> <li>Retrieval of the current span from a given context.</li> <li>Adding events to the current span.</li> <li>Executing a function within the context of a new span.</li> </ul> <p>Key Types:</p> <ul> <li><code>testError</code>: A custom error type used solely for testing purposes to simulate errors within span operations. It implements the <code>error</code> interface.</li> </ul> <p>Important Functions:</p> <ul> <li><code>Init(ctx context.Context, serviceName string, version string) error</code>: This function initializes the OpenTelemetry tracer. It takes the context, service name, and version as input. If the <code>OTEL_EXPORTER_OTLP_ENDPOINT</code> environment variable is not set, it initializes the tracer without a configured exporter, resulting in a no-op tracer.  It returns an error if initialization fails, but is designed to succeed silently when no endpoint is provided.</li> <li><code>Shutdown(ctx context.Context) error</code>: This function shuts down the OpenTelemetry tracer. It gracefully stops the tracer and releases resources. It does not panic if the tracer was never initialized. It returns an error if shutdown fails, but will succeed if the tracer was never initialized.</li> <li><code>GetCurrentSpan(ctx context.Context) trace.Span</code>: This function retrieves the current span associated with the given context. If no span is active in the context, it returns a no-op span, preventing panics.</li> <li><code>AddSpanEvent(ctx context.Context, name string)</code>: This function adds an event to the current span. If no span is active, it does nothing and does not return an error.</li> <li><code>WithSpan(ctx context.Context, name string, fn func(context.Context, trace.Span) (string, error)) (string, error)</code>: This function executes the provided function <code>fn</code> within the context of a new span. It automatically starts and ends the span. The function takes the context, span name, and a function as input. It returns the result of the function and any error that occurred during its execution. If the tracer is not initialized, it still executes the function without creating a span.</li> </ul> <p>Error Handling:</p> <p>The package employs standard Go error handling practices. Functions return an <code>error</code> value to indicate failure. The <code>testError</code> type is used in tests to simulate specific error conditions.  The <code>WithSpan</code> function propagates errors returned by the provided function.</p> <p>Concurrency:</p> <p>The OpenTelemetry SDK handles concurrency internally. This package itself does not explicitly manage goroutines or channels, but relies on the concurrent safety of the underlying OpenTelemetry APIs.</p> <p>Design Decisions:</p> <ul> <li>Resilience to Missing Configuration: The <code>Init</code> function is designed to operate without a configured OpenTelemetry endpoint. This allows applications to run in environments where tracing is not yet set up without crashing.</li> <li>No-Op Behavior:  Functions like <code>GetCurrentSpan</code> and <code>AddSpanEvent</code> are designed to gracefully handle cases where a span is not active, preventing panics.</li> <li>Simplified Interface: The package provides a minimal set of functions to cover common tracing use cases, keeping the API simple and easy to use.</li> <li>Testability: The inclusion of the <code>testError</code> type facilitates unit testing of error handling scenarios.</li> </ul>"},{"location":"packages/runtime/docs/tsconfig/","title":"<code>tsconfig.json</code> Documentation - Runtime Package","text":"<p>This document details the <code>tsconfig.json</code> file located in the <code>packages/runtime</code> directory. This file configures the TypeScript compiler for the runtime package, defining how TypeScript code is transpiled into JavaScript. It is a crucial component of the build process, ensuring code quality and compatibility.</p>"},{"location":"packages/runtime/docs/tsconfig/#data-representation","title":"Data Representation","text":"<p>This JSON object represents the configuration settings for the TypeScript compiler. It dictates how the TypeScript code within the <code>src</code> directory is processed and outputted to the <code>lib</code> directory.  The configuration controls aspects like target JavaScript version, module system, and type checking strictness.</p>"},{"location":"packages/runtime/docs/tsconfig/#schema-details","title":"Schema Details","text":"<p>The <code>tsconfig.json</code> file is structured with two primary top-level keys: <code>compilerOptions</code> and <code>include</code>/<code>exclude</code>.</p>"},{"location":"packages/runtime/docs/tsconfig/#compileroptions-required","title":"<code>compilerOptions</code> (Required)","text":"<p>This object contains settings that control the compilation process.  Each key-value pair within <code>compilerOptions</code> defines a specific compiler behavior.</p> <ul> <li><code>target</code> (Required):  Specifies the ECMAScript target version for the output JavaScript.  <code>\"ES2020\"</code> indicates the generated JavaScript will be compatible with ECMAScript 2020 features.</li> <li><code>module</code> (Required):  Determines the module code generation style. <code>\"CommonJS\"</code> specifies that the output will use the CommonJS module system, suitable for Node.js environments.</li> <li><code>moduleResolution</code> (Required):  Specifies how the compiler resolves module imports. <code>\"node\"</code> instructs the compiler to use the Node.js module resolution algorithm.</li> <li><code>baseUrl</code> (Required):  Sets the base directory to resolve non-relative module names. <code>\"./\"</code> indicates that module resolution should start from the current directory.</li> <li><code>paths</code> (Required):  Allows mapping of module names to specific locations. <code>\"*\": [\"node_modules/*\"]</code> maps all module names to their corresponding locations within the <code>node_modules</code> directory.</li> <li><code>outDir</code> (Required):  Specifies the output directory for the compiled JavaScript files. <code>\"./lib\"</code> indicates that the compiled files will be placed in a <code>lib</code> directory in the current directory.</li> <li><code>rootDir</code> (Required):  Specifies the root directory of the source files. <code>\"./src\"</code> indicates that the source files are located in the <code>src</code> directory.</li> <li><code>strict</code> (Required):  Enables all strict type-checking options. <code>\"true\"</code> enforces rigorous type checking, improving code reliability.</li> <li><code>noImplicitAny</code> (Required):  Raises an error when a variable or parameter does not have an explicit type and the compiler cannot infer one. <code>\"true\"</code> helps prevent unexpected behavior due to implicit <code>any</code> types.</li> <li><code>esModuleInterop</code> (Required):  Enables interoperability between CommonJS and ES modules. <code>\"true\"</code> allows importing CommonJS modules as if they were ES modules.</li> <li><code>forceConsistentCasingInFileNames</code> (Required):  Ensures that file names are consistently cased across different operating systems. <code>\"true\"</code> prevents issues caused by case-sensitive file systems.</li> <li><code>skipLibCheck</code> (Required):  Skips type checking of declaration files (<code>.d.ts</code>). <code>\"true\"</code> can improve compilation speed, especially when working with large projects and external libraries.</li> </ul>"},{"location":"packages/runtime/docs/tsconfig/#include-required","title":"<code>include</code> (Required)","text":"<p>This array specifies the files or patterns of files to be included in the compilation process.</p> <ul> <li><code>[\"src/**/*\"]</code>: Includes all TypeScript files (<code>.ts</code> and <code>.tsx</code>) recursively within the <code>src</code> directory.</li> </ul>"},{"location":"packages/runtime/docs/tsconfig/#exclude-required","title":"<code>exclude</code> (Required)","text":"<p>This array specifies the files or patterns of files to be excluded from the compilation process.</p> <ul> <li><code>[\"node_modules\"]</code>: Excludes the <code>node_modules</code> directory, preventing the compilation of third-party libraries.</li> <li><code>[\"**/*.test.ts\"]</code>: Excludes all files ending with <code>.test.ts</code>, typically used for unit tests, from the compilation process.</li> </ul>"},{"location":"packages/runtime/docs/tsconfig/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Building the Runtime Package: This <code>tsconfig.json</code> is used during the build process to transpile TypeScript code into JavaScript, preparing the runtime package for distribution and use.</li> <li>Type Checking: The strict type-checking options ensure code quality and prevent runtime errors.</li> <li>Module Resolution: The <code>moduleResolution</code> and <code>paths</code> settings ensure that modules are resolved correctly, allowing the code to import and use dependencies.</li> <li>Development Workflow:  The configuration supports a smooth development workflow by automatically compiling and type-checking code as it is modified.</li> </ul>"},{"location":"packages/runtime/docs/types-config.d/","title":"Types Config","text":""},{"location":"packages/runtime/docs/types-config.d/#glassops-configuration-document","title":"GlassOps Configuration Document","text":"<p>This document details the structure and options available within the GlassOps configuration file. This configuration governs the behavior of the system, defining execution parameters, governance policies, environment settings, and notification preferences.</p> <p>1. Core Configuration</p> <ul> <li>version: (String, required) Specifies the configuration schema version. Currently set to \"1.0\".</li> <li>metadata: (Object, optional) Contains information about the configuration itself.<ul> <li>last_updated: (String, optional) Timestamp indicating the last modification date.</li> <li>schema_version: (String, optional) Version of the schema used for this configuration.</li> </ul> </li> </ul> <p>2. Execution Settings</p> <ul> <li>engine: (String, required) Determines the execution engine used by GlassOps. Options are:<ul> <li>native:  Uses the native execution environment.</li> <li>hardis: Uses the Hardis execution environment.</li> </ul> </li> <li>fallback: (String, optional) Specifies a fallback engine in case the primary engine fails. Options are:<ul> <li>native: Fallback to the native execution environment.</li> <li>none: No fallback engine is used.</li> </ul> </li> </ul> <p>3. Governance Policies</p> <p>These settings define the quality and security standards enforced by GlassOps.</p> <ul> <li>minCoverage: (Number, required) Minimum code coverage percentage required for successful execution.</li> <li>requireTests: (Boolean, required)  Indicates whether tests are mandatory for execution.</li> <li>enforcedBy: (String, optional) Identifies the entity responsible for enforcing these governance policies. This is primarily for documentation and audit purposes.</li> </ul> <p>4. Environment Configurations</p> <p>This section allows defining configurations for different environments (e.g., development, staging, production).</p> <ul> <li>Each key represents a unique environment name.</li> <li>display_name: (String, optional) A user-friendly name for the environment.</li> <li>branch_mapping: (String, optional) Maps a Git branch to this environment.</li> <li>deployment_policy: (Object, optional) Controls the deployment process for this environment.<ul> <li>test_level: (String, optional) Specifies the required test level.</li> <li>wait_time: (String, optional) Defines a waiting period before deployment.</li> <li>use_delta: (Boolean, optional) Indicates whether to deploy only changes since the last deployment.</li> <li>validation_required: (Boolean, optional) Specifies if validation steps are needed before deployment.</li> <li>auto_deploy_on_merge: (Boolean, optional) Enables automatic deployment upon merging into the mapped branch.</li> </ul> </li> <li>quality_gates: (Object, optional) Defines quality criteria that must be met before deployment.<ul> <li>minCoverage: (Number, optional) Minimum code coverage for this environment.</li> <li>security_severity_threshold: (Number, optional) Maximum allowed security severity level.</li> <li>block_on_test_failure: (Boolean, optional) Prevents deployment if tests fail.</li> </ul> </li> <li>github_environment: (String, optional) Links this environment to a GitHub environment.</li> <li>notes: (String, optional)  Allows adding descriptive notes about the environment.</li> </ul> <p>5. GlassOps Specific Settings</p> <ul> <li>glassops: (Object, optional) Contains settings specific to the GlassOps platform.<ul> <li>enablePlatformEvents: (Boolean, optional) Enables or disables platform event emission.</li> </ul> </li> </ul> <p>6. Notification Settings</p> <ul> <li>notifications: (Object, optional) Configures notification behavior.<ul> <li>enabled_by_default: (Boolean, optional) Enables notifications globally by default.</li> <li>channels: (Object, optional) Defines notification channels.<ul> <li>slack: (Object, optional) Configures Slack notifications.<ul> <li>enabled: (Boolean, optional) Enables Slack notifications.</li> <li>mention_on_failure: (Boolean, optional) Mentions specific users in Slack upon failure.</li> </ul> </li> <li>email: (Object, optional) Configures email notifications.<ul> <li>enabled: (Boolean, optional) Enables email notifications.</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>7. Extensibility</p> <ul> <li>The configuration supports arbitrary extensions. You can add custom keys and values to the root object to extend functionality. These extensions are not validated by the core schema.</li> </ul>"},{"location":"packages/runtime/docs/types-contract.d/","title":"Types Contract","text":""},{"location":"packages/runtime/docs/types-contract.d/#deployment-contract-specification","title":"Deployment Contract Specification","text":"<p>This document details the structure of the Deployment Contract, a central data object representing the outcome of a deployment process. It provides a comprehensive record of the deployment\u2019s execution, quality, policy compliance, and audit information. This contract is designed for both automated systems and human review.</p> <p>1. Overview</p> <p>The Deployment Contract encapsulates all relevant information pertaining to a deployment, from initial trigger to final status. It facilitates transparency, accountability, and informed decision-making throughout the software delivery lifecycle.</p> <p>2. Contract Structure</p> <p>The contract is organized into the following key sections:</p> <p>2.1. meta</p> <p>Contains metadata about the deployment process itself.</p> <ul> <li><code>adapter</code>: The name of the adapter used for deployment.</li> <li><code>engine</code>: The deployment engine used.</li> <li><code>engineVersion</code>: The version of the deployment engine.</li> <li><code>timestamp</code>: The date and time of the deployment.</li> <li><code>trigger</code>: The event that initiated the deployment.</li> </ul> <p>2.2. status</p> <p>Indicates the overall outcome of the deployment. Possible values:</p> <ul> <li><code>Succeeded</code>: The deployment completed successfully.</li> <li><code>Failed</code>: The deployment failed.</li> <li><code>Canceled</code>: The deployment was canceled.</li> <li><code>Partial</code>: The deployment completed with some failures.</li> </ul> <p>2.3. deployment</p> <p>Details specific to the deployment execution.</p> <ul> <li><code>id</code>: A unique identifier for the deployment.</li> <li><code>url</code>: (Optional) A URL pointing to the deployment details.</li> <li><code>mode</code>: The deployment mode used: <code>validate</code>, <code>deploy</code>, or <code>quick_deploy</code>.</li> <li><code>validationId</code>: (Optional) The ID of the validation run associated with this deployment.</li> <li><code>metrics</code>: Quantitative data about the deployment.<ul> <li><code>componentsDeployed</code>: The number of components successfully deployed.</li> <li><code>componentsFailed</code>: The number of components that failed to deploy.</li> <li><code>testsRun</code>: The number of tests executed.</li> <li><code>durationMs</code>: The total duration of the deployment in milliseconds.</li> </ul> </li> </ul> <p>2.4. quality</p> <p>Assesses the quality of the deployed code.</p> <ul> <li><code>coverage</code>: Code coverage metrics.<ul> <li><code>actual</code>: The actual code coverage achieved.</li> <li><code>required</code>: The required code coverage threshold.</li> <li><code>met</code>: A boolean indicating whether the required coverage was met.</li> <li><code>details</code>: (Optional) Granular coverage details.<ul> <li><code>orgWideCoverage</code>: Coverage across the entire organization.</li> <li><code>packageCoverage</code>: Coverage for a specific package.</li> </ul> </li> </ul> </li> <li><code>staticAnalysis</code>: Results from static code analysis tools.<ul> <li><code>toolsUsed</code>: An array of tools used for static analysis.</li> <li><code>score</code>: An overall health score from the analysis.</li> <li><code>criticalViolations</code>: The number of critical violations found (e.g., security risks).</li> <li><code>warningViolations</code>: The number of warning violations found (e.g., potential technical debt).</li> <li><code>topIssues</code>: (Optional) An array of the most significant issues identified, including file, rule, severity, line number, and message.</li> </ul> </li> </ul> <p>2.5. policy</p> <p>Information related to policy enforcement.</p> <ul> <li><code>source</code>: Details about the source of the policy rules.<ul> <li><code>githubFloor</code>: Policy configuration from GitHub.</li> <li><code>configFile</code>: Policy configuration from a configuration file.</li> <li><code>salesforceCmdt</code>: Policy configuration from Salesforce CMT.</li> </ul> </li> <li><code>effective</code>: The effective policy version applied during deployment.</li> <li><code>overrides</code>: (Optional) An array of policy overrides, including the reason and approver.</li> </ul> <p>2.6. audit</p> <p>Provides audit trail information.</p> <ul> <li><code>triggeredBy</code>: The user or system that triggered the deployment.</li> <li><code>repository</code>: The repository containing the code.</li> <li><code>ref</code>: The branch or tag used for the deployment.</li> <li><code>commit</code>: The commit hash of the deployed code.</li> <li><code>runUrl</code>: A URL to the deployment run details.</li> </ul> <p>2.7. errors</p> <p>(Optional) An array of errors encountered during the deployment.</p> <ul> <li><code>code</code>: An error code.</li> <li><code>message</code>: A descriptive error message.</li> <li><code>severity</code>: The severity of the error (<code>Critical</code> or <code>Warning</code>).</li> <li><code>component</code>: (Optional) The component associated with the error.</li> </ul> <p>2.8. extensions</p> <p>(Optional) A flexible section for adding custom data. This allows for extending the contract with additional information specific to your environment. You can add any key-value pair here.</p> <p>3. Usage</p> <p>I generate this contract after each deployment attempt. You can use this data for reporting, analysis, and automated remediation. The contract\u2019s standardized format enables integration with various tools and systems.</p>"},{"location":"packages/runtime/docs/validator-validator/","title":"Validator validator","text":""},{"location":"packages/runtime/docs/validator-validator/#package-validator-documentation","title":"Package validator Documentation","text":"<p>This package is responsible for validating the environment, inputs, and context in which the application operates. It ensures that necessary conditions are met before proceeding with core functionality, enhancing reliability and security. We aim to provide clear and actionable error messages when validation fails.</p>"},{"location":"packages/runtime/docs/validator-validator/#key-types-and-interfaces","title":"Key Types and Interfaces","text":"<p>This package does not define any custom types or interfaces. It relies on standard Go types like strings and errors.</p>"},{"location":"packages/runtime/docs/validator-validator/#functions","title":"Functions","text":"<p><code>ValidateEnvironment()</code></p> <p>This function verifies the presence of essential environment variables. It checks for <code>GITHUB_WORKSPACE</code>, <code>GITHUB_ACTOR</code>, and <code>GITHUB_REPOSITORY</code>. If any of these variables are not set, it returns an error listing the missing variables. Otherwise, it returns nil, indicating successful validation.</p> <p>Example:</p> <p>If <code>GITHUB_WORKSPACE</code> is not set, the function returns an error message similar to: <code>missing required environment variables: GITHUB_WORKSPACE</code>.</p> <p><code>ValidateInputs()</code></p> <p>This function validates required inputs obtained from the GitHub Actions environment. It checks for the existence of <code>client_id</code>, <code>jwt_key</code>, and <code>username</code> inputs using the <code>gha.GetInput()</code> function. If any input is missing, it returns an error listing the missing inputs. Additionally, it performs a basic format check on the <code>jwt_key</code>. If <code>skip_auth</code> is not set to \"true\", it verifies that the <code>jwt_key</code> contains both \"BEGIN\" and \"END\" markers. If the key is valid and not empty, it is set as a secret using <code>gha.SetSecret()</code>.</p> <p>Example:</p> <p>If <code>client_id</code> is missing, the function returns an error message similar to: <code>missing required inputs: client_id</code>.</p> <p><code>ValidateContext()</code></p> <p>This function validates the context of the execution, specifically checking for pull request and repository validity. If the <code>GITHUB_EVENT_NAME</code> is <code>pull_request</code>, it verifies the presence of the <code>GITHUB_HEAD_REF</code> environment variable. If <code>GITHUB_HEAD_REF</code> is missing, it returns an error. It also issues a warning via <code>gha.Warning()</code> if the pull request originates from a forked repository, recommending additional security validations.  It validates the format of the <code>GITHUB_REPOSITORY</code> environment variable using a regular expression to ensure it conforms to the expected <code>owner/repository</code> structure.</p> <p>Example:</p> <p>If <code>GITHUB_HEAD_REF</code> is missing during a pull request event, the function returns an error message: <code>invalid pull request context - missing GITHUB_HEAD_REF</code>.</p> <p><code>EnsureValidInstanceURL(url string) error</code></p> <p>This function validates a provided Salesforce instance URL. It checks if the URL's length is greater than 8 characters and if it begins with either \"http://\" or \"https://\". If either of these conditions is not met, it returns an error indicating an invalid URL. Otherwise, it returns nil.</p> <p>Example:</p> <p>If the provided URL is \"example\", the function returns an error message similar to: <code>invalid instance URL: example</code>.</p>"},{"location":"packages/runtime/docs/validator-validator/#error-handling","title":"Error Handling","text":"<p>The package consistently uses the <code>error</code> type for signaling validation failures. Error messages are formatted to be informative, clearly indicating which variables or inputs are missing or invalid.  The <code>fmt.Errorf()</code> function is used to create error messages, allowing for dynamic inclusion of relevant details like missing variable names or invalid URL values.</p>"},{"location":"packages/runtime/docs/validator-validator/#concurrency","title":"Concurrency","text":"<p>This package does not employ goroutines or channels. All operations are performed synchronously.</p>"},{"location":"packages/runtime/docs/validator-validator/#design-decisions","title":"Design Decisions","text":"<ul> <li>Separation of Concerns: The validation logic is divided into separate functions, each responsible for a specific aspect of validation (environment, inputs, context, URL). This promotes modularity and maintainability.</li> <li>Clear Error Messages:  We prioritize providing clear and specific error messages to assist users in quickly identifying and resolving validation issues.</li> <li>GitHub Actions Integration: The package is designed to work seamlessly within a GitHub Actions environment, leveraging environment variables and input parameters provided by the platform.</li> <li>Basic JWT Key Validation: The JWT key validation is intentionally basic, checking only for the presence of \"BEGIN\" and \"END\" markers. More robust validation might be considered in the future, but this provides a reasonable initial check.</li> </ul>"},{"location":"packages/runtime/docs/validator-validator_test/","title":"Validator validator test","text":""},{"location":"packages/runtime/docs/validator-validator_test/#runtime-validator-package-documentation","title":"Runtime Validator Package Documentation","text":"<p>This package provides functions for validating the environment and specific configuration values used within the runtime. It ensures that necessary environment variables are present and that provided URLs conform to expected formats.</p> <p>Key Responsibilities:</p> <ul> <li>Environment validation: Checks for the existence of required environment variables.</li> <li>URL validation: Verifies that provided instance URLs are in a valid format.</li> </ul> <p>Key Types and Interfaces:</p> <p>This package does not define any custom types or interfaces. It operates directly on primitive types like strings and errors.</p> <p>Important Functions:</p> <ul> <li> <p><code>ValidateEnvironment()</code>: This function validates the presence of essential environment variables. Specifically, it checks for <code>GITHUB_WORKSPACE</code>, <code>GITHUB_ACTOR</code>, and <code>GITHUB_REPOSITORY</code>. If any of these variables are not set, it returns an error. Otherwise, it returns nil, indicating a successful validation. We designed this to ensure the application is running within a supported environment, such as a CI/CD pipeline.</p> <pre><code>func ValidateEnvironment() error\n</code></pre> </li> <li> <p><code>EnsureValidInstanceURL(url string) error</code>: This function validates a given URL string, checking if it represents a potentially valid instance URL. Currently, it accepts URLs with <code>https</code>, <code>http</code>, and even <code>ftp</code> schemes, but flags <code>ftp</code> as invalid. It returns an error if the URL is empty or does not appear to be a valid URL format. We allow <code>http</code> for flexibility, but this may be revisited in future versions.</p> <pre><code>func EnsureValidInstanceURL(url string) error\n</code></pre> </li> </ul> <p>Error Handling:</p> <p>Both <code>ValidateEnvironment()</code> and <code>EnsureValidInstanceURL()</code> return an <code>error</code> value to indicate validation failures.  If a validation check fails, a non-nil error is returned, providing information about the reason for the failure.  If a check passes, a nil error is returned.</p> <p>Concurrency:</p> <p>This package does not employ any concurrency patterns (goroutines or channels). The functions are designed to be executed synchronously.</p> <p>Design Decisions:</p> <ul> <li>Environment Variable Validation: We chose to explicitly check for specific environment variables rather than relying on more generic approaches. This provides clear and targeted validation for the runtime's dependencies.</li> <li>URL Validation Flexibility: The current URL validation allows <code>http</code> URLs. This decision was made to accommodate a wider range of configurations, but it\u2019s important to note that this might be tightened in the future for security reasons.</li> <li>Testability: The package is designed with testability in mind, as demonstrated by the included unit tests. The tests cover both success and failure scenarios for each validation function.</li> <li>Test Setup/Teardown: The <code>TestValidateEnvironment</code> function uses <code>defer</code> to restore the original environment variables after each test case. This ensures that tests do not interfere with each other or the system's environment. You should be aware that tests modify environment variables temporarily.</li> </ul>"},{"location":"packages/runtime/docs/workflows-integration-tests/","title":"Integration Tests Workflow Documentation","text":"<p>This document details the <code>integration-tests.yml</code> workflow file, which automates the integration testing process for the project.</p>"},{"location":"packages/runtime/docs/workflows-integration-tests/#purpose","title":"Purpose","text":"<p>The primary goal of this workflow is to ensure the quality and stability of the project's code by running integration tests on various environments. It covers unit and integration tests, generates coverage reports, and performs end-to-end testing of an action.</p>"},{"location":"packages/runtime/docs/workflows-integration-tests/#workflow-triggers","title":"Workflow Triggers","text":"<p>The workflow is triggered by the following events:</p> <ul> <li><code>push</code> to <code>main</code> branch: When code is pushed to the <code>main</code> branch, the workflow runs if the changes are in the <code>src</code>, <code>config</code>, <code>package.json</code>, <code>tsconfig.json</code>, or <code>.github/workflows/integration-tests.yml</code> directories.</li> <li><code>pull_request</code> to <code>main</code> branch: When a pull request is created or updated targeting the <code>main</code> branch.</li> <li><code>workflow_dispatch</code>: Allows manual triggering of the workflow with an optional <code>debug</code> input.</li> </ul>"},{"location":"packages/runtime/docs/workflows-integration-tests/#jobs","title":"Jobs","text":"<p>The workflow consists of the following jobs:</p>"},{"location":"packages/runtime/docs/workflows-integration-tests/#1-integration-tests","title":"1. <code>integration-tests</code>","text":"<ul> <li>Name: Integration Test Suite</li> <li>Runs on: <code>ubuntu-latest</code></li> <li>Purpose: Executes the core integration tests.</li> <li>Steps:<ul> <li>Checkout Repository: Checks out the project's code.</li> <li>Setup Node.js: Sets up the Node.js environment with version 20 and enables npm caching.</li> <li>Install Dependencies: Installs project dependencies using <code>npm ci</code>.</li> <li>Build Project: Builds the project using <code>npm run build</code>.</li> <li>Run Integration Tests: Executes the integration tests using <code>npm run test:integration</code>.  Sets environment variables for access within the tests.</li> <li>Upload Integration Test Coverage: Uploads the integration test coverage report from the <code>coverage/integration/</code> directory as a workflow artifact.  The artifact is retained for 14 days.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-integration-tests/#2-combined-coverage","title":"2. <code>combined-coverage</code>","text":"<ul> <li>Name: Combined Coverage Report</li> <li>Runs on: <code>ubuntu-latest</code></li> <li>Needs: <code>integration-tests</code> (This job depends on the successful completion of the <code>integration-tests</code> job.)</li> <li>Purpose: Generates a combined coverage summary report from both unit and integration tests.</li> <li>Steps:<ul> <li>Checkout Repository: Checks out the project's code.</li> <li>Setup Node.js: Sets up the Node.js environment with version 20 and enables npm caching.</li> <li>Install Dependencies: Installs project dependencies using <code>npm ci</code>.</li> <li>Run All Tests with Coverage: Runs both unit tests (<code>npm test</code>) and integration tests (<code>npm run test:integration</code>) to generate coverage data.</li> <li>Generate Combined Coverage Summary: Creates a summary report in the GitHub step output using <code>jq</code> to parse the <code>coverage-summary.json</code> files for unit and integration tests. The report is formatted as Markdown and includes percentage coverage for statements, branches, functions, and lines.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-integration-tests/#3-e2e-action-test","title":"3. <code>e2e-action-test</code>","text":"<ul> <li>Name: E2E Action Test</li> <li>Runs on: <code>ubuntu-latest</code></li> <li>Conditional Execution: Runs only if one of the following conditions is met:<ul> <li>The workflow is triggered manually (<code>workflow_dispatch</code>).</li> <li>The workflow is triggered by a <code>push</code> event to the <code>main</code> branch.</li> <li>The workflow is triggered by a <code>pull_request</code> event.</li> </ul> </li> <li>Purpose: Performs an end-to-end test of the project's action.</li> <li>Steps:<ul> <li>Checkout Repository: Checks out the project's code.</li> <li>Setup Node.js: Sets up the Node.js environment with version 20 and enables npm caching.</li> <li>Install Dependencies: Installs project dependencies using <code>npm ci</code>.</li> <li>Build Action: Builds the project's action using <code>npm run build</code>.</li> <li>Create Test Configuration: Creates a <code>devops-config.json</code> file with a predefined configuration for the action test, including governance settings and runtime parameters.</li> <li>Test Action Execution (Dry Run): Executes the action in dry-run mode using the <code>./</code> path (assuming the action is in the current directory).  It provides test credentials and sets the <code>DEBUG</code> environment variable based on the <code>inputs.debug</code> value. <code>continue-on-error: true</code> allows the workflow to continue even if the action fails (as it's expected to fail in dry-run mode without valid credentials).</li> <li>Verify Action Outputs:  Analyzes the outcome of the action test and logs the results to the GitHub step output.  It checks if the action executed successfully and displays the runtime ID if available.  It also includes the <code>devops-config.json</code> file used for the test.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-integration-tests/#4-matrix-integration","title":"4. <code>matrix-integration</code>","text":"<ul> <li>Name: Matrix Integration (${{ matrix.os }} / Node ${{ matrix.node }})</li> <li>Runs on:  Dynamically determined based on the matrix strategy.</li> <li>Strategy: Uses a matrix strategy to run the integration tests on multiple operating systems and Node.js versions.<ul> <li><code>os</code>: <code>ubuntu-latest</code>, <code>windows-latest</code>, <code>macos-latest</code></li> <li><code>node</code>: <code>\"20\"</code>, <code>\"22\"</code></li> </ul> </li> <li>Purpose:  Ensures compatibility across different environments.</li> <li>Steps:<ul> <li>Checkout Repository: Checks out the project's code.</li> <li>Setup Node.js: Sets up the Node.js environment with the version specified in the matrix and enables npm caching.</li> <li>Install Dependencies: Installs project dependencies using <code>npm ci</code>.</li> <li>Build Project: Builds the project using <code>npm run build</code>.</li> <li>Run Integration Tests: Executes the integration tests using <code>npm run test:integration</code>. Sets environment variables for access within the tests.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-integration-tests/#inputs","title":"Inputs","text":"<p>The <code>workflow_dispatch</code> event accepts the following input:</p> <ul> <li><code>debug</code>: (boolean, optional, default: <code>false</code>) Enables debug logging if set to <code>true</code>.</li> </ul>"},{"location":"packages/runtime/docs/workflows-integration-tests/#artifacts","title":"Artifacts","text":"<p>The workflow produces the following artifacts:</p> <ul> <li><code>integration-coverage-report</code>: Contains the integration test coverage report from the <code>coverage/integration/</code> directory.  Retained for 14 days.</li> </ul>"},{"location":"packages/runtime/docs/workflows-plugin-whitelist-test/","title":"Workflows Plugin Whitelist","text":""},{"location":"packages/runtime/docs/workflows-plugin-whitelist-test/#plugin-whitelist-governance-test-workflow-documentation","title":"Plugin Whitelist Governance Test Workflow Documentation","text":"<p>This workflow validates the plugin whitelist governance feature. It tests scenarios involving whitelisted plugins, non-whitelisted plugins, missing whitelist configurations, version constraints, and the blocking of specific plugins (like the scanner).</p>"},{"location":"packages/runtime/docs/workflows-plugin-whitelist-test/#workflow-triggers","title":"Workflow Triggers","text":"<p>The workflow is triggered by:</p> <ul> <li><code>push</code> events: When code is pushed to the <code>main</code> branch, specifically changes in the <code>src/</code> directory, the <code>action.yml</code> file, or the workflow file itself (<code>.github/workflows/plugin-whitelist-test.yml</code>).</li> <li><code>pull_request</code> events: When a pull request is opened against the <code>main</code> branch.</li> <li><code>workflow_dispatch</code> events:  Allows manual triggering of the workflow.</li> </ul>"},{"location":"packages/runtime/docs/workflows-plugin-whitelist-test/#jobs","title":"Jobs","text":"<p>The workflow consists of five jobs:</p> <ol> <li><code>test-whitelisted-plugin</code>: Tests the successful installation of a plugin that is included in the whitelist.</li> <li><code>test-non-whitelisted-plugin</code>: Tests that the workflow correctly rejects the installation of a plugin that is not in the whitelist.</li> <li><code>test-no-whitelist</code>: Tests the behavior when no plugin whitelist is configured.</li> <li><code>test-version-constraints</code>: Tests the enforcement of version constraints specified in the whitelist.</li> <li><code>test-scanner-blocked</code>: Specifically tests that the deprecated <code>@salesforce/sfdx-scanner</code> plugin is blocked, even if governance is enabled.</li> </ol>"},{"location":"packages/runtime/docs/workflows-plugin-whitelist-test/#job-structure-common-elements","title":"Job Structure (Common Elements)","text":"<p>Each job shares a common structure:</p> <ul> <li><code>name</code>: A descriptive name for the job.</li> <li><code>runs-on</code>: Specifies the virtual machine environment to use (<code>ubuntu-latest</code>).</li> <li><code>steps</code>: A sequence of steps to execute.  These steps generally include:<ul> <li><code>Checkout</code>: Checks out the repository code using <code>actions/checkout@v6</code>.</li> <li><code>Setup Node.js</code>: Sets up a Node.js environment using <code>actions/setup-node@v6</code>, specifying version 20 and enabling npm caching.</li> <li><code>Install Dependencies</code>: Installs project dependencies using <code>npm ci</code>.</li> <li><code>Build Action</code>: Builds the action using <code>npm run build</code>.</li> <li><code>Create Test Config with Plugin Whitelist</code>: Creates a <code>devops-config.json</code> file containing the governance configuration, including the <code>plugin_whitelist</code>. The content of this file varies between jobs to test different scenarios.</li> <li><code>Test Whitelisted/Non-Whitelisted Plugin Installation</code>: Executes the action (<code>./</code>) with specific input parameters to simulate plugin installation.  Key parameters include:<ul> <li><code>jwt_key</code>: A mock JWT key for authentication.</li> <li><code>client_id</code>: A mock client ID.</li> <li><code>username</code>: A mock username.</li> <li><code>plugins</code>: The name of the plugin to install (either whitelisted or non-whitelisted).</li> <li><code>enforce_policy</code>: Set to <code>\"false\"</code> to allow testing of the rejection logic without actually enforcing the policy.</li> <li><code>skip_auth</code>: Set to <code>\"true\"</code> to bypass authentication.</li> </ul> </li> <li><code>Verify Plugin Was Rejected</code> (in <code>test-non-whitelisted-plugin</code>):  Checks the outcome of the previous step (which is expected to fail) and reports success or failure based on whether the non-whitelisted plugin was correctly rejected.  The result is written to the GitHub Step Summary.</li> <li><code>Validate Scanner Blocked</code> (in <code>test-scanner-blocked</code>): Checks the outcome of the scanner installation attempt and validates that the scanner was blocked as expected. The result is written to the GitHub Step Summary.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-plugin-whitelist-test/#devops-configjson-configuration","title":"<code>devops-config.json</code> Configuration","text":"<p>The <code>devops-config.json</code> file is dynamically created in each job and defines the governance policy.  The relevant section is:</p> <pre><code>{\n  \"governance\": {\n    \"enabled\": true,\n    \"plugin_whitelist\": [\"plugin1\", \"plugin2@version\"]\n  },\n  \"runtime\": {\n    \"cli_version\": \"latest\"\n  }\n}\n</code></pre> <ul> <li><code>governance.enabled</code>: A boolean value indicating whether governance is enabled.  Set to <code>true</code> in all jobs.</li> <li><code>governance.plugin_whitelist</code>: An array of strings representing the whitelisted plugins.  Each string can include a version constraint using semantic versioning (e.g., <code>\"sfdx-hardis@^6.0.0\"</code>).  If this array is empty or missing, no whitelist is enforced.</li> <li><code>runtime.cli_version</code>: Specifies the CLI version to use. Set to <code>\"latest\"</code> in all jobs.</li> </ul>"},{"location":"packages/runtime/docs/workflows-plugin-whitelist-test/#key-takeaways","title":"Key Takeaways","text":"<p>This workflow provides comprehensive testing of the plugin whitelist governance feature, ensuring that:</p> <ul> <li>Whitelisted plugins are installed successfully.</li> <li>Non-whitelisted plugins are rejected.</li> <li>The workflow behaves correctly when no whitelist is configured.</li> <li>Version constraints are enforced.</li> <li>Specific, deprecated plugins (like the scanner) are blocked.</li> </ul>"},{"location":"packages/runtime/docs/workflows-release/","title":"Release Workflow Documentation","text":"<p>This document details the <code>release.yml</code> workflow file located in the <code>.github/workflows</code> directory. This workflow automates the release process for the project, triggered by pushes to tags (versioned releases) or manual dispatch.</p>"},{"location":"packages/runtime/docs/workflows-release/#workflow-structure","title":"Workflow Structure","text":"<p>The workflow consists of a single job named <code>release</code>. This job is executed on an Ubuntu-latest runner.</p>"},{"location":"packages/runtime/docs/workflows-release/#key-configuration-details","title":"Key Configuration Details","text":""},{"location":"packages/runtime/docs/workflows-release/#name-release","title":"<code>name: Release</code>","text":"<ul> <li>Purpose: Defines the name of the workflow, displayed in the GitHub Actions interface.</li> </ul>"},{"location":"packages/runtime/docs/workflows-release/#on","title":"<code>on:</code>","text":"<ul> <li>Purpose: Specifies the events that trigger the workflow.</li> <li><code>push:</code> Triggers the workflow on push events.<ul> <li><code>tags:</code>  Further filters the push event to only trigger when a tag is pushed. The tag name must match the pattern <code>\"v*\"</code>.</li> </ul> </li> <li><code>workflow_dispatch:</code> Enables manual triggering of the workflow from the GitHub Actions interface.</li> </ul>"},{"location":"packages/runtime/docs/workflows-release/#jobs","title":"<code>jobs:</code>","text":"<ul> <li>Purpose: Defines the jobs to be executed in the workflow.</li> <li><code>release:</code> Defines the release job.<ul> <li><code>name: Create Release</code> Sets the name of the job.</li> <li><code>runs-on: ubuntu-latest</code> Specifies the runner environment for the job (Ubuntu latest).</li> <li><code>permissions:</code> Defines the permissions granted to the workflow.<ul> <li><code>contents: write</code> Allows the workflow to write to the repository's contents (e.g., create/update files).</li> <li><code>packages: write</code> Allows the workflow to write to the repository's packages.</li> <li><code>id-token: write</code> Allows the workflow to write to the repository's ID token.</li> </ul> </li> <li><code>steps:</code>  A sequence of tasks to be executed within the job.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-release/#steps-breakdown","title":"Steps Breakdown","text":"<ul> <li><code>Checkout</code><ul> <li><code>uses: actions/checkout@v6</code> Checks out the repository code to the runner.</li> </ul> </li> <li><code>Setup Node.js</code><ul> <li><code>uses: actions/setup-node@v6</code> Sets up a Node.js environment.</li> <li><code>with:</code> Configuration options for the Node.js setup.<ul> <li><code>node-version: \"20\"</code> Specifies the Node.js version to use.</li> <li><code>cache: \"npm\"</code> Enables caching of npm dependencies for faster builds.</li> <li><code>registry-url: \"https://registry.npmjs.org\"</code> Sets the npm registry URL.</li> </ul> </li> </ul> </li> <li><code>Install Dependencies</code><ul> <li><code>run: npm ci</code> Installs project dependencies using <code>npm ci</code> (clean install).</li> </ul> </li> <li><code>Run Tests</code><ul> <li><code>run: npm test</code> Executes the project's test suite.</li> </ul> </li> <li><code>Build</code><ul> <li><code>run: npm run build</code> Executes the project's build script.</li> </ul> </li> <li><code>Create GitHub Release</code><ul> <li><code>uses: softprops/action-gh-release@v2</code> Creates a GitHub release.</li> <li><code>with:</code> Configuration options for the release creation.<ul> <li><code>generate_release_notes: true</code> Automatically generates release notes based on commit messages.</li> <li><code>body:</code> The body of the release notes. Includes installation instructions and a link to the CHANGELOG.md file.</li> <li><code>draft: false</code> Creates a published release (not a draft).</li> <li><code>prerelease: false</code> Creates a stable release (not a pre-release).</li> </ul> </li> </ul> </li> <li><code>Generate Changelog</code><ul> <li><code>run:</code> A multi-line script to generate a basic CHANGELOG.md file.  It creates a new file or overwrites an existing one with a header, release version, date, and placeholder changes.</li> </ul> </li> <li><code>Commit Changelog</code><ul> <li><code>run:</code> A multi-line script to commit the generated CHANGELOG.md file back to the repository. It configures git with a generic user, adds the CHANGELOG.md file, commits the changes, and pushes them to the repository.  Includes error handling to prevent commit failures if no changes are detected.</li> </ul> </li> <li><code>Publish to NPM (if applicable)</code><ul> <li><code>run:</code> A conditional script to publish the package to npm. It checks if the tag name matches the pattern <code>v[0-9]+\\.[0-9]+\\.[0-9]+</code> (a semantic version). If it does, it publishes the package using <code>npm publish</code>. Otherwise, it skips the publishing step.</li> <li><code>env:</code> Environment variables for the step.<ul> <li><code>NODE_AUTH_TOKEN: ${{ secrets.NPM_TOKEN }}</code> Provides the npm authentication token from a GitHub secret.</li> </ul> </li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-auth-contract/","title":"Auth Contract Verification Workflow Documentation","text":"<p>This document details the <code>verify-auth-contract.yml</code> workflow file, which automates the verification of the authentication contract for the GlassOps Runtime.</p>"},{"location":"packages/runtime/docs/workflows-verify-auth-contract/#purpose","title":"Purpose","text":"<p>The primary goal of this workflow is to ensure that the GlassOps Runtime is correctly initialized and configured with valid authentication credentials and organizational information. It verifies the output of the runtime initialization process, specifically checking for a valid organization ID and a readiness signal.  This workflow is triggered on pushes and pull requests to the <code>main</code> branch, and can also be manually triggered.</p>"},{"location":"packages/runtime/docs/workflows-verify-auth-contract/#structure","title":"Structure","text":"<p>The workflow consists of a single job named <code>verify-identity-contract</code>. This job is executed on an Ubuntu-latest runner.</p>"},{"location":"packages/runtime/docs/workflows-verify-auth-contract/#name-auth-contract-verification","title":"<code>name: Auth Contract Verification</code>","text":"<ul> <li>Purpose: Defines the name of the workflow as displayed in the GitHub Actions interface.</li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-auth-contract/#on","title":"<code>on:</code>","text":"<ul> <li>Purpose: Specifies the events that trigger the workflow.<ul> <li><code>push:</code><ul> <li><code>branches: [main]</code> - Triggers the workflow on pushes to the <code>main</code> branch.</li> </ul> </li> <li><code>pull_request:</code><ul> <li><code>branches: [main]</code> - Triggers the workflow on pull requests targeting the <code>main</code> branch.</li> </ul> </li> <li><code>workflow_dispatch:</code> - Allows manual triggering of the workflow.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-auth-contract/#jobs","title":"<code>jobs:</code>","text":"<ul> <li> <p>Purpose: Defines the jobs to be executed in the workflow.</p> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-auth-contract/#verify-identity-contract","title":"<code>verify-identity-contract:</code>","text":"<ul> <li><code>name: Verify Identity &amp; Output Contract</code> -  Defines the name of the job.</li> <li><code>runs-on: ubuntu-latest</code> - Specifies that the job should run on a virtual machine with the latest Ubuntu operating system.</li> <li><code>if: github.repository_owner == 'glassops-platform' &amp;&amp; github.actor != 'dependabot[bot]'</code> -  A conditional statement that determines whether the job should run. It only runs if the repository owner is <code>glassops-platform</code> and the actor is not the <code>dependabot[bot]</code> user.</li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-auth-contract/#steps","title":"<code>steps:</code>","text":"<ul> <li> <p>Purpose: Defines the sequence of steps to be executed within the job.</p> <ul> <li><code>- name: Checkout</code><ul> <li><code>uses: actions/checkout@v6</code> - Checks out the repository code to the runner.</li> </ul> </li> <li><code>- name: Initialize GlassOps Runtime\u2122</code><ul> <li><code>id: runtime</code> - Assigns an ID to this step, allowing its outputs to be referenced in subsequent steps.</li> <li><code>uses: ./</code> - Uses a custom action defined within the repository (presumably the GlassOps Runtime initialization action).</li> <li><code>with:</code><ul> <li><code>jwt_key: ${{ secrets.SF_JWT_KEY }}</code> - Passes the JWT key as a secret to the action.</li> <li><code>client_id: ${{ secrets.SF_CLIENT_ID }}</code> - Passes the client ID as a secret to the action.</li> <li><code>username: ${{ vars.SF_USERNAME }}</code> - Passes the username as a variable to the action.</li> <li><code>enforce_policy: \"false\"</code> -  Disables policy enforcement during runtime initialization.</li> </ul> </li> </ul> </li> <li><code>- name: Validate Contract Primitives</code><ul> <li><code>run: |</code> - Executes a multi-line shell script.<ul> <li>The script verifies the <code>org_id</code> and <code>glassops_ready</code> outputs from the <code>runtime</code> step.</li> <li>It checks if the <code>org_id</code> starts with \"00D\".</li> <li>It checks if <code>glassops_ready</code> is equal to \"true\".</li> <li>If either check fails, the script exits with an error code (1).</li> <li>If both checks pass, it prints a success message.</li> <li>It also generates a step summary in Markdown format, displaying the verification results.</li> </ul> </li> </ul> </li> <li><code>- name: Audit Environment Setup</code><ul> <li><code>run: |</code> - Executes a multi-line shell script.<ul> <li>The script verifies the Salesforce CLI (sf) environment.</li> <li>It attempts to display the org ID using <code>sf org display --json</code> and pipes the output to <code>jq</code> to extract the ID. The output is redirected to <code>/dev/null</code> to suppress it.</li> <li>If the command succeeds, it prints a success message indicating that the CLI is authenticated and functional.</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-governance/","title":"Governance Validation Workflow Documentation","text":"<p>This workflow validates the governance and freeze window enforcement logic of the runtime component. It consists of two jobs: <code>test-freeze-logic</code> and <code>test-bypass-logic</code>.</p>"},{"location":"packages/runtime/docs/workflows-verify-governance/#workflow-triggers","title":"Workflow Triggers","text":"<p>The workflow is triggered on:</p> <ul> <li>Push to <code>main</code> branch:  Executes when code is pushed to the <code>main</code> branch.</li> <li>Pull Request to <code>main</code> branch: Executes when a pull request is opened or updated targeting the <code>main</code> branch.</li> <li>Workflow Dispatch: Allows manual triggering of the workflow.</li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-governance/#jobs","title":"Jobs","text":""},{"location":"packages/runtime/docs/workflows-verify-governance/#1-test-freeze-logic-verify-freeze-window-enforcement","title":"1. <code>test-freeze-logic</code> - Verify Freeze Window Enforcement","text":"<p>This job verifies that the runtime component correctly blocks deployments during an active freeze window.</p> <ul> <li><code>runs-on</code>: <code>ubuntu-latest</code> - Specifies that the job runs on a virtual machine with the latest Ubuntu operating system.</li> <li>Steps:<ul> <li><code>Checkout</code>: Uses the <code>actions/checkout@v6</code> action to check out the repository code.</li> <li><code>Generate Active Freeze Policy</code>: Creates a <code>devops-config.json</code> file containing a governance policy that enables governance and defines a freeze window for the current day, spanning the entire day (00:00 - 23:59).  The <code>DAY</code> variable is dynamically set to the current day of the week.</li> <li><code>Attempt Governed Run (Expected to Fail)</code>: Executes the runtime component using the <code>./</code> action (assumes the runtime component is in the same repository).  It passes mock values for <code>jwt_key</code>, <code>client_id</code>, and <code>username</code>.  Crucially, <code>enforce_policy</code> is set to <code>\"true\"</code>, meaning the runtime should enforce the governance policy. <code>continue-on-error: true</code> allows the workflow to continue even if this step fails (as it's expected to fail during the freeze window).</li> <li><code>Validate Blocked Outcome</code>:  Checks the outcome of the <code>governed-run</code> step. If the step failed (as expected), it logs a success message indicating that the runtime correctly blocked the deployment. If the step succeeded, it logs a failure message and exits with an error code (1).  The results are written to the GitHub Step Summary.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-governance/#2-test-bypass-logic-verify-manual-bypass","title":"2. <code>test-bypass-logic</code> - Verify Manual Bypass","text":"<p>This job verifies that the runtime component can be bypassed when <code>enforce_policy</code> is set to <code>\"false\"</code>.</p> <ul> <li><code>runs-on</code>: <code>ubuntu-latest</code> - Specifies that the job runs on a virtual machine with the latest Ubuntu operating system.</li> <li>Steps:<ul> <li><code>Checkout</code>: Uses the <code>actions/checkout@v6</code> action to check out the repository code.</li> <li><code>Generate Active Freeze Policy</code>: Creates a <code>devops-config.json</code> file, identical to the one in <code>test-freeze-logic</code>, enabling governance and defining a freeze window for the current day.</li> <li><code>Attempt Bypassed Run</code>: Executes the runtime component with <code>enforce_policy</code> set to <code>\"false\"</code> and <code>skip_auth</code> set to <code>\"true\"</code>. This simulates a manual bypass of the governance policy. <code>continue-on-error: true</code> allows the workflow to continue even if this step fails.</li> <li><code>Verify Bypass</code>: Checks the outcome of the <code>test-bypass</code> step. If the step succeeded, it logs a success message indicating that the policy was successfully bypassed. If the step failed, it logs a failure message, includes the outcome, and exits with an error code (1). The results are written to the GitHub Step Summary. <code>if: always()</code> ensures this step runs regardless of the previous step's outcome.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-governance/#devops-configjson-structure","title":"<code>devops-config.json</code> Structure","text":"<p>The <code>devops-config.json</code> file used in both jobs has the following structure:</p> <pre><code>{\n  \"governance\": {\n    \"enabled\": true,\n    \"freeze_windows\": [\n      { \"day\": \"DAY_OF_WEEK\", \"start\": \"HH:MM\", \"end\": \"HH:MM\" }\n    ]\n  },\n  \"runtime\": { \"cli_version\": \"latest\" }\n}\n</code></pre> <ul> <li><code>governance</code>:  An object containing governance-related settings.<ul> <li><code>enabled</code>: A boolean value indicating whether governance is enabled.</li> <li><code>freeze_windows</code>: An array of objects, each defining a freeze window.<ul> <li><code>day</code>: The day of the week the freeze window applies to (e.g., \"Monday\", \"Tuesday\").</li> <li><code>start</code>: The start time of the freeze window in HH:MM format (e.g., \"00:00\").</li> <li><code>end</code>: The end time of the freeze window in HH:MM format (e.g., \"23:59\").</li> </ul> </li> </ul> </li> <li><code>runtime</code>: An object containing runtime-related settings.<ul> <li><code>cli_version</code>: The desired CLI version for the runtime.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-primitives/","title":"Primitive Logic Verification Workflow Documentation","text":""},{"location":"packages/runtime/docs/workflows-verify-primitives/#purpose","title":"Purpose","text":"<p>This workflow automates the verification of primitive logic within the project. It performs unit tests, code hygiene checks (ESLint and Prettier), dependency audits, and dependency reviews on code changes.  The workflow is triggered by pushes to the <code>main</code> branch, pull requests targeting <code>main</code>, and manual dispatch.</p>"},{"location":"packages/runtime/docs/workflows-verify-primitives/#structure","title":"Structure","text":"<p>The workflow consists of three main jobs: <code>unit-tests</code>, <code>code-hygiene</code>, and <code>dependency-review</code>. Each job runs on a specific environment and performs a set of steps.</p>"},{"location":"packages/runtime/docs/workflows-verify-primitives/#1-unit-tests-job","title":"1. <code>unit-tests</code> Job","text":"<ul> <li>Name: <code>Run Logic Unit Tests (${{ matrix.os }})</code></li> <li><code>runs-on</code>: <code>${{ matrix.os }}</code> - Dynamically selects the operating system based on the matrix.</li> <li><code>strategy</code>: Defines a matrix of configurations for running the tests across different environments.<ul> <li><code>matrix.os</code>: <code>[ubuntu-latest, windows-latest, macos-latest]</code> - Runs tests on Ubuntu, Windows, and macOS.</li> <li><code>matrix.node-version</code>: <code>[\"18\", \"20\"]</code> - Runs tests with Node.js versions 18 and 20.</li> <li><code>exclude</code>:  Excludes specific combinations from the matrix. In this case, it excludes running Node.js 18 on Ubuntu.</li> </ul> </li> <li>Steps:<ul> <li><code>Checkout</code>: Uses <code>actions/checkout@v6</code> to checkout the repository code.</li> <li><code>Setup Node.js ${{ matrix.node-version }}</code>: Uses <code>actions/setup-node@v6</code> to set up the specified Node.js version.  <code>cache: \"npm\"</code> enables caching of npm dependencies for faster builds.</li> <li><code>Install Dependencies</code>: Runs <code>npm ci</code> to install dependencies from <code>package-lock.json</code>.</li> <li><code>Run Jest Suite</code>: Executes the Jest test suite using <code>npm test</code>.  The output is redirected to <code>test-output.log</code>, and a summary of the test results is written to the GitHub step summary.  The workflow fails if tests fail.</li> <li><code>Upload Coverage Reports</code>: Uses <code>codecov/codecov-action@v5</code> to upload code coverage reports to Codecov. This step only runs on Ubuntu with Node.js 20.  <code>file: ./coverage/lcov.info</code> specifies the coverage report file. <code>flags: unittests</code> and <code>name: codecov-umbrella</code> are used for organization within Codecov.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-primitives/#2-code-hygiene-job","title":"2. <code>code-hygiene</code> Job","text":"<ul> <li>Name: <code>Verify Code Standards</code></li> <li><code>runs-on</code>: <code>ubuntu-latest</code> - Runs on Ubuntu.</li> <li>Steps:<ul> <li><code>Checkout</code>: Uses <code>actions/checkout@v6</code> to checkout the repository code.</li> <li><code>Setup Node.js</code>: Uses <code>actions/setup-node@v6</code> to set up Node.js version 20.</li> <li><code>Install Dependencies</code>: Runs <code>npm ci</code> to install dependencies.</li> <li><code>Run Code Hygiene Checks</code>: Executes ESLint (<code>npm run lint</code>) and Prettier (<code>npm run format:check</code>) to verify code style and formatting.  The results are written to the GitHub step summary in a table format.</li> <li><code>Verify Build</code>: Runs <code>npm run build</code> to ensure the project builds successfully.</li> <li><code>Check Dependencies</code>: Runs <code>npm audit --audit-level moderate</code> to scan for security vulnerabilities in dependencies, reporting those with a moderate severity or higher.</li> </ul> </li> </ul>"},{"location":"packages/runtime/docs/workflows-verify-primitives/#3-dependency-review-job","title":"3. <code>dependency-review</code> Job","text":"<ul> <li>Name: <code>Dependency Review</code></li> <li><code>runs-on</code>: <code>ubuntu-latest</code> - Runs on Ubuntu.</li> <li><code>if: github.event_name == 'pull_request'</code>: This job only runs when triggered by a pull request event.</li> <li>Steps:<ul> <li><code>Checkout</code>: Uses <code>actions/checkout@v6</code> to checkout the repository code.</li> <li><code>Dependency Review</code>: Uses <code>actions/dependency-review-action@v4</code> to perform a review of the pull request's dependencies, identifying potential security vulnerabilities and outdated packages.</li> </ul> </li> </ul>"},{"location":"packages/tools/adr-enforcer/","title":"GlassOps ADR Enforcer","text":"<p>Tool for enforcing Architecture Decision Records compliance.</p> <p>See Documentation.</p>"},{"location":"packages/tools/adr-enforcer/docs/","title":"GlassOps ADR Enforcer Documentation","text":"<ul> <li>Architecture Decision Records</li> <li>Architecture</li> </ul>"},{"location":"packages/tools/adr-enforcer/docs/LICENSE/","title":"LICENSE","text":"<p>Attribution 4.0 International</p> <p>=======================================================================</p> <p>Creative Commons Corporation (\"Creative Commons\") is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \"as-is\" basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.</p> <p>Using Creative Commons Public Licenses</p> <p>Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.</p> <pre><code> Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n</code></pre> <p>=======================================================================</p> <p>Creative Commons Attribution 4.0 International Public License</p> <p>By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.</p> <p>Section 1 -- Definitions.</p> <p>a. Adapted Material means material subject to Copyright and Similar      Rights that is derived from or based upon the Licensed Material      and in which the Licensed Material is translated, altered,      arranged, transformed, or otherwise modified in a manner requiring      permission under the Copyright and Similar Rights held by the      Licensor. For purposes of this Public License, where the Licensed      Material is a musical work, performance, or sound recording,      Adapted Material is always produced where the Licensed Material is      synched in timed relation with a moving image.</p> <p>b. Adapter's License means the license You apply to Your Copyright      and Similar Rights in Your contributions to Adapted Material in      accordance with the terms and conditions of this Public License.</p> <p>c. Copyright and Similar Rights means copyright and/or similar rights      closely related to copyright including, without limitation,      performance, broadcast, sound recording, and Sui Generis Database      Rights, without regard to how the rights are labeled or      categorized. For purposes of this Public License, the rights      specified in Section 2(b)(1)-(2) are not Copyright and Similar      Rights.</p> <p>d. Effective Technological Measures means those measures that, in the      absence of proper authority, may not be circumvented under laws      fulfilling obligations under Article 11 of the WIPO Copyright      Treaty adopted on December 20, 1996, and/or similar international      agreements.</p> <p>e. Exceptions and Limitations means fair use, fair dealing, and/or      any other exception or limitation to Copyright and Similar Rights      that applies to Your use of the Licensed Material.</p> <p>f. Licensed Material means the artistic or literary work, database,      or other material to which the Licensor applied this Public      License.</p> <p>g. Licensed Rights means the rights granted to You subject to the      terms and conditions of this Public License, which are limited to      all Copyright and Similar Rights that apply to Your use of the      Licensed Material and that the Licensor has authority to license.</p> <p>h. Licensor means the individual(s) or entity(ies) granting rights      under this Public License.</p> <p>i. Share means to provide material to the public by any means or      process that requires permission under the Licensed Rights, such      as reproduction, public display, public performance, distribution,      dissemination, communication, or importation, and to make material      available to the public including in ways that members of the      public may access the material from a place and at a time      individually chosen by them.</p> <p>j. Sui Generis Database Rights means rights other than copyright      resulting from Directive 96/9/EC of the European Parliament and of      the Council of 11 March 1996 on the legal protection of databases,      as amended and/or succeeded, as well as other essentially      equivalent rights anywhere in the world.</p> <p>k. You means the individual or entity exercising the Licensed Rights      under this Public License. Your has a corresponding meaning.</p> <p>Section 2 -- Scope.</p> <p>a. License grant.</p> <pre><code>   1. Subject to the terms and conditions of this Public License,\n      the Licensor hereby grants You a worldwide, royalty-free,\n      non-sublicensable, non-exclusive, irrevocable license to\n      exercise the Licensed Rights in the Licensed Material to:\n\n        a. reproduce and Share the Licensed Material, in whole or\n           in part; and\n\n        b. produce, reproduce, and Share Adapted Material.\n\n   2. Exceptions and Limitations. For the avoidance of doubt, where\n      Exceptions and Limitations apply to Your use, this Public\n      License does not apply, and You do not need to comply with\n      its terms and conditions.\n\n   3. Term. The term of this Public License is specified in Section\n      6(a).\n\n   4. Media and formats; technical modifications allowed. The\n      Licensor authorizes You to exercise the Licensed Rights in\n      all media and formats whether now known or hereafter created,\n      and to make technical modifications necessary to do so. The\n      Licensor waives and/or agrees not to assert any right or\n      authority to forbid You from making technical modifications\n      necessary to exercise the Licensed Rights, including\n      technical modifications necessary to circumvent Effective\n      Technological Measures. For purposes of this Public License,\n      simply making modifications authorized by this Section 2(a)\n      (4) never produces Adapted Material.\n\n   5. Downstream recipients.\n\n        a. Offer from the Licensor -- Licensed Material. Every\n           recipient of the Licensed Material automatically\n           receives an offer from the Licensor to exercise the\n           Licensed Rights under the terms and conditions of this\n           Public License.\n\n        b. No downstream restrictions. You may not offer or impose\n           any additional or different terms or conditions on, or\n           apply any Effective Technological Measures to, the\n           Licensed Material if doing so restricts exercise of the\n           Licensed Rights by any recipient of the Licensed\n           Material.\n\n   6. No endorsement. Nothing in this Public License constitutes or\n      may be construed as permission to assert or imply that You\n      are, or that Your use of the Licensed Material is, connected\n      with, or sponsored, endorsed, or granted official status by,\n      the Licensor or others designated to receive attribution as\n      provided in Section 3(a)(1)(A)(i).\n</code></pre> <p>b. Other rights.</p> <pre><code>   1. Moral rights, such as the right of integrity, are not\n      licensed under this Public License, nor are publicity,\n      privacy, and/or other similar personality rights; however, to\n      the extent possible, the Licensor waives and/or agrees not to\n      assert any such rights held by the Licensor to the limited\n      extent necessary to allow You to exercise the Licensed\n      Rights, but not otherwise.\n\n   2. Patent and trademark rights are not licensed under this\n      Public License.\n\n   3. To the extent possible, the Licensor waives any right to\n      collect royalties from You for the exercise of the Licensed\n      Rights, whether directly or through a collecting society\n      under any voluntary or waivable statutory or compulsory\n      licensing scheme. In all other cases the Licensor expressly\n      reserves any right to collect such royalties.\n</code></pre> <p>Section 3 -- License Conditions.</p> <p>Your exercise of the Licensed Rights is expressly made subject to the following conditions.</p> <p>a. Attribution.</p> <pre><code>   1. If You Share the Licensed Material (including in modified\n      form), You must:\n\n        a. retain the following if it is supplied by the Licensor\n           with the Licensed Material:\n\n             i. identification of the creator(s) of the Licensed\n                Material and any others designated to receive\n                attribution, in any reasonable manner requested by\n                the Licensor (including by pseudonym if\n                designated);\n\n            ii. a copyright notice;\n\n           iii. a notice that refers to this Public License;\n\n            iv. a notice that refers to the disclaimer of\n                warranties;\n\n             v. a URI or hyperlink to the Licensed Material to the\n                extent reasonably practicable;\n\n        b. indicate if You modified the Licensed Material and\n           retain an indication of any previous modifications; and\n\n        c. indicate the Licensed Material is licensed under this\n           Public License, and include the text of, or the URI or\n           hyperlink to, this Public License.\n\n   2. You may satisfy the conditions in Section 3(a)(1) in any\n      reasonable manner based on the medium, means, and context in\n      which You Share the Licensed Material. For example, it may be\n      reasonable to satisfy the conditions by providing a URI or\n      hyperlink to a resource that includes the required\n      information.\n\n   3. If requested by the Licensor, You must remove any of the\n      information required by Section 3(a)(1)(A) to the extent\n      reasonably practicable.\n\n   4. If You Share Adapted Material You produce, the Adapter's\n      License You apply must not prevent recipients of the Adapted\n      Material from complying with this Public License.\n</code></pre> <p>Section 4 -- Sui Generis Database Rights.</p> <p>Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:</p> <p>a. for the avoidance of doubt, Section 2(a)(1) grants You the right      to extract, reuse, reproduce, and Share all or a substantial      portion of the contents of the database;</p> <p>b. if You include all or a substantial portion of the database      contents in a database in which You have Sui Generis Database      Rights, then the database in which You have Sui Generis Database      Rights (but not its individual contents) is Adapted Material; and</p> <p>c. You must comply with the conditions in Section 3(a) if You Share      all or a substantial portion of the contents of the database.</p> <p>For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.</p> <p>Section 5 -- Disclaimer of Warranties and Limitation of Liability.</p> <p>a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE      EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS      AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF      ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,      IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,      WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR      PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,      ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT      KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT      ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.</p> <p>b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE      TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,      NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,      INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,      COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR      USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN      ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR      DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR      IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.</p> <p>c. The disclaimer of warranties and limitation of liability provided      above shall be interpreted in a manner that, to the extent      possible, most closely approximates an absolute disclaimer and      waiver of all liability.</p> <p>Section 6 -- Term and Termination.</p> <p>a. This Public License applies for the term of the Copyright and      Similar Rights licensed here. However, if You fail to comply with      this Public License, then Your rights under this Public License      terminate automatically.</p> <p>b. Where Your right to use the Licensed Material has terminated under      Section 6(a), it reinstates:</p> <pre><code>   1. automatically as of the date the violation is cured, provided\n      it is cured within 30 days of Your discovery of the\n      violation; or\n\n   2. upon express reinstatement by the Licensor.\n\n For the avoidance of doubt, this Section 6(b) does not affect any\n right the Licensor may have to seek remedies for Your violations\n of this Public License.\n</code></pre> <p>c. For the avoidance of doubt, the Licensor may also offer the      Licensed Material under separate terms or conditions or stop      distributing the Licensed Material at any time; however, doing so      will not terminate this Public License.</p> <p>d. Sections 1, 5, 6, 7, and 8 survive termination of this Public      License.</p> <p>Section 7 -- Other Terms and Conditions.</p> <p>a. The Licensor shall not be bound by any additional or different      terms or conditions communicated by You unless expressly agreed.</p> <p>b. Any arrangements, understandings, or agreements regarding the      Licensed Material not stated herein are separate from and      independent of the terms and conditions of this Public License.</p> <p>Section 8 -- Interpretation.</p> <p>a. For the avoidance of doubt, this Public License does not, and      shall not be interpreted to, reduce, limit, restrict, or impose      conditions on any use of the Licensed Material that could lawfully      be made without permission under this Public License.</p> <p>b. To the extent possible, if any provision of this Public License is      deemed unenforceable, it shall be automatically reformed to the      minimum extent necessary to make it enforceable. If the provision      cannot be reformed, it shall be severed from this Public License      without affecting the enforceability of the remaining terms and      conditions.</p> <p>c. No term or condition of this Public License will be waived and no      failure to comply consented to unless expressly agreed to by the      Licensor.</p> <p>d. Nothing in this Public License constitutes or may be interpreted      as a limitation upon, or waiver of, any privileges and immunities      that apply to the Licensor or You, including from the legal      processes of any jurisdiction or authority.</p> <p>=======================================================================</p> <p>Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark \"Creative Commons\" or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.</p> <p>Creative Commons may be contacted at creativecommons.org.</p>"},{"location":"packages/tools/adr-enforcer/docs/package/","title":"<code>@glassops/adr-enforcer</code> Package Documentation","text":"<p>This document details the <code>package.json</code> file for the <code>@glassops/adr-enforcer</code> package. This package is a tool designed to enforce Architectural Decision Records (ADRs) within a project. It likely integrates into a development workflow to validate code or configurations against established ADRs.</p>"},{"location":"packages/tools/adr-enforcer/docs/package/#data-representation","title":"Data Representation","text":"<p>The <code>package.json</code> file is a standard Node.js package manifest. It contains metadata about the package, including its name, version, and other configuration details.  In this specific instance, it's a relatively minimal manifest, indicating a focused tool with potentially limited external dependencies or a tightly controlled scope.</p>"},{"location":"packages/tools/adr-enforcer/docs/package/#fields","title":"Fields","text":""},{"location":"packages/tools/adr-enforcer/docs/package/#name-string-required","title":"<code>name</code> (String, Required)","text":"<ul> <li>Description:  The name of the package.  This uniquely identifies the package within the Node.js ecosystem and within the project's dependency graph.</li> <li>Value: <code>@glassops/adr-enforcer</code></li> <li>Significance:  Used for importing the package in other modules and for dependency management. The scope <code>@glassops</code> suggests this package is part of a larger organization or suite of tools.</li> </ul>"},{"location":"packages/tools/adr-enforcer/docs/package/#version-string-required","title":"<code>version</code> (String, Required)","text":"<ul> <li>Description: The version number of the package, adhering to semantic versioning (SemVer).</li> <li>Value: <code>1.0.0</code></li> <li>Significance:  Indicates the maturity and compatibility of the package.  <code>1.0.0</code> signifies the first stable release.</li> </ul>"},{"location":"packages/tools/adr-enforcer/docs/package/#private-boolean-optional","title":"<code>private</code> (Boolean, Optional)","text":"<ul> <li>Description:  A flag indicating whether the package should be published to a public registry (like npm).</li> <li>Value: <code>true</code></li> <li>Significance:  Setting this to <code>true</code> prevents accidental publication of the package. This is common for internal tools or packages that are only meant to be used within a specific project or organization.</li> </ul>"},{"location":"packages/tools/adr-enforcer/docs/package/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Dependency Management:  This <code>package.json</code> is used by package managers (npm, yarn, pnpm) to install and manage the package as a dependency within other projects.</li> <li>Script Execution:  While not present in this snippet, this <code>package.json</code> would typically contain <code>scripts</code> for running the ADR enforcement tool (e.g., <code>lint:adr</code>, <code>validate-adr</code>).</li> <li>Tool Integration:  The package is likely integrated into CI/CD pipelines or developer workflows to automatically check for ADR compliance.</li> <li>Internal Tooling: The <code>private: true</code> field suggests this is an internal tool used within a larger system and not intended for public distribution.</li> </ul>"},{"location":"packages/tools/adr-enforcer/docs/adr/","title":"GlassOps ADR Enforcement Adapter - Architecture Decision Records","text":"<p>This directory contains Architecture Decision Records (ADRs) specific to the ADR Enforcement Adapter.</p>"},{"location":"packages/tools/adr-enforcer/docs/adr/#scope","title":"Scope","text":"<p>ADRs in this directory cover decisions related to:</p> <ul> <li>ADR compliance detection strategies</li> <li>Decision drift identification</li> <li>SARIF mapping for governance violations</li> <li>ADR coverage metrics</li> <li>Enforcement vs advisory modes</li> </ul>"},{"location":"packages/tools/adr-enforcer/docs/adr/#current-adrs","title":"Current ADRs","text":"Number Title Status Date - No ADRs yet - -"},{"location":"packages/tools/adr-enforcer/docs/adr/#proposed-decisions-to-document","title":"Proposed Decisions to Document","text":"<ol> <li>ADR Detection Strategy - How to identify when ADRs should exist but don't</li> <li>Decision Drift Detection - Validate implementation matches documented decision</li> <li>Enforcement Mode - Block vs warn on violations</li> <li>ADR Coverage Metrics - What percentage of architecture is documented</li> <li>Meta-Governance - How does the ADR adapter govern itself?</li> </ol>"},{"location":"packages/tools/adr-enforcer/docs/adr/#adapter-specific-context","title":"Adapter-Specific Context","text":"<p>Purpose: Governance of governance - ensures architectural decisions are documented and followed</p> <p>Key Characteristics:</p> <ul> <li>Meta-Adapter - Governs the governance process itself</li> <li>Scans codebase for architectural patterns</li> <li>Validates implementations match ADRs</li> <li>Emits SARIF findings for missing or violated ADRs</li> <li>Self-referential (this adapter needs its own ADRs!)</li> </ul> <p>Integration Points:</p> <ul> <li>Consumes: ADR markdown files across all projects</li> <li>Analyzes: Codebase for architectural patterns</li> <li>Emits: SARIF 2.1.0 contracts to <code>.glassops/glassops-contract.sarif.json</code></li> <li>Detects: Missing ADRs, decision drift, violated constraints</li> </ul>"},{"location":"packages/tools/adr-enforcer/docs/adr/#example-violations-this-adapter-would-detect","title":"Example Violations This Adapter Would Detect","text":""},{"location":"packages/tools/adr-enforcer/docs/adr/#missing-adr","title":"Missing ADR","text":"<pre><code>SARIF Finding:\n  - ruleId: ADR_MISSING\n  - message: \"Database technology changed from PostgreSQL to MongoDB but no ADR exists\"\n  - level: warning\n  - location: db/connection.ts\n</code></pre>"},{"location":"packages/tools/adr-enforcer/docs/adr/#decision-drift","title":"Decision Drift","text":"<pre><code>SARIF Finding:\n  - ruleId: ADR_VIOLATED\n  - message: \"ADR-005 requires Kubernetes operator pattern but code uses polling\"\n  - level: error\n  - location: operator/controller.go\n  - relatedLocations: [ADR-005.md]\n</code></pre>"},{"location":"packages/tools/adr-enforcer/docs/adr/#outdated-adr","title":"Outdated ADR","text":"<pre><code>SARIF Finding:\n  - ruleId: ADR_STALE\n  - message: \"ADR-003 status is 'Proposed' but implementation exists\"\n  - level: warning\n  - location: docs/adr/003-additive-governance.md\n</code></pre>"},{"location":"packages/tools/adr-enforcer/docs/adr/#detection-strategies-proposed","title":"Detection Strategies (Proposed)","text":"<ol> <li>Pattern Matching - Regex/AST analysis for architectural patterns</li> <li>Git History - Detect significant changes without corresponding ADRs</li> <li>Dependency Analysis - New major dependencies should have ADRs</li> <li>Contract Validation - SARIF contracts should match documented patterns</li> <li>Status Checks - ADR status (Proposed/Accepted/Deprecated) vs implementation state</li> </ol>"},{"location":"packages/tools/adr-enforcer/docs/adr/#the-meta-governance-challenge","title":"The Meta-Governance Challenge","text":"<p>This adapter faces a unique challenge: It enforces ADRs, but it also IS an adapter that needs ADRs.</p> <p>Questions:</p> <ul> <li>Who governs the governance adapter?</li> <li>Do we need ADR-001 for this adapter before writing any code?</li> <li>What if the ADR enforcement logic violates its own ADRs?</li> </ul> <p>Resolution: Bootstrap with ADR-001 defining the enforcement strategy, then self-enforce.</p>"},{"location":"packages/tools/adr-enforcer/docs/adr/#creating-a-new-adr","title":"Creating a New ADR","text":"<p>See the Master ADR Index for the template and guidelines.</p> <p>Related Documentation:</p> <ul> <li>Master ADR Index</li> <li>Platform ADRs</li> <li>ADR-006: Documentation as Governed Artifact</li> <li>[ADR- Control Plane Architecture</li> </ul>"}]}